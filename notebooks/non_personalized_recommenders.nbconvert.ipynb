{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac35dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.029372Z",
     "iopub.status.busy": "2025-08-26T05:39:24.028932Z",
     "iopub.status.idle": "2025-08-26T05:39:24.589037Z",
     "shell.execute_reply": "2025-08-26T05:39:24.588405Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lenskit as lk\n",
    "import lenskit.algorithms as lk_algo\n",
    "import lenskit.crossfold as xf\n",
    "import lenskit.metrics.predict as lk_metrics\n",
    "import lenskit.util as lk_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c05810b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.591227Z",
     "iopub.status.busy": "2025-08-26T05:39:24.591056Z",
     "iopub.status.idle": "2025-08-26T05:39:24.597572Z",
     "shell.execute_reply": "2025-08-26T05:39:24.597184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/workspace/data/external/ratings.csv'),\n",
       " PosixPath('/workspace/data/external/movies.csv'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Paths tailored to your project ---\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA = PROJ / 'data' / 'external'\n",
    "PRED_DIR = PROJ / 'predictions' / 'processed'\n",
    "PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RATINGS_PATH = DATA / 'ratings.csv'\n",
    "MOVIES_PATH  = DATA / 'movies.csv'\n",
    "\n",
    "# Read as latin-1 encoding\n",
    "RATINGS_PATH, MOVIES_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5537e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.600910Z",
     "iopub.status.busy": "2025-08-26T05:39:24.600632Z",
     "iopub.status.idle": "2025-08-26T05:39:24.729797Z",
     "shell.execute_reply": "2025-08-26T05:39:24.729328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12882</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12882</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12882</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12882</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12882</td>\n",
       "      <td>110</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0   12882        1     4.0\n",
       "1   12882       32     3.5\n",
       "2   12882       47     5.0\n",
       "3   12882       50     5.0\n",
       "4   12882      110     4.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read ratings and movies data with specified encoding\n",
    "ratings = pd.read_csv(RATINGS_PATH, encoding='latin-1')\n",
    "movies  = pd.read_csv(MOVIES_PATH, encoding='latin-1')\n",
    "\n",
    "# Normalize column names to standard names\n",
    "colmap = {}\n",
    "if 'user' in ratings.columns: colmap['user'] = 'userId'\n",
    "if 'item' in ratings.columns: colmap['item'] = 'movieId'\n",
    "if 'UserID' in ratings.columns: colmap['UserID'] = 'userId'\n",
    "if 'MovieID' in ratings.columns: colmap['MovieID'] = 'movieId'\n",
    "if 'Rating' in ratings.columns: colmap['Rating'] = 'rating'\n",
    "\n",
    "ratings = ratings.rename(columns=colmap)\n",
    "ratings = ratings[['userId','movieId','rating']]\n",
    "\n",
    "# Display the ratings table as output\n",
    "from IPython.display import display\n",
    "display(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ba0ad",
   "metadata": {},
   "source": [
    "## ranks items by their scores to get the top-N results (topn_series) and then attaches movie titles to those top-scoring IDs if the movies DataFrame contains them (with_titles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effde4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.731215Z",
     "iopub.status.busy": "2025-08-26T05:39:24.731111Z",
     "iopub.status.idle": "2025-08-26T05:39:24.735550Z",
     "shell.execute_reply": "2025-08-26T05:39:24.735261Z"
    }
   },
   "outputs": [],
   "source": [
    "def topn_series(scores: pd.Series, n=10) -> pd.Series:\n",
    "    if n is None or n >= len(scores):\n",
    "        return scores.sort_values(ascending=False)\n",
    "    idx = np.argpartition(-scores.values, range(min(n, len(scores))))[:n]\n",
    "    return scores.iloc[idx].sort_values(ascending=False)\n",
    "\n",
    "def with_titles(series: pd.Series, movies: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = series.rename('score').to_frame().reset_index().rename(columns={'index':'movieId'})\n",
    "    has_titles = {'movieId','title'}.issubset(movies.columns)\n",
    "    return df.merge(movies[['movieId','title']], on='movieId', how='left') if has_titles else df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d61ec",
   "metadata": {},
   "source": [
    "## Raw item means (equivalent of pandas groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ff15eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.736648Z",
     "iopub.status.busy": "2025-08-26T05:39:24.736535Z",
     "iopub.status.idle": "2025-08-26T05:39:24.761712Z",
     "shell.execute_reply": "2025-08-26T05:39:24.761309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>4.364362</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858</td>\n",
       "      <td>4.315848</td>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1248</td>\n",
       "      <td>4.259259</td>\n",
       "      <td>Touch of Evil (1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2959</td>\n",
       "      <td>4.258503</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7502</td>\n",
       "      <td>4.247423</td>\n",
       "      <td>Band of Brothers (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1203</td>\n",
       "      <td>4.246032</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2859</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>Stop Making Sense (1984)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1221</td>\n",
       "      <td>4.218462</td>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>296</td>\n",
       "      <td>4.217781</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2571</td>\n",
       "      <td>4.195359</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId     score                             title\n",
       "0      318  4.364362  Shawshank Redemption, The (1994)\n",
       "1      858  4.315848             Godfather, The (1972)\n",
       "2     1248  4.259259              Touch of Evil (1958)\n",
       "3     2959  4.258503                 Fight Club (1999)\n",
       "4     7502  4.247423           Band of Brothers (2001)\n",
       "5     1203  4.246032               12 Angry Men (1957)\n",
       "6     2859  4.220000          Stop Making Sense (1984)\n",
       "7     1221  4.218462    Godfather: Part II, The (1974)\n",
       "8      296  4.217781               Pulp Fiction (1994)\n",
       "9     2571  4.195359                Matrix, The (1999)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_means = ratings.groupby('movieId')['rating'].mean().rename('mean')\n",
    "top_raw = with_titles(topn_series(item_means, 10), movies)\n",
    "top_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce35258b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.763047Z",
     "iopub.status.busy": "2025-08-26T05:39:24.762912Z",
     "iopub.status.idle": "2025-08-26T05:39:24.771683Z",
     "shell.execute_reply": "2025-08-26T05:39:24.771317Z"
    }
   },
   "outputs": [],
   "source": [
    "item_means.to_csv(PRED_DIR / 'item_means_raw.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90df65",
   "metadata": {},
   "source": [
    "## 5) Damped item means (Bayesian mean)\n",
    "\n",
    "> Formula: $\\displaystyle \\hat{\\mu}_i = \\frac{\\sum r_{ui} + \\alpha \\mu}{n_i + \\alpha}$, where $\\mu$ is global mean, $n_i$ is item count, $\\alpha$ is damping (e.g., 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace40f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.773044Z",
     "iopub.status.busy": "2025-08-26T05:39:24.772887Z",
     "iopub.status.idle": "2025-08-26T05:39:24.787452Z",
     "shell.execute_reply": "2025-08-26T05:39:24.787110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>4.356802</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858</td>\n",
       "      <td>4.306888</td>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2959</td>\n",
       "      <td>4.252142</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1203</td>\n",
       "      <td>4.226909</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296</td>\n",
       "      <td>4.212007</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7502</td>\n",
       "      <td>4.210983</td>\n",
       "      <td>Band of Brothers (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1221</td>\n",
       "      <td>4.207637</td>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1248</td>\n",
       "      <td>4.195260</td>\n",
       "      <td>Touch of Evil (1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2571</td>\n",
       "      <td>4.190223</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4226</td>\n",
       "      <td>4.187542</td>\n",
       "      <td>Memento (2000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId     score                             title\n",
       "0      318  4.356802  Shawshank Redemption, The (1994)\n",
       "1      858  4.306888             Godfather, The (1972)\n",
       "2     2959  4.252142                 Fight Club (1999)\n",
       "3     1203  4.226909               12 Angry Men (1957)\n",
       "4      296  4.212007               Pulp Fiction (1994)\n",
       "5     7502  4.210983           Band of Brothers (2001)\n",
       "6     1221  4.207637    Godfather: Part II, The (1974)\n",
       "7     1248  4.195260              Touch of Evil (1958)\n",
       "8     2571  4.190223                Matrix, The (1999)\n",
       "9     4226  4.187542                    Memento (2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA = 5.0  # matches the assignment\n",
    "\n",
    "mu = ratings['rating'].mean()\n",
    "grp = ratings.groupby('movieId')['rating'].agg(['sum','count'])\n",
    "item_means_damped = ((grp['sum'] + ALPHA*mu) / (grp['count'] + ALPHA)).rename('damped_mean')\n",
    "\n",
    "top_damped = with_titles(topn_series(item_means_damped, 10), movies)\n",
    "top_damped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c5690f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.788777Z",
     "iopub.status.busy": "2025-08-26T05:39:24.788660Z",
     "iopub.status.idle": "2025-08-26T05:39:24.794646Z",
     "shell.execute_reply": "2025-08-26T05:39:24.794262Z"
    }
   },
   "outputs": [],
   "source": [
    "item_means_damped.to_csv(PRED_DIR / 'item_means_damped.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3733105b",
   "metadata": {},
   "source": [
    "# Cross-check with LensKit’s Bias model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678b8b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:24.796266Z",
     "iopub.status.busy": "2025-08-26T05:39:24.796150Z",
     "iopub.status.idle": "2025-08-26T05:39:25.199755Z",
     "shell.execute_reply": "2025-08-26T05:39:25.199169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.881784197001252e-16,\n",
       "          damped_mean  mean_lkpy\n",
       " movieId                        \n",
       " 1           3.790460   3.790460\n",
       " 2           3.077536   3.077536\n",
       " 3           2.958076   2.958076\n",
       " 4           2.834462   2.834462\n",
       " 5           2.889140   2.889140)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try both import paths; different LKPY versions organize modules slightly differently.\n",
    "try:\n",
    "    from lenskit.algorithms.basic import Bias\n",
    "except Exception:\n",
    "    from lenskit.basic import Bias  # fallback for some builds\n",
    "\n",
    "# lenskit 0.14.4 expects columns named 'user', 'item', 'rating'\n",
    "ratings_lk = ratings.rename(columns={'userId': 'user', 'movieId': 'item'})\n",
    "\n",
    "# item-only bias → item means (global + item offset)\n",
    "bias = Bias(items=True, users=False, damping=ALPHA)\n",
    "bias.fit(ratings_lk)  # expects user, item, rating\n",
    "\n",
    "# In recent LKPY versions, use bias.mean_ instead of bias.global_mean\n",
    "lkpy_item_means = pd.Series(\n",
    "    bias.mean_ + bias.item_offsets_,\n",
    "    index=bias.item_offsets_.index, name='mean_lkpy'\n",
    ")\n",
    "# Convert index back to movieId for comparison\n",
    "lkpy_item_means.index.name = 'movieId'\n",
    "lkpy_item_means.index = lkpy_item_means.index.astype(ratings['movieId'].dtype)\n",
    "\n",
    "# Check they match our manual damped means\n",
    "chk = pd.concat([item_means_damped, lkpy_item_means], axis=1).dropna()\n",
    "float(np.max(np.abs(chk['damped_mean'] - chk['mean_lkpy']))), chk.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783baa05",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 7) Basic Association Rules — $P(i\\mid j)$\n",
    "\n",
    "> $P(i\\mid j) = \\frac{|U_i \\cap U_j|}{|U_j|}$. Treat each user’s rated items as a basket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8889b623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:25.201747Z",
     "iopub.status.busy": "2025-08-26T05:39:25.201535Z",
     "iopub.status.idle": "2025-08-26T05:39:25.277740Z",
     "shell.execute_reply": "2025-08-26T05:39:25.277349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2571</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1196</td>\n",
       "      <td>0.899065</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4993</td>\n",
       "      <td>0.891589</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1210</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi (1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5952</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7153</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>296</td>\n",
       "      <td>0.828037</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1198</td>\n",
       "      <td>0.790654</td>\n",
       "      <td>Raiders of the Lost Ark (Indiana Jones and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>480</td>\n",
       "      <td>0.788785</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId     score                                              title\n",
       "0     2571  0.915888                                 Matrix, The (1999)\n",
       "1     1196  0.899065  Star Wars: Episode V - The Empire Strikes Back...\n",
       "2     4993  0.891589  Lord of the Rings: The Fellowship of the Ring,...\n",
       "3     1210  0.846729  Star Wars: Episode VI - Return of the Jedi (1983)\n",
       "4      356  0.842991                                Forrest Gump (1994)\n",
       "5     5952  0.841121      Lord of the Rings: The Two Towers, The (2002)\n",
       "6     7153  0.829907  Lord of the Rings: The Return of the King, The...\n",
       "7      296  0.828037                                Pulp Fiction (1994)\n",
       "8     1198  0.790654  Raiders of the Lost Ark (Indiana Jones and the...\n",
       "9      480  0.788785                               Jurassic Park (1993)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def baskets_from_ratings(df: pd.DataFrame):\n",
    "    return df.groupby('userId')['movieId'].apply(lambda s: set(s.values))\n",
    "\n",
    "def basic_assoc_scores(df: pd.DataFrame, reference: int) -> pd.Series:\n",
    "    baskets = baskets_from_ratings(df)\n",
    "    uj = sum(1 for items in baskets if reference in items)\n",
    "    if uj == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    co = Counter()\n",
    "    for items in baskets:\n",
    "        if reference in items:\n",
    "            co.update(i for i in items if i != reference)\n",
    "    scores = {i: c/uj for i, c in co.items()}\n",
    "    return pd.Series(scores, name='assoc_basic').sort_values(ascending=False)\n",
    "\n",
    "REFERENCE = 260  # Star Wars in ML-1M/100k; adjust to your data if needed\n",
    "basic_scores = basic_assoc_scores(ratings, REFERENCE)\n",
    "with_titles(topn_series(basic_scores, 10), movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eb37e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:25.279011Z",
     "iopub.status.busy": "2025-08-26T05:39:25.278875Z",
     "iopub.status.idle": "2025-08-26T05:39:25.285726Z",
     "shell.execute_reply": "2025-08-26T05:39:25.285408Z"
    }
   },
   "outputs": [],
   "source": [
    "basic_scores.to_csv(PRED_DIR / f'basic_assoc_ref_{REFERENCE}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22bbe37",
   "metadata": {},
   "source": [
    "## 8) Lift Association Rules — $\\text{lift}(i\\mid j)=\\frac{P(i\\land j)}{P(i)P(j)}$\n",
    "\n",
    "> Equivalent with counts: $\\text{lift} = \\frac{|U_i\\cap U_j|\\cdot |U|}{|U_i|\\cdot |U_j|}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383113e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:25.286911Z",
     "iopub.status.busy": "2025-08-26T05:39:25.286787Z",
     "iopub.status.idle": "2025-08-26T05:39:25.356780Z",
     "shell.execute_reply": "2025-08-26T05:39:25.356364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631</td>\n",
       "      <td>4.897727</td>\n",
       "      <td>All Dogs Go to Heaven 2 (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2532</td>\n",
       "      <td>4.810268</td>\n",
       "      <td>Conquest of the Planet of the Apes (1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3615</td>\n",
       "      <td>4.545703</td>\n",
       "      <td>Dinosaur (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340</td>\n",
       "      <td>4.489583</td>\n",
       "      <td>War, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016</td>\n",
       "      <td>4.489583</td>\n",
       "      <td>Shaggy Dog, The (1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2439</td>\n",
       "      <td>4.489583</td>\n",
       "      <td>Affliction (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1649</td>\n",
       "      <td>4.489583</td>\n",
       "      <td>Fast, Cheap &amp; Out of Control (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>332</td>\n",
       "      <td>4.377344</td>\n",
       "      <td>Village of the Damned (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2736</td>\n",
       "      <td>4.329241</td>\n",
       "      <td>Brighton Beach Memoirs (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3213</td>\n",
       "      <td>4.316907</td>\n",
       "      <td>Batman: Mask of the Phantasm (1993)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId     score                                      title\n",
       "0      631  4.897727             All Dogs Go to Heaven 2 (1996)\n",
       "1     2532  4.810268  Conquest of the Planet of the Apes (1972)\n",
       "2     3615  4.545703                            Dinosaur (2000)\n",
       "3      340  4.489583                            War, The (1994)\n",
       "4     1016  4.489583                     Shaggy Dog, The (1959)\n",
       "5     2439  4.489583                          Affliction (1997)\n",
       "6     1649  4.489583        Fast, Cheap & Out of Control (1997)\n",
       "7      332  4.377344               Village of the Damned (1995)\n",
       "8     2736  4.329241              Brighton Beach Memoirs (1986)\n",
       "9     3213  4.316907        Batman: Mask of the Phantasm (1993)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lift_assoc_scores(df: pd.DataFrame, reference: int) -> pd.Series:\n",
    "    baskets = baskets_from_ratings(df)\n",
    "    U = len(baskets)\n",
    "    if U == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    item_users = Counter()\n",
    "    for items in baskets:\n",
    "        item_users.update(items)\n",
    "\n",
    "    uj = item_users.get(reference, 0)\n",
    "    if uj == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    co = Counter()\n",
    "    for items in baskets:\n",
    "        if reference in items:\n",
    "            co.update(i for i in items if i != reference)\n",
    "\n",
    "    out = {}\n",
    "    for i, cij in co.items():\n",
    "        ui = item_users.get(i, 0)\n",
    "        if ui > 0:\n",
    "            out[i] = (cij * U) / (ui * uj)\n",
    "    return pd.Series(out, name='assoc_lift').sort_values(ascending=False)\n",
    "\n",
    "REFERENCE_LIFT = 2761  # Iron Giant in example; change if not in your data\n",
    "lift_scores = lift_assoc_scores(ratings, REFERENCE_LIFT)\n",
    "with_titles(topn_series(lift_scores, 10), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8232a2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:25.357982Z",
     "iopub.status.busy": "2025-08-26T05:39:25.357859Z",
     "iopub.status.idle": "2025-08-26T05:39:25.364404Z",
     "shell.execute_reply": "2025-08-26T05:39:25.364021Z"
    }
   },
   "outputs": [],
   "source": [
    "lift_scores.to_csv(PRED_DIR / f'lift_assoc_ref_{REFERENCE_LIFT}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7a3dc",
   "metadata": {},
   "source": [
    "# Quick sanity checks (match the handout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f210360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:25.365671Z",
     "iopub.status.busy": "2025-08-26T05:39:25.365553Z",
     "iopub.status.idle": "2025-08-26T05:39:25.378782Z",
     "shell.execute_reply": "2025-08-26T05:39:25.378378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>score_raw</th>\n",
       "      <th>title</th>\n",
       "      <th>score_damped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2959</td>\n",
       "      <td>4.258503</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>4.252142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1203</td>\n",
       "      <td>4.246032</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "      <td>4.226909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  score_raw                title  score_damped\n",
       "0     2959   4.258503    Fight Club (1999)      4.252142\n",
       "1     1203   4.246032  12 Angry Men (1957)      4.226909"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust IDs if your dataset differs from the handout\n",
    "check_ids = [2959, 1203]  # Fight Club, 12 Angry Men (if present)\n",
    "disp = pd.DataFrame({\n",
    "    'movieId': check_ids,\n",
    "    'mean': [item_means.get(i, np.nan) for i in check_ids],\n",
    "    'damped_mean': [item_means_damped.get(i, np.nan) for i in check_ids],\n",
    "})\n",
    "with_titles(disp.set_index('movieId')['mean'], movies).merge(\n",
    "    with_titles(disp.set_index('movieId')['damped_mean'], movies),\n",
    "    on=['movieId','title'], suffixes=('_raw','_damped')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e823bb6",
   "metadata": {},
   "source": [
    "# Save pretty Top-N tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8f87f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T05:39:25.380039Z",
     "iopub.status.busy": "2025-08-26T05:39:25.379883Z",
     "iopub.status.idle": "2025-08-26T05:39:25.390762Z",
     "shell.execute_reply": "2025-08-26T05:39:25.390424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspace/predictions/processed')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_raw.to_csv(PRED_DIR / 'top10_raw_means.csv', index=False)\n",
    "top_damped.to_csv(PRED_DIR / 'top10_damped_means.csv', index=False)\n",
    "with_titles(topn_series(basic_scores, 50), movies).to_csv(PRED_DIR / f'top_basic_assoc_{REFERENCE}.csv', index=False)\n",
    "with_titles(topn_series(lift_scores, 50), movies).to_csv(PRED_DIR / f'top_lift_assoc_{REFERENCE_LIFT}.csv', index=False)\n",
    "\n",
    "PRED_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4147f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6e314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db980e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter-friendly version of recsys_eval.py\n",
    "# All code is now importable and callable from notebook cells.\n",
    "# To run an evaluation, call `evaluate_pipeline` with your DataFrames and parameters.\n",
    "\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ------------------------------ utils & metrics ------------------------------\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(mean_squared_error(y_true, y_pred, squared=False))\n",
    "\n",
    "def precision_at_k(recs: List[int], relevant: set, k: int) -> float:\n",
    "    if k == 0 or not recs: return 0.0\n",
    "    hits = sum(1 for x in recs[:k] if x in relevant)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recs: List[int], relevant: set, k: int) -> float:\n",
    "    if not relevant: return 0.0\n",
    "    hits = sum(1 for x in recs[:k] if x in relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "def ap_at_k(recs: List[int], relevant: set, k: int) -> float:\n",
    "    if not recs: return 0.0\n",
    "    ap = 0.0\n",
    "    hits = 0\n",
    "    for i, m in enumerate(recs[:k], start=1):\n",
    "        if m in relevant:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / hits if hits > 0 else 0.0\n",
    "\n",
    "def mrr_at_k(recs: List[int], relevant: set, k: int) -> float:\n",
    "    if not recs: return 0.0\n",
    "    for i, m in enumerate(recs[:k], start=1):\n",
    "        if m in relevant:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k_binary(recs: List[int], relevant: set, k: int) -> float:\n",
    "    if not recs or k == 0: return 0.0\n",
    "    gains = [1.0 if x in relevant else 0.0 for x in recs[:k]]\n",
    "    dcg = sum(g / np.log2(i + 2) for i, g in enumerate(gains))\n",
    "    ideal = int(min(k, len(relevant)))\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal))\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def entropy(tokens: List[str]) -> float:\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "    cnt = Counter(tokens)\n",
    "    total = sum(cnt.values())\n",
    "    ps = [c / total for c in cnt.values() if c > 0]\n",
    "    return float(-sum(p * np.log2(p) for p in ps))\n",
    "\n",
    "# ------------------------------ data split -----------------------------------\n",
    "\n",
    "@dataclass\n",
    "class FoldData:\n",
    "    train_df: pd.DataFrame   # observed ratings available to train (incl. query parts of test users)\n",
    "    test_pairs: pd.DataFrame # held-out (userId, movieId, rating) to predict/evaluate\n",
    "\n",
    "def chronological_user_holdout(df: pd.DataFrame, holdout_per_user: int = 1) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split each user's ratings into query (train) and test (last-N by timestamp).\"\"\"\n",
    "    parts = []\n",
    "    tests = []\n",
    "    for uid, g in df.sort_values(\"timestamp\").groupby(\"userId\"):\n",
    "        if len(g) <= holdout_per_user:\n",
    "            # if too few, keep all in train; empty test for that user\n",
    "            parts.append(g)\n",
    "            continue\n",
    "        q = g.iloc[:-holdout_per_user]\n",
    "        t = g.iloc[-holdout_per_user:]\n",
    "        parts.append(q)\n",
    "        tests.append(t)\n",
    "    train_part = pd.concat(parts, ignore_index=True)\n",
    "    test_part = pd.concat(tests, ignore_index=True) if tests else df.iloc[0:0].copy()\n",
    "    return train_part, test_part\n",
    "\n",
    "def make_folds_user_cv(ratings: pd.DataFrame, n_folds: int, holdout_per_user: int, seed: int = 42) -> List[FoldData]:\n",
    "    users = ratings[\"userId\"].unique()\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    folds: List[FoldData] = []\n",
    "\n",
    "    for train_users_idx, test_users_idx in kf.split(users):\n",
    "        train_users = set(users[train_users_idx])\n",
    "        test_users = set(users[test_users_idx])\n",
    "\n",
    "        ratings_train_users = ratings[ratings[\"userId\"].isin(train_users)]\n",
    "        ratings_test_users  = ratings[ratings[\"userId\"].isin(test_users)]\n",
    "\n",
    "        # For test users: split into query (goes into training) and held-out test\n",
    "        query_part, heldout = chronological_user_holdout(ratings_test_users, holdout_per_user)\n",
    "\n",
    "        train_df = pd.concat([ratings_train_users, query_part], ignore_index=True)\n",
    "        test_pairs = heldout[[\"userId\", \"movieId\", \"rating\"]].copy()\n",
    "\n",
    "        folds.append(FoldData(train_df=train_df, test_pairs=test_pairs))\n",
    "    return folds\n",
    "\n",
    "# ------------------------------ baselines ------------------------------------\n",
    "\n",
    "class Baselines:\n",
    "    def __init__(self):\n",
    "        self.global_mean = None\n",
    "        self.item_mean: Dict[int, float] = {}\n",
    "        self.user_mean: Dict[int, float] = {}\n",
    "\n",
    "    def fit(self, train_df: pd.DataFrame):\n",
    "        self.global_mean = float(train_df[\"rating\"].mean())\n",
    "        self.item_mean = train_df.groupby(\"movieId\")[\"rating\"].mean().to_dict()\n",
    "        self.user_mean = train_df.groupby(\"userId\")[\"rating\"].mean().to_dict()\n",
    "\n",
    "    def predict_global(self, pairs: pd.DataFrame) -> np.ndarray:\n",
    "        return np.full(len(pairs), self.global_mean, dtype=float)\n",
    "\n",
    "    def predict_item(self, pairs: pd.DataFrame) -> np.ndarray:\n",
    "        return pairs[\"movieId\"].map(self.item_mean).fillna(self.global_mean).to_numpy(float)\n",
    "\n",
    "    def predict_user(self, pairs: pd.DataFrame) -> np.ndarray:\n",
    "        return pairs[\"userId\"].map(self.user_mean).fillna(self.global_mean).to_numpy(float)\n",
    "\n",
    "# ------------------------------ item-kNN CF ----------------------------------\n",
    "\n",
    "class ItemKNN:\n",
    "    def __init__(self, k_neighbors: int = 50, min_item_support: int = 2):\n",
    "        self.k = k_neighbors\n",
    "        self.min_item_support = min_item_support\n",
    "        self.nn = None  # NearestNeighbors\n",
    "        self.train_matrix: csr_matrix = None\n",
    "        self.user_ids: np.ndarray = None\n",
    "        self.item_ids: np.ndarray = None\n",
    "        self.user2idx: Dict[int, int] = {}\n",
    "        self.item2idx: Dict[int, int] = {}\n",
    "        self.idx2item: Dict[int, int] = {}\n",
    "        self.global_mean = None\n",
    "        self.item_degrees: Dict[int, int] = {}\n",
    "\n",
    "    def _encode(self, df: pd.DataFrame):\n",
    "        # keep only supported items (>= min_item_support unique users)\n",
    "        supported_items = df.groupby(\"movieId\")[\"userId\"].nunique()\n",
    "        supported_items = supported_items[supported_items >= self.min_item_support].index.values\n",
    "\n",
    "        users = df[\"userId\"].unique()\n",
    "        items = np.array(sorted(supported_items))\n",
    "\n",
    "        self.user_ids = np.array(sorted(users))\n",
    "        self.item_ids = items\n",
    "        self.user2idx = {u: i for i, u in enumerate(self.user_ids)}\n",
    "        self.item2idx = {m: j for j, m in enumerate(self.item_ids)}\n",
    "        self.idx2item = {j: m for m, j in self.item2idx.items()}\n",
    "\n",
    "    def fit(self, train_df: pd.DataFrame):\n",
    "        self.global_mean = float(train_df[\"rating\"].mean())\n",
    "        self._encode(train_df)\n",
    "\n",
    "        # Build CSR matrix (users x items) with only supported items\n",
    "        rows, cols, vals = [], [], []\n",
    "        for r in train_df.itertuples(index=False):\n",
    "            u, m, rt = int(r.userId), int(r.movieId), float(r.rating)\n",
    "            if m not in self.item2idx:  # unsupported\n",
    "                continue\n",
    "            rows.append(self.user2idx[u])\n",
    "            cols.append(self.item2idx[m])\n",
    "            vals.append(rt)\n",
    "        if not rows:\n",
    "            # degenerate (shouldn't happen on MovieLens)\n",
    "            self.train_matrix = csr_matrix((0, 0), dtype=float)\n",
    "            return\n",
    "\n",
    "        n_users = len(self.user_ids)\n",
    "        n_items = len(self.item_ids)\n",
    "        self.train_matrix = csr_matrix((vals, (rows, cols)), shape=(n_users, n_items), dtype=float)\n",
    "\n",
    "        # degrees per item (for info/coverage)\n",
    "        self.item_degrees = dict(zip(self.item_ids, np.asarray(self.train_matrix.sum(axis=0)).ravel().astype(int)))\n",
    "\n",
    "        # Fit item neighbors on item vectors (columns)\n",
    "        self.nn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\", n_neighbors=min(self.k + 1, n_items))\n",
    "        self.nn.fit(self.train_matrix.T)\n",
    "\n",
    "    def predict_pair(self, user_id: int, movie_id: int) -> Tuple[float, bool]:\n",
    "        \"\"\"Predict rating for (user, movie). Returns (prediction, covered?)\"\"\"\n",
    "        if movie_id not in self.item2idx or user_id not in self.user2idx:\n",
    "            # unknown item or user\n",
    "            return self.global_mean, False\n",
    "\n",
    "        u = self.user2idx[user_id]\n",
    "        i = self.item2idx[movie_id]\n",
    "\n",
    "        # if item has no ratings in train (shouldn't happen due to support), fallback\n",
    "        if self.train_matrix[:, i].nnz == 0:\n",
    "            return self.global_mean, False\n",
    "\n",
    "        dists, idxs = self.nn.kneighbors(self.train_matrix.T[i], n_neighbors=min(self.k + 1, self.train_matrix.shape[1]))\n",
    "        sims = 1.0 - dists.flatten()\n",
    "        neigh_items = idxs.flatten()\n",
    "\n",
    "        # drop self neighbor if present\n",
    "        mask = (neigh_items != i)\n",
    "        neigh_items = neigh_items[mask]\n",
    "        sims = sims[mask]\n",
    "\n",
    "        # ratings of the user for neighbor items\n",
    "        user_row = self.train_matrix[u, neigh_items].toarray().ravel()\n",
    "        rated_mask = user_row > 0\n",
    "        if not np.any(rated_mask):\n",
    "            return self.global_mean, False\n",
    "\n",
    "        num = float(np.dot(sims[rated_mask], user_row[rated_mask]))\n",
    "        den = float(np.sum(np.abs(sims[rated_mask])) + 1e-8)\n",
    "        return num / den, True\n",
    "\n",
    "    def recommend(self, user_id: int, topk: int = 10) -> List[int]:\n",
    "        \"\"\"Return a list of movieIds (not indices) recommended to the user.\"\"\"\n",
    "        if user_id not in self.user2idx:\n",
    "            return []\n",
    "        u = self.user2idx[user_id]\n",
    "        seen = set(int(self.idx2item[j]) for j in self.train_matrix[u].indices)\n",
    "\n",
    "        scores = defaultdict(float)\n",
    "\n",
    "        # Use up to S seed items from user's profile for speed\n",
    "        seeds = list(self.train_matrix[u].indices)\n",
    "        if not seeds:\n",
    "            return []\n",
    "\n",
    "        # Accumulate neighbor sims\n",
    "        for it in seeds:\n",
    "            dists, idxs = self.nn.kneighbors(self.train_matrix.T[it], n_neighbors=min(self.k + 1, self.train_matrix.shape[1]))\n",
    "            sims = 1.0 - dists.flatten()\n",
    "            neigh_items = idxs.flatten()\n",
    "            for j, s in zip(neigh_items, sims):\n",
    "                if j == it:\n",
    "                    continue\n",
    "                m_id = int(self.idx2item[j])\n",
    "                if m_id in seen:\n",
    "                    continue\n",
    "                scores[m_id] += float(s)\n",
    "\n",
    "        if not scores:\n",
    "            return []\n",
    "\n",
    "        ranked = sorted(scores.items(), key=lambda kv: -kv[1])\n",
    "        return [m for m, _ in ranked[:topk]]\n",
    "\n",
    "# ------------------------------ diversity helpers ----------------------------\n",
    "\n",
    "def build_movie_tokens(movies: pd.DataFrame, tags: pd.DataFrame) -> Dict[int, List[str]]:\n",
    "    \"\"\"Map movieId -> list of tokens (tags if present, else genres as pseudo-tags).\"\"\"\n",
    "    tags = tags.copy()\n",
    "    tags[\"tag\"] = tags[\"tag\"].fillna(\"\").astype(str).str.lower().str.strip()\n",
    "    tag_map = tags.groupby(\"movieId\")[\"tag\"].apply(list).to_dict()\n",
    "\n",
    "    genres = movies.set_index(\"movieId\")[\"genres\"].fillna(\"\").astype(str).to_dict()\n",
    "\n",
    "    out = {}\n",
    "    for mid in set(list(genres.keys()) + list(tag_map.keys())):\n",
    "        toks = []\n",
    "        if mid in tag_map and len(tag_map[mid]) > 0:\n",
    "            toks = [t for t in tag_map[mid] if t]\n",
    "        if not toks:\n",
    "            g = genres.get(mid, \"\")\n",
    "            if g:\n",
    "                toks = [x.strip().lower() for x in g.split(\"|\") if x]\n",
    "        out[mid] = toks\n",
    "    return out\n",
    "\n",
    "# ------------------------------ main eval loop -------------------------------\n",
    "\n",
    "def evaluate_pipeline(\n",
    "    movies: pd.DataFrame,\n",
    "    ratings: pd.DataFrame,\n",
    "    tags: pd.DataFrame,\n",
    "    folds: int = 5,\n",
    "    holdout_per_user: int = 1,\n",
    "    neighbors: int = 50,\n",
    "    topk: int = 10,\n",
    "    min_item_support: int = 2,\n",
    "    seed: int = 42,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Ensure proper dtypes\n",
    "    for c in [\"userId\", \"movieId\", \"rating\", \"timestamp\"]:\n",
    "        assert c in ratings.columns, f\"ratings.csv missing '{c}'\"\n",
    "\n",
    "    ratings = ratings.copy()\n",
    "    ratings[\"userId\"] = ratings[\"userId\"].astype(int)\n",
    "    ratings[\"movieId\"] = ratings[\"movieId\"].astype(int)\n",
    "    ratings[\"rating\"] = ratings[\"rating\"].astype(float)\n",
    "    ratings[\"timestamp\"] = ratings[\"timestamp\"].astype(int)\n",
    "\n",
    "    folds_data = make_folds_user_cv(ratings, n_folds=folds, holdout_per_user=holdout_per_user, seed=seed)\n",
    "\n",
    "    # Precompute tokens for diversity (once)\n",
    "    movie_tokens = build_movie_tokens(movies, tags)\n",
    "\n",
    "    # Aggregators\n",
    "    rmse_global_all, rmse_item_all, rmse_user_all, rmse_itemknn_all = [], [], [], []\n",
    "    pred_cov_itemknn_all = []\n",
    "    # Top-N metrics for itemKNN and popularity\n",
    "    topn_item_metrics = []\n",
    "    topn_pop_metrics = []\n",
    "    user_cov_itemknn_all = []\n",
    "    catalog_cov_itemknn_all = []\n",
    "    diversity_itemknn_all = []\n",
    "\n",
    "    for fold_idx, fold in enumerate(folds_data, start=1):\n",
    "        train_df = fold.train_df.copy()\n",
    "        test_pairs = fold.test_pairs.copy()\n",
    "\n",
    "        # ---------------- baselines ----------------\n",
    "        bl = Baselines()\n",
    "        bl.fit(train_df)\n",
    "\n",
    "        y_true = test_pairs[\"rating\"].to_numpy(float)\n",
    "        y_pred_global = bl.predict_global(test_pairs)\n",
    "        y_pred_item = bl.predict_item(test_pairs)\n",
    "        y_pred_user = bl.predict_user(test_pairs)\n",
    "\n",
    "        rmse_global_all.append(rmse(y_true, y_pred_global))\n",
    "        rmse_item_all.append(rmse(y_true, y_pred_item))\n",
    "        rmse_user_all.append(rmse(y_true, y_pred_user))\n",
    "\n",
    "        # ---------------- item-kNN CF ----------------\n",
    "        iknn = ItemKNN(k_neighbors=neighbors, min_item_support=min_item_support)\n",
    "        iknn.fit(train_df)\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        covered_flags = []\n",
    "        for r in test_pairs.itertuples(index=False):\n",
    "            p, covered = iknn.predict_pair(int(r.userId), int(r.movieId))\n",
    "            preds.append(p)\n",
    "            trues.append(float(r.rating))\n",
    "            covered_flags.append(covered)\n",
    "\n",
    "        if preds:\n",
    "            rmse_itemknn_all.append(rmse(trues, preds))\n",
    "            pred_cov_itemknn_all.append(np.mean(covered_flags))\n",
    "        else:\n",
    "            rmse_itemknn_all.append(np.nan)\n",
    "            pred_cov_itemknn_all.append(0.0)\n",
    "\n",
    "        # ---------------- Top-N: item-kNN & popularity ----------------\n",
    "        # Relevant set is each test user's held-out items\n",
    "        test_by_user = test_pairs.groupby(\"userId\")[\"movieId\"].apply(set).to_dict()\n",
    "\n",
    "        # Popularity baseline from train\n",
    "        pop_items = train_df.groupby(\"movieId\").size().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "        # Gather recommendations & metrics\n",
    "        recs_item_all = {}\n",
    "        recs_pop_all = {}\n",
    "        for uid in test_by_user.keys():\n",
    "            recs_item_all[uid] = iknn.recommend(uid, topk=topk)\n",
    "            # popularity excluding seen items\n",
    "            seen = set(train_df.loc[train_df[\"userId\"] == uid, \"movieId\"].values)\n",
    "            pop_recs = [m for m in pop_items if m not in seen][:topk]\n",
    "            recs_pop_all[uid] = pop_recs\n",
    "\n",
    "        def aggregate_topn(recs_dict):\n",
    "            precs, recs, maps, mrrs, ndcgs = [], [], [], [], []\n",
    "            nonempty_users = 0\n",
    "            catalog_items = set()\n",
    "            for uid, rel in test_by_user.items():\n",
    "                recs_list = recs_dict.get(uid, [])\n",
    "                if recs_list:\n",
    "                    nonempty_users += 1\n",
    "                    catalog_items.update(recs_list)\n",
    "                precs.append(precision_at_k(recs_list, rel, topk))\n",
    "                recs.append(recall_at_k(recs_list, rel, topk))\n",
    "                maps.append(ap_at_k(recs_list, rel, topk))\n",
    "                mrrs.append(mrr_at_k(recs_list, rel, topk))\n",
    "                ndcgs.append(ndcg_at_k_binary(recs_list, rel, topk))\n",
    "            user_coverage = nonempty_users / max(1, len(test_by_user))\n",
    "            catalog_coverage = len(catalog_items) / max(1, len(iknn.item_ids))\n",
    "            return {\n",
    "                \"precision\": float(np.mean(precs)),\n",
    "                \"recall\": float(np.mean(recs)),\n",
    "                \"map\": float(np.mean(maps)),\n",
    "                \"mrr\": float(np.mean(mrrs)),\n",
    "                \"ndcg\": float(np.mean(ndcgs)),\n",
    "                \"user_coverage\": user_coverage,\n",
    "                \"catalog_coverage\": catalog_coverage,\n",
    "            }\n",
    "\n",
    "        item_topn = aggregate_topn(recs_item_all)\n",
    "        pop_topn = aggregate_topn(recs_pop_all)\n",
    "        topn_item_metrics.append(item_topn)\n",
    "        topn_pop_metrics.append(pop_topn)\n",
    "        user_cov_itemknn_all.append(item_topn[\"user_coverage\"])\n",
    "        catalog_cov_itemknn_all.append(item_topn[\"catalog_coverage\"])\n",
    "\n",
    "        # ---------------- Diversity (tag entropy) for item-kNN ----------------\n",
    "        entrs = []\n",
    "        for uid, recs_list in recs_item_all.items():\n",
    "            toks = []\n",
    "            for m in recs_list:\n",
    "                toks.extend(movie_tokens.get(m, []))\n",
    "            entrs.append(entropy(toks))\n",
    "        diversity_itemknn_all.append(float(np.mean(entrs) if entrs else 0.0))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[fold {fold_idx}/{len(folds_data)}] \"\n",
    "                  f\"RMSE: GM={rmse_global_all[-1]:.4f} IM={rmse_item_all[-1]:.4f} UM={rmse_user_all[-1]:.4f} iKNN={rmse_itemknn_all[-1]:.4f} \"\n",
    "                  f\"| TopN(iKNN) P@{topk}={item_topn['precision']:.3f} nDCG={item_topn['ndcg']:.3f} \"\n",
    "                  f\"| PredCov(iKNN)={pred_cov_itemknn_all[-1]:.3f}\")\n",
    "\n",
    "    # Average over folds\n",
    "    def avg_or_nan(xs): \n",
    "        xs = [x for x in xs if np.isfinite(x)]\n",
    "        return float(np.mean(xs)) if xs else float(\"nan\")\n",
    "\n",
    "    summary = {\n",
    "        \"params\": {\n",
    "            \"folds\": folds,\n",
    "            \"holdout_per_user\": holdout_per_user,\n",
    "            \"neighbors\": neighbors,\n",
    "            \"topk\": topk,\n",
    "            \"min_item_support\": min_item_support,\n",
    "            \"seed\": seed,\n",
    "        },\n",
    "        \"RMSE\": {\n",
    "            \"GlobalMean\": round(avg_or_nan(rmse_global_all), 4),\n",
    "            \"ItemMean\": round(avg_or_nan(rmse_item_all), 4),\n",
    "            \"UserMean\": round(avg_or_nan(rmse_user_all), 4),\n",
    "            \"ItemKNN\": round(avg_or_nan(rmse_itemknn_all), 4),\n",
    "            \"ItemKNN_PredictionCoverage\": round(avg_or_nan(pred_cov_itemknn_all), 4),\n",
    "        },\n",
    "        \"TopN_ItemKNN\": {\n",
    "            \"Precision\": round(np.mean([m[\"precision\"] for m in topn_item_metrics]), 4),\n",
    "            \"Recall\": round(np.mean([m[\"recall\"] for m in topn_item_metrics]), 4),\n",
    "            \"MAP\": round(np.mean([m[\"map\"] for m in topn_item_metrics]), 4),\n",
    "            \"MRR\": round(np.mean([m[\"mrr\"] for m in topn_item_metrics]), 4),\n",
    "            \"nDCG\": round(np.mean([m[\"ndcg\"] for m in topn_item_metrics]), 4),\n",
    "            \"UserCoverage\": round(avg_or_nan(user_cov_itemknn_all), 4),\n",
    "            \"CatalogCoverage\": round(avg_or_nan(catalog_cov_itemknn_all), 4),\n",
    "            \"Diversity_TagEntropy\": round(avg_or_nan(diversity_itemknn_all), 4),\n",
    "        },\n",
    "        \"TopN_Popularity\": {\n",
    "            \"Precision\": round(np.mean([m[\"precision\"] for m in topn_pop_metrics]), 4),\n",
    "            \"Recall\": round(np.mean([m[\"recall\"] for m in topn_pop_metrics]), 4),\n",
    "            \"MAP\": round(np.mean([m[\"map\"] for m in topn_pop_metrics]), 4),\n",
    "            \"MRR\": round(np.mean([m[\"mrr\"] for m in topn_pop_metrics]), 4),\n",
    "            \"nDCG\": round(np.mean([m[\"ndcg\"] for m in topn_pop_metrics]), 4),\n",
    "            \"UserCoverage\": round(np.mean([m[\"user_coverage\"] for m in topn_pop_metrics]), 4),\n",
    "            \"CatalogCoverage\": round(np.mean([m[\"catalog_coverage\"] for m in topn_pop_metrics]), 4),\n",
    "        }\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d2c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load the movies data from the external data directory\n",
    "movies_path = Path(\"/workspace/data/external/movies.csv\")\n",
    "movies = pd.read_csv(movies_path)\n",
    "# Load the ratings and tags data from the external data directory\n",
    "ratings_path = Path(\"/workspace/data/external/ratings.csv\")\n",
    "tags_path = Path(\"/workspace/data/external/tags.csv\")\n",
    "\n",
    "# Specify encoding='latin1' to handle UnicodeDecodeError\n",
    "ratings = pd.read_csv(ratings_path, encoding='latin1')\n",
    "tags = pd.read_csv(tags_path, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43bec7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage in a notebook:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# If you encounter \"TypeError: got an unexpected keyword argument 'squared'\",\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# remove the 'squared' argument from your function calls.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_per_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(summary, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 335\u001b[0m, in \u001b[0;36mevaluate_pipeline\u001b[0;34m(movies, ratings, tags, folds, holdout_per_user, neighbors, topk, min_item_support, seed, verbose)\u001b[0m\n\u001b[1;32m    332\u001b[0m y_pred_item \u001b[38;5;241m=\u001b[39m bl\u001b[38;5;241m.\u001b[39mpredict_item(test_pairs)\n\u001b[1;32m    333\u001b[0m y_pred_user \u001b[38;5;241m=\u001b[39m bl\u001b[38;5;241m.\u001b[39mpredict_user(test_pairs)\n\u001b[0;32m--> 335\u001b[0m rmse_global_all\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_global\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    336\u001b[0m rmse_item_all\u001b[38;5;241m.\u001b[39mappend(rmse(y_true, y_pred_item))\n\u001b[1;32m    337\u001b[0m rmse_user_all\u001b[38;5;241m.\u001b[39mappend(rmse(y_true, y_pred_user))\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mrmse\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrmse\u001b[39m(y_true, y_pred) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_sig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/inspect.py:3175\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3173\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m   3174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3176\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3177\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# Example usage in a notebook:\n",
    "# If you encounter \"TypeError: got an unexpected keyword argument 'squared'\",\n",
    "# remove the 'squared' argument from your function calls.\n",
    "summary = evaluate_pipeline(movies, ratings, tags, folds=5, holdout_per_user=1, neighbors=50, topk=10)\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b8b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
