{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6015605",
   "metadata": {},
   "source": [
    "# item–item KNN CF using BM25‑weighted cosine + shrinkage, evaluated by leave‑one‑out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3551e",
   "metadata": {},
   "source": [
    "1. Split by order time, not by (user, item) rows. Example: sort orders by order_timestamp, use first 80% of orders as train, last 20% as test (or a rolling window).\n",
    "  a. Deduplicate within order: treat (order, item) as binary; handle quantities separately only if needed.\n",
    "  \n",
    "  b. Cold items (seen only in test) can’t be recommended; track coverage. Backfill with category/popularity.\n",
    "  c. Build matrices on TRAIN ONLY\n",
    "\n",
    "\n",
    "2. For each test order with ≥2 items, randomly hide 1 item and predict it from the remaining items in the same basket.\n",
    "  a. Very popular items dominate cosine; use BM25/TF‑IDF or lift to reduce popularity bias.\n",
    "  b. Shrinkage is essential for long‑tail items.\n",
    "  c. For your “basket-aware” scenario, CF (item2vec/ALS) captures co-purchase complements well. But start with item-item CF (BM25-weighted cosine + shrinkage). Simple, strong, fast.\n",
    "3. Use implicit feedback techniques (co‑occurrence, cosine/Jaccard/lift, BM25/TF‑IDF weighting, shrinkage) and add fallbacks (popularity, category‑aware) for baskets with too little context. Report HitRate@K / Recall@K / NDCG@K. (With one hidden item, HitRate@K = Recall@K.) To capture richer relations or to unify with next-order personalization later: train Item2vec or ALS; at serve time you can:\n",
    "- do basket averaging (Item2vec) or fold-in (ALS) for context-aware recs, or\n",
    "- precompute top-K neighbors per item from embeddings and serve like item-item CF.\n",
    "\n",
    "If you split items from the same order across train and test, you’ll artificially inflate results.\n",
    "Filters at serve time: availability, price range, category blacklists, etc.\n",
    "\n",
    "for basket completion, both Item2vec and ALS work without historical user data by using the current cart as context. For home-page personalization with no context, you’ll need past interactions (ALS) or rely on non-CF signals (popularity/content)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "51bd3eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shopUserId</th>\n",
       "      <th>orderId</th>\n",
       "      <th>quantity</th>\n",
       "      <th>groupId</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>812427</td>\n",
       "      <td>785001</td>\n",
       "      <td>1</td>\n",
       "      <td>261873</td>\n",
       "      <td>2025-08-05 20:14:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>831360</td>\n",
       "      <td>784985</td>\n",
       "      <td>4</td>\n",
       "      <td>261745</td>\n",
       "      <td>2025-08-05 19:55:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>230625</td>\n",
       "      <td>784973</td>\n",
       "      <td>1</td>\n",
       "      <td>260951</td>\n",
       "      <td>2025-08-05 19:39:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>230625</td>\n",
       "      <td>784973</td>\n",
       "      <td>1</td>\n",
       "      <td>590833</td>\n",
       "      <td>2025-08-05 19:39:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>230625</td>\n",
       "      <td>784973</td>\n",
       "      <td>1</td>\n",
       "      <td>260141</td>\n",
       "      <td>2025-08-05 19:39:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250024</th>\n",
       "      <td>78202</td>\n",
       "      <td>158870</td>\n",
       "      <td>1</td>\n",
       "      <td>221416</td>\n",
       "      <td>2024-05-22 14:18:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250026</th>\n",
       "      <td>78181</td>\n",
       "      <td>158841</td>\n",
       "      <td>1</td>\n",
       "      <td>265843</td>\n",
       "      <td>2024-05-22 13:42:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250038</th>\n",
       "      <td>78145</td>\n",
       "      <td>158800</td>\n",
       "      <td>1</td>\n",
       "      <td>261518</td>\n",
       "      <td>2024-05-22 12:54:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250039</th>\n",
       "      <td>78136</td>\n",
       "      <td>158791</td>\n",
       "      <td>1</td>\n",
       "      <td>542087</td>\n",
       "      <td>2024-05-22 12:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250040</th>\n",
       "      <td>78135</td>\n",
       "      <td>158790</td>\n",
       "      <td>1</td>\n",
       "      <td>291294</td>\n",
       "      <td>2024-05-22 12:38:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111294 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shopUserId  orderId  quantity groupId              created\n",
       "0           812427   785001         1  261873  2025-08-05 20:14:28\n",
       "1           831360   784985         4  261745  2025-08-05 19:55:36\n",
       "8           230625   784973         1  260951  2025-08-05 19:39:49\n",
       "9           230625   784973         1  590833  2025-08-05 19:39:49\n",
       "10          230625   784973         1  260141  2025-08-05 19:39:49\n",
       "...            ...      ...       ...     ...                  ...\n",
       "250024       78202   158870         1  221416  2024-05-22 14:18:16\n",
       "250026       78181   158841         1  265843  2024-05-22 13:42:39\n",
       "250038       78145   158800         1  261518  2024-05-22 12:54:51\n",
       "250039       78136   158791         1  542087  2024-05-22 12:44:01\n",
       "250040       78135   158790         1  291294  2024-05-22 12:38:29\n",
       "\n",
       "[111294 rows x 5 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = ['shopUserId', 'orderId', 'quantity', 'groupId', 'created']\n",
    "tx = pd.read_csv('../../../data/processed//transactions_clean.csv', usecols=cols + ['status'], low_memory=False)\n",
    "tx = tx[tx['status'] == 'active'][cols].astype({'quantity': int})\n",
    "\n",
    "# --- remove top-occurring groupIds and save them separately ---\n",
    "HEAD_FRAC = 0.01  # top 1% (tune) or set HEAD_TOPN instead\n",
    "cnt = tx.groupby('groupId')['orderId'].nunique()  # occurrences by distinct orders\n",
    "head_ids = cnt.sort_values(ascending=False).index[:max(5, int(len(cnt)*HEAD_FRAC))]\n",
    "\n",
    "head_df = tx[tx['groupId'].isin(head_ids)].copy()     # saved popular items\n",
    "tx = tx[~tx['groupId'].isin(head_ids)].copy()\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a977bee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['261637', '240187', '260646', '210338', '241562', '260596', '260513',\n",
       "       '260695', '242024', '265298', '210186'],\n",
       "      dtype='object', name='groupId')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e50dc8",
   "metadata": {},
   "source": [
    "### one row = one order, with items (list), quantities, created, n_items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "65dd9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Parse timestamp\n",
    "tx['created'] = pd.to_datetime(tx['created'], errors='coerce')  # add utc=True if you know tz\n",
    "\n",
    "# 2) Drop exact duplicate rows\n",
    "tx = tx.drop_duplicates(['orderId', 'groupId', 'created'])\n",
    "\n",
    "# 3) Sort by order then timestamp; tie-break by groupId to keep it deterministic\n",
    "tx = tx.sort_values(['orderId', 'created', 'groupId'])\n",
    "\n",
    "baskets = (\n",
    "    tx\n",
    "      .groupby(['orderId', 'shopUserId'], sort=False)\n",
    "      .agg(\n",
    "          created=('created', 'min'),\n",
    "          items=('groupId', list),\n",
    "          quantities=('quantity', list),\n",
    "          n_items=('groupId', 'size')\n",
    "      )\n",
    "      .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8fc50977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time-based split + dedupe items per order\n",
    "baskets = baskets.sort_values(['created','orderId']).reset_index(drop=True)\n",
    "split = int(len(baskets)*0.75)\n",
    "train = baskets.iloc[:split].copy()\n",
    "test  = baskets.iloc[split:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3cf7caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce binary per order\n",
    "train['items'] = train['items'].apply(lambda xs: sorted(set(xs)))\n",
    "test['items']  = test['items'].apply(lambda xs: sorted(set(xs)))\n",
    "\n",
    "# ignore quantities\n",
    "train = train.drop(columns=['quantities'], errors='ignore')\n",
    "test  = test.drop(columns=['quantities'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c0846",
   "metadata": {},
   "source": [
    "Produce co-occurrence counts to later convert into BM25/TF-IDF cosine, Jaccard, or lift, then apply shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "57f09856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next: co-occurrence counts (for item–item CF)\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "co = Counter()\n",
    "for items in train['items']:\n",
    "    for a,b in combinations(items, 2):\n",
    "        co[(a,b)] += 1 # of train orders containing both a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c061f1d",
   "metadata": {},
   "source": [
    "turn co into a weighted cosine similarity with lift, built on TRAIN-only item frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "575e00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace your cos/lift block with this BM25-weighted cosine + shrinkage\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "import math\n",
    "\n",
    "# binary popularity\n",
    "ni = Counter(i for xs in train['items'] for i in xs)\n",
    "\n",
    "ranked = [i for i, _ in ni.most_common()]        # global popularity order\n",
    "head_skip = max(5, int(0.02 * len(ranked)))      # skip ultra-head (top ~2%)\n",
    "\n",
    "bm25_pop = ranked[head_skip: head_skip + 1000]   # big cap, de-hot head\n",
    "\n",
    "# same category popularity\n",
    "PER_PREFIX_CAP = 20\n",
    "bm25_pop_by_prefix = defaultdict(list)\n",
    "for i in ranked[head_skip:]:\n",
    "    p = str(i)[:2]\n",
    "    if len(bm25_pop_by_prefix[p]) < PER_PREFIX_CAP:\n",
    "        bm25_pop_by_prefix[p].append(i)\n",
    "\n",
    "N  = len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dcabe429",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1, B = 1.2, 0.5\n",
    "alpha = 50  \n",
    "\n",
    "# IDF and avg doc length\n",
    "idf = {i: max(0.0, math.log((N - df + 0.5) / (df + 0.5))) for i, df in ni.items()}\n",
    "avgdl = (sum(len(set(xs)) for xs in train['items']) / N) if N else 0.0\n",
    "\n",
    "# Accumulators\n",
    "num = defaultdict(float)   # BM25-weighted dot products\n",
    "norm = defaultdict(float)  # per-item squared norms\n",
    "co   = Counter()           # binary co-occurrence counts (for shrinkage)\n",
    "\n",
    "for xs in train['items']:\n",
    "    items = sorted(set(xs))\n",
    "    dl = len(items)\n",
    "    denom = K1 * (1.0 - B + B * (dl / (avgdl + 1e-12)))\n",
    "    # tf=1 for presence; BM25 weight per item in this order\n",
    "    w = {i: idf.get(i, 0.0) * ((1.0 * (K1 + 1.0)) / (1.0 + denom)) for i in items}\n",
    "\n",
    "    for i, wi in w.items():\n",
    "        norm[i] += wi * wi\n",
    "    for a, b in combinations(items, 2):\n",
    "        wa, wb = w[a], w[b]\n",
    "        if wa == 0.0 or wb == 0.0:\n",
    "            continue\n",
    "        num[(a, b)] += wa * wb\n",
    "        num[(b, a)] += wa * wb\n",
    "        co[(a, b)]  += 1\n",
    "        co[(b, a)]  += 1\n",
    "\n",
    "# Final similarities with significance shrinkage\n",
    "sim = defaultdict(float)\n",
    "for (i, j), n in num.items():\n",
    "    s = n / (math.sqrt(norm[i]) * math.sqrt(norm[j]) + 1e-12)\n",
    "    c = co[(i, j)]\n",
    "    s *= (c / (c + alpha))          # shrinkage\n",
    "    sim[(i, j)] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "22870700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build per-item top BM25 neighbors (from sim) for scoring\n",
    "from collections import defaultdict\n",
    "bm25_nbrs = defaultdict(list)\n",
    "for (i, j), s in sim.items():\n",
    "    bm25_nbrs[i].append((j, s))\n",
    "for i in list(bm25_nbrs):\n",
    "    bm25_nbrs[i].sort(key=lambda x: x[1], reverse=True)\n",
    "    bm25_nbrs[i] = [j for j, _ in bm25_nbrs[i][:100]]  # cap neighbors\n",
    "\n",
    "# Popularity fallback (TRAIN)\n",
    "bm25_pop = [i for i, _ in ni.most_common(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0210b2",
   "metadata": {},
   "source": [
    "eval_df is a filtered view of TEST: keep TEST orders with ≥2 items and add (context, target) by hiding one item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7bb661c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_eval: 5983\n",
      "catalog coverage: 584 of 1003 (58.2%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare eval_df (binary, hide-1 on TEST)\n",
    "import numpy as np\n",
    "\n",
    "# binary per order\n",
    "test['items'] = test['items'].apply(lambda xs: sorted(set(xs)))\n",
    "\n",
    "# keep baskets with ≥2 items\n",
    "eval_df = test[test['items'].str.len().ge(2)].copy()\n",
    "\n",
    "# hide one item\n",
    "rng = np.random.default_rng(42)\n",
    "eval_df['target']  = eval_df['items'].apply(lambda xs: rng.choice(xs))\n",
    "eval_df['context'] = eval_df.apply(lambda r: [i for i in r['items'] if i != r['target']], axis=1)\n",
    "\n",
    "# Filter out rows where the hidden target is not in ni (i.e., not in train set)\n",
    "eval_df = eval_df[eval_df['target'].apply(lambda t: t in ni)]\n",
    "\n",
    "# Report n_eval and catalog coverage\n",
    "n_eval = len(eval_df)\n",
    "unique_targets = set(eval_df['target'])\n",
    "catalog_covered = len(unique_targets)\n",
    "catalog_total = len(ni)\n",
    "catalog_coverage = catalog_covered / catalog_total if catalog_total > 0 else 0.0\n",
    "\n",
    "print(f\"n_eval: {n_eval}\")\n",
    "print(f\"catalog coverage: {catalog_covered} of {catalog_total} ({catalog_coverage:.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcabfb",
   "metadata": {},
   "source": [
    "* For a basket’s current items (“context”), score other items by how similar they are to any item in the basket.\n",
    "* Sum those scores, take the top-10 as recs, and if fewer than 10, fill with popular items.\n",
    "* For evaluation, hide one item from each test basket and check if that hidden item appears in the top-10.\n",
    "* The final number is the fraction of baskets where we “hit” the hidden item — **HitRate\\@10**. 20% of recs had the actual item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f1db52be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2619087414340632"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed-K=10 eval (hide-1)\n",
    "def recommend10(ctx, per_anchor=10):\n",
    "    scores = {}\n",
    "    for a in ctx:\n",
    "        for pair in bm25_nbrs.get(a, [])[:per_anchor]:\n",
    "            if isinstance(pair, tuple):\n",
    "                b, s = pair\n",
    "            else:  # ID-only\n",
    "                b, s = pair, sim.get((a, pair), 0.0)\n",
    "            if b not in ctx:\n",
    "                scores[b] = scores.get(b, 0.0) + s\n",
    "    recs = [i for i, _ in sorted(scores.items(), key=lambda x: (-x[1], x[0]))[:10]]\n",
    "    recs += [i for i in bm25_pop if i not in ctx and i not in recs]\n",
    "    return recs[:10]\n",
    "\n",
    "\n",
    "hits = 0\n",
    "for _, r in eval_df.iterrows():\n",
    "    hits += int(r['target'] in recommend10(r['context']))\n",
    "hr10_cf = hits / len(eval_df)\n",
    "hr10_cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ed92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HR@10_CF+CAT': 0.2547217115159619}\n"
     ]
    }
   ],
   "source": [
    "# --- CF → category-pop only (no global pop); keep only truly similar CF (min_sim) ---\n",
    "\n",
    "MIN_SIM = 1e-3  # set on TRAIN only (e.g., 0.01)\n",
    "# assumes: bm25_nbrs, sim, bm25_pop_by_prefix (built on TRAIN), train, eval_df\n",
    "\n",
    "def recommend10_hybrid(ctx, topk=10, per_anchor=None, min_sim=MIN_SIM):\n",
    "    Z = max(1, len(ctx))\n",
    "    scores, source = {}, {}\n",
    "\n",
    "    # 1) CF scoring (only truly similar: s >= min_sim)\n",
    "    for a in ctx:\n",
    "        nbrs = bm25_nbrs.get(a, [])\n",
    "        if per_anchor is not None:\n",
    "            nbrs = nbrs[:per_anchor]\n",
    "        for pair in nbrs:\n",
    "            b, s = pair if isinstance(pair, tuple) else (pair, sim.get((a, pair), 0.0))\n",
    "            if b in ctx or s < min_sim:\n",
    "                continue\n",
    "            scores[b] = scores.get(b, 0.0) + s / Z\n",
    "            source.setdefault(b, \"CF\")\n",
    "\n",
    "    # ranked CF list\n",
    "    recs = [i for i, _ in sorted(scores.items(), key=lambda x: (-x[1], x[0]))]\n",
    "\n",
    "    # 2) Fill only with category popularity (prefix buckets), no global fallback\n",
    "    if len(recs) < topk:\n",
    "        for p in dict.fromkeys(str(a)[:2] for a in ctx):  # prefixes from context\n",
    "            for i in bm25_pop_by_prefix.get(p, []):\n",
    "                if i in ctx or i in scores or i in recs:\n",
    "                    continue\n",
    "                recs.append(i)\n",
    "                source.setdefault(i, \"POP(cat)\")\n",
    "                if len(recs) >= topk:\n",
    "                    break\n",
    "            if len(recs) >= topk:\n",
    "                break\n",
    "\n",
    "    return recs[:topk], scores, source  # may be < topk if category list is short\n",
    "\n",
    "# --- evaluation (HR@10; skips cold targets). Note: if recs < 10, it's still counted fairly. ---\n",
    "train_items = set(i for xs in train['items'] for i in xs)\n",
    "hits = n_eval = 0\n",
    "for _, r in eval_df.iterrows():\n",
    "    tgt = r['target']\n",
    "    if tgt not in train_items:\n",
    "        continue\n",
    "    recs, _, _ = recommend10_hybrid(r['context'], topk=10, per_anchor=10)\n",
    "    hits += int(tgt in recs)\n",
    "    n_eval += 1\n",
    "\n",
    "hr10_hybrid = hits / n_eval if n_eval else float('nan')\n",
    "print({'HR@10_hybrid': hr10_hybrid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6a27a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDER 666848  target=291294  context=['293068']\n",
      "candidate  cf_score top_anchor   source  pop_score   hit\n",
      "   290149  0.017009     293068       CF   0.815414 False\n",
      "   290246  0.004078     293068       CF   0.731679 False\n",
      "   290232  0.003606     293068       CF   0.820855 False\n",
      "   291294  0.002859     293068       CF   0.780187  True\n",
      "   290181  0.002447     293068       CF   0.685317 False\n",
      "   503373  0.001023     293068       CF   0.737852 False\n",
      "   294090  0.000000            POP(cat)   0.930634 False\n",
      "   291195  0.000000            POP(cat)   0.913313 False\n",
      "   291088  0.000000            POP(cat)   0.899649 False\n",
      "   291054  0.000000            POP(cat)   0.885796 False\n",
      "\n",
      "ORDER 716963  target=270599  context=['241091']\n",
      "candidate  cf_score top_anchor source  pop_score   hit\n",
      "   241687  0.009540     241091     CF   0.924143 False\n",
      "   240012  0.008045     241091     CF   0.754928 False\n",
      "   241653  0.004882     241091     CF   0.816918 False\n",
      "   221416  0.004426     241091     CF   0.845349 False\n",
      "   240184  0.002632     241091     CF   0.983701 False\n",
      "   200304  0.002283     241091     CF   1.000000 False\n",
      "   210754  0.001924     241091     CF   0.753386 False\n",
      "   266643  0.001629     241091     CF   0.909951 False\n",
      "   260079  0.001267     241091     CF   0.299789 False\n",
      "   281410  0.001130     241091     CF   0.793694 False\n",
      "\n",
      "ORDER 681297  target=541321  context=['242305']\n",
      "candidate  cf_score top_anchor source  pop_score   hit\n",
      "   200400  0.003735     242305     CF   0.992966 False\n",
      "   242198  0.003646     242305     CF   0.870813 False\n",
      "   218982  0.003590     242305     CF   0.980047 False\n",
      "   241653  0.003192     242305     CF   0.816918 False\n",
      "   240184  0.002525     242305     CF   0.983701 False\n",
      "   265249  0.001753     242305     CF   0.935537 False\n",
      "   261699  0.001659     242305     CF   0.948919 False\n",
      "   250125  0.001546     242305     CF   0.808707 False\n",
      "   241208  0.001539     242305     CF   0.808178 False\n",
      "   210756  0.001441     242305     CF   0.826565 False\n",
      "\n",
      "ORDER 678203  target=260949  context=['210695']\n",
      "candidate  cf_score top_anchor source  pop_score   hit\n",
      "   265041  0.011743     210695     CF   0.999579 False\n",
      "   200400  0.011144     210695     CF   0.992966 False\n",
      "   260224  0.006516     210695     CF   0.852149 False\n",
      "   240184  0.005922     210695     CF   0.983701 False\n",
      "   261436  0.004939     210695     CF   0.934216 False\n",
      "   260931  0.003821     210695     CF   0.886105 False\n",
      "   240144  0.003290     210695     CF   0.865925 False\n",
      "   261699  0.003189     210695     CF   0.948919 False\n",
      "   261888  0.003055     210695     CF   0.795441 False\n",
      "   240181  0.002977     210695     CF   0.800560 False\n",
      "\n",
      "ORDER 707113  target=270597  context=['260973', '263855']\n",
      "candidate  cf_score top_anchor source  pop_score   hit\n",
      "   264804  0.010742     263855     CF   0.933329 False\n",
      "   265843  0.003793     263855     CF   0.954596 False\n",
      "   264614  0.003698     263855     CF   0.676343 False\n",
      "   266072  0.002783     263855     CF   0.841615 False\n",
      "   261610  0.002752     260973     CF   0.976957 False\n",
      "   264473  0.002745     263855     CF   0.569644 False\n",
      "   261427  0.002331     260973     CF   0.935974 False\n",
      "   261595  0.001717     260973     CF   0.965499 False\n",
      "   264549  0.001508     263855     CF   0.669573 False\n",
      "   260313  0.001456     263855     CF   0.898804 False\n"
     ]
    }
   ],
   "source": [
    "# --- one-time (before visualize_one) ---\n",
    "import math\n",
    "from collections import Counter\n",
    "ni = Counter(i for xs in train['items'] for i in xs)   # TRAIN-only doc freq\n",
    "_max = max(ni.values()) if ni else 1\n",
    "pop_score = {i: math.log1p(ni[i]) / math.log1p(_max) for i in ni}  # ∈ [0,1]\n",
    "\n",
    "# --- visualizer (aligned with recommend10_hybrid) ---\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def visualize_one(r, topk=10, per_anchor=10, min_sim=MIN_SIM):\n",
    "    ctx, tgt = r['context'], r['target']\n",
    "    recs, scores, source = recommend10_hybrid(ctx, topk=topk, per_anchor=per_anchor, min_sim=min_sim)\n",
    "    Z = max(1, len(ctx))\n",
    "    rows = []\n",
    "    for i in recs:\n",
    "        if source.get(i) == \"CF\":\n",
    "            contrib = [(a, sim.get((a,i), 0.0)/Z) for a in ctx if sim.get((a,i), 0.0) >= min_sim]\n",
    "            ta = max(contrib, key=lambda x: x[1])[0] if contrib else \"\"\n",
    "        else:\n",
    "            ta = \"\"  # POP(cat)\n",
    "        rows.append((i, scores.get(i, 0.0), ta, source.get(i, \"POP(cat)\"), pop_score.get(i, 0.0)))\n",
    "    df = pd.DataFrame(rows, columns=[\"candidate\",\"cf_score\",\"top_anchor\",\"source\",\"pop_score\"])\n",
    "    df[\"hit\"] = df[\"candidate\"].eq(tgt)\n",
    "    return df\n",
    "\n",
    "# Example\n",
    "rng = np.random.default_rng()\n",
    "for idx in rng.choice(eval_df.index, size=min(5, len(eval_df)), replace=False):\n",
    "    r = eval_df.loc[idx]\n",
    "    print(f\"\\nORDER {r.get('orderId', idx)}  target={r['target']}  context={r['context']}\")\n",
    "    print(visualize_one(r).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86656276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc94d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
