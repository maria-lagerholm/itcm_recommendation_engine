{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6015605",
   "metadata": {},
   "source": [
    "# item–item KNN CF using BM25‑weighted cosine + shrinkage, evaluated by leave‑one‑out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3551e",
   "metadata": {},
   "source": [
    "1. Split by order time, not by (user, item) rows. Example: sort orders by order_timestamp, use first 80% of orders as train, last 20% as test (or a rolling window).\n",
    "  a. Deduplicate within order: treat (order, item) as binary; handle quantities separately only if needed.\n",
    "  \n",
    "  b. Cold items (seen only in test) can’t be recommended; track coverage. Backfill with category/popularity.\n",
    "  c. Build matrices on TRAIN ONLY\n",
    "\n",
    "\n",
    "2. For each test order with ≥2 items, randomly hide 1 item and predict it from the remaining items in the same basket.\n",
    "  a. Very popular items dominate cosine; use BM25/TF‑IDF or lift to reduce popularity bias.\n",
    "  b. Shrinkage is essential for long‑tail items.\n",
    "  c. For your “basket-aware” scenario, CF (item2vec/ALS) captures co-purchase complements well. But start with item-item CF (BM25-weighted cosine + shrinkage). Simple, strong, fast.\n",
    "3. Use implicit feedback techniques (co‑occurrence, cosine/Jaccard/lift, BM25/TF‑IDF weighting, shrinkage) and add fallbacks (popularity, category‑aware) for baskets with too little context. Report HitRate@K / Recall@K / NDCG@K. (With one hidden item, HitRate@K = Recall@K.) To capture richer relations or to unify with next-order personalization later: train Item2vec or ALS; at serve time you can:\n",
    "- do basket averaging (Item2vec) or fold-in (ALS) for context-aware recs, or\n",
    "- precompute top-K neighbors per item from embeddings and serve like item-item CF.\n",
    "\n",
    "If you split items from the same order across train and test, you’ll artificially inflate results.\n",
    "Filters at serve time: availability, price range, category blacklists, etc.\n",
    "\n",
    "for basket completion, both Item2vec and ALS work without historical user data by using the current cart as context. For home-page personalization with no context, you’ll need past interactions (ALS) or rely on non-CF signals (popularity/content)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "51bd3eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shopUserId</th>\n",
       "      <th>orderId</th>\n",
       "      <th>quantity</th>\n",
       "      <th>groupId</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>812427</td>\n",
       "      <td>785001</td>\n",
       "      <td>1</td>\n",
       "      <td>261873</td>\n",
       "      <td>2025-08-05 20:14:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>831360</td>\n",
       "      <td>784985</td>\n",
       "      <td>4</td>\n",
       "      <td>261745</td>\n",
       "      <td>2025-08-05 19:55:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>230625</td>\n",
       "      <td>784973</td>\n",
       "      <td>1</td>\n",
       "      <td>260951</td>\n",
       "      <td>2025-08-05 19:39:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>230625</td>\n",
       "      <td>784973</td>\n",
       "      <td>1</td>\n",
       "      <td>590833</td>\n",
       "      <td>2025-08-05 19:39:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>230625</td>\n",
       "      <td>784973</td>\n",
       "      <td>1</td>\n",
       "      <td>260141</td>\n",
       "      <td>2025-08-05 19:39:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250024</th>\n",
       "      <td>78202</td>\n",
       "      <td>158870</td>\n",
       "      <td>1</td>\n",
       "      <td>221416</td>\n",
       "      <td>2024-05-22 14:18:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250026</th>\n",
       "      <td>78181</td>\n",
       "      <td>158841</td>\n",
       "      <td>1</td>\n",
       "      <td>265843</td>\n",
       "      <td>2024-05-22 13:42:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250038</th>\n",
       "      <td>78145</td>\n",
       "      <td>158800</td>\n",
       "      <td>1</td>\n",
       "      <td>261518</td>\n",
       "      <td>2024-05-22 12:54:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250039</th>\n",
       "      <td>78136</td>\n",
       "      <td>158791</td>\n",
       "      <td>1</td>\n",
       "      <td>542087</td>\n",
       "      <td>2024-05-22 12:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250040</th>\n",
       "      <td>78135</td>\n",
       "      <td>158790</td>\n",
       "      <td>1</td>\n",
       "      <td>291294</td>\n",
       "      <td>2024-05-22 12:38:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111294 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shopUserId  orderId  quantity groupId              created\n",
       "0           812427   785001         1  261873  2025-08-05 20:14:28\n",
       "1           831360   784985         4  261745  2025-08-05 19:55:36\n",
       "8           230625   784973         1  260951  2025-08-05 19:39:49\n",
       "9           230625   784973         1  590833  2025-08-05 19:39:49\n",
       "10          230625   784973         1  260141  2025-08-05 19:39:49\n",
       "...            ...      ...       ...     ...                  ...\n",
       "250024       78202   158870         1  221416  2024-05-22 14:18:16\n",
       "250026       78181   158841         1  265843  2024-05-22 13:42:39\n",
       "250038       78145   158800         1  261518  2024-05-22 12:54:51\n",
       "250039       78136   158791         1  542087  2024-05-22 12:44:01\n",
       "250040       78135   158790         1  291294  2024-05-22 12:38:29\n",
       "\n",
       "[111294 rows x 5 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = ['shopUserId', 'orderId', 'quantity', 'groupId', 'created']\n",
    "tx = pd.read_csv('../../../data/processed//transactions_clean.csv', usecols=cols + ['status'], low_memory=False)\n",
    "tx = tx[tx['status'] == 'active'][cols].astype({'quantity': int})\n",
    "\n",
    "# --- remove top-occurring groupIds and save them separately ---\n",
    "HEAD_FRAC = 0.01  # top 1% (tune) or set HEAD_TOPN instead\n",
    "cnt = tx.groupby('groupId')['orderId'].nunique()  # occurrences by distinct orders\n",
    "head_ids = cnt.sort_values(ascending=False).index[:max(5, int(len(cnt)*HEAD_FRAC))]\n",
    "\n",
    "head_df = tx[tx['groupId'].isin(head_ids)].copy()     # saved popular items\n",
    "tx = tx[~tx['groupId'].isin(head_ids)].copy()\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a977bee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['261637', '240187', '260646', '210338', '241562', '260596', '260513',\n",
       "       '260695', '242024', '265298', '210186'],\n",
       "      dtype='object', name='groupId')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e50dc8",
   "metadata": {},
   "source": [
    "### one row = one order, with items (list), quantities, created, n_items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "65dd9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Parse timestamp\n",
    "tx['created'] = pd.to_datetime(tx['created'], errors='coerce')  # add utc=True if you know tz\n",
    "\n",
    "# 2) Drop exact duplicate rows\n",
    "tx = tx.drop_duplicates(['orderId', 'groupId', 'created'])\n",
    "\n",
    "# 3) Sort by order then timestamp; tie-break by groupId to keep it deterministic\n",
    "tx = tx.sort_values(['orderId', 'created', 'groupId'])\n",
    "\n",
    "baskets = (\n",
    "    tx\n",
    "      .groupby(['orderId', 'shopUserId'], sort=False)\n",
    "      .agg(\n",
    "          created=('created', 'min'),\n",
    "          items=('groupId', list),\n",
    "          quantities=('quantity', list),\n",
    "          n_items=('groupId', 'size')\n",
    "      )\n",
    "      .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8fc50977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time-based split + dedupe items per order\n",
    "baskets = baskets.sort_values(['created','orderId']).reset_index(drop=True)\n",
    "split = int(len(baskets)*0.8)\n",
    "train = baskets.iloc[:split].copy()\n",
    "test  = baskets.iloc[split:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3cf7caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce binary per order\n",
    "train['items'] = train['items'].apply(lambda xs: sorted(set(xs)))\n",
    "test['items']  = test['items'].apply(lambda xs: sorted(set(xs)))\n",
    "\n",
    "# ignore quantities\n",
    "train = train.drop(columns=['quantities'], errors='ignore')\n",
    "test  = test.drop(columns=['quantities'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c0846",
   "metadata": {},
   "source": [
    "Produce co-occurrence counts to later convert into BM25/TF-IDF cosine, Jaccard, or lift, then apply shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "57f09856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next: co-occurrence counts (for item–item CF)\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "co = Counter()\n",
    "for items in train['items']:\n",
    "    for a,b in combinations(items, 2):\n",
    "        co[(a,b)] += 4 # of train orders containing both a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c061f1d",
   "metadata": {},
   "source": [
    "turn co into a weighted cosine similarity with lift, built on TRAIN-only item frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "575e00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace your cos/lift block with this BM25-weighted cosine + shrinkage\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "import math\n",
    "\n",
    "# binary popularity\n",
    "ni = Counter(i for xs in train['items'] for i in xs)\n",
    "\n",
    "ranked = [i for i, _ in ni.most_common()]        # global popularity order\n",
    "head_skip = max(5, int(0.02 * len(ranked)))      # skip ultra-head (top ~2%)\n",
    "\n",
    "bm25_pop = ranked[head_skip: head_skip + 1000]   # big cap, de-hot head\n",
    "\n",
    "# same category popularity\n",
    "PER_PREFIX_CAP = 20\n",
    "bm25_pop_by_prefix = defaultdict(list)\n",
    "for i in ranked[head_skip:]:\n",
    "    p = str(i)[:2]\n",
    "    if len(bm25_pop_by_prefix[p]) < PER_PREFIX_CAP:\n",
    "        bm25_pop_by_prefix[p].append(i)\n",
    "\n",
    "N  = len(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93989b8",
   "metadata": {},
   "source": [
    "To de-bias popularity and basket-length effects: we BM25-weight item presence (via K1,B,idf), compute cosine in that weighted space (num/norm), and apply shrinkage by co-occurrence count (alpha) to down-weight noisy rare pairs.\n",
    "\n",
    "K1 (≈0.8–1.6) —how fast extra occurrences stop adding weight (with binary baskets it mainly scales scores).\n",
    "B (0–1) controls length normalization—how strongly you adjust for basket length (0 = none, 1 = full normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "dcabe429",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1, B = 1.2, 0.5\n",
    "alpha = 50  \n",
    "\n",
    "# IDF and avg doc length\n",
    "idf = {i: max(0.0, math.log((N - df + 0.5) / (df + 0.5))) for i, df in ni.items()}\n",
    "avgdl = (sum(len(set(xs)) for xs in train['items']) / N) if N else 0.0\n",
    "\n",
    "# Accumulators\n",
    "num = defaultdict(float)   # BM25-weighted dot products\n",
    "norm = defaultdict(float)  # per-item squared norms\n",
    "co   = Counter()           # binary co-occurrence counts (for shrinkage)\n",
    "\n",
    "for xs in train['items']:\n",
    "    items = sorted(set(xs))\n",
    "    dl = len(items)\n",
    "    denom = K1 * (1.0 - B + B * (dl / (avgdl + 1e-12)))\n",
    "    # tf=1 for presence; BM25 weight per item in this order\n",
    "    w = {i: idf.get(i, 0.0) * ((1.0 * (K1 + 1.0)) / (1.0 + denom)) for i in items}\n",
    "\n",
    "    for i, wi in w.items():\n",
    "        norm[i] += wi * wi\n",
    "    for a, b in combinations(items, 2):\n",
    "        wa, wb = w[a], w[b]\n",
    "        if wa == 0.0 or wb == 0.0:\n",
    "            continue\n",
    "        num[(a, b)] += wa * wb\n",
    "        num[(b, a)] += wa * wb\n",
    "        co[(a, b)]  += 1\n",
    "        co[(b, a)]  += 1\n",
    "\n",
    "# Final similarities with significance shrinkage\n",
    "sim = defaultdict(float)\n",
    "for (i, j), n in num.items():\n",
    "    s = n / (math.sqrt(norm[i]) * math.sqrt(norm[j]) + 1e-12)\n",
    "    c = co[(i, j)]\n",
    "    s *= (c / (c + alpha))          # shrinkage\n",
    "    sim[(i, j)] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "22870700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build per-item top BM25 neighbors (from sim) for scoring\n",
    "from collections import defaultdict\n",
    "bm25_nbrs = defaultdict(list)\n",
    "for (i, j), s in sim.items():\n",
    "    bm25_nbrs[i].append((j, s))\n",
    "for i in list(bm25_nbrs):\n",
    "    bm25_nbrs[i].sort(key=lambda x: x[1], reverse=True)\n",
    "    bm25_nbrs[i] = [j for j, _ in bm25_nbrs[i][:50]]  # cap neighbors\n",
    "\n",
    "# Popularity fallback (TRAIN)\n",
    "bm25_pop = [i for i, _ in ni.most_common(50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0210b2",
   "metadata": {},
   "source": [
    "eval_df is a filtered view of TEST: keep TEST orders with ≥2 items and add (context, target) by hiding one item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7bb661c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_eval: 4781\n",
      "catalog coverage: 543 of 1020 (53.2%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare eval_df (binary, hide-1 on TEST)\n",
    "import numpy as np\n",
    "\n",
    "# binary per order\n",
    "test['items'] = test['items'].apply(lambda xs: sorted(set(xs)))\n",
    "\n",
    "# keep baskets with ≥2 items\n",
    "eval_df = test[test['items'].str.len().ge(2)].copy()\n",
    "\n",
    "# hide one item\n",
    "rng = np.random.default_rng(42)\n",
    "eval_df['target']  = eval_df['items'].apply(lambda xs: rng.choice(xs))\n",
    "eval_df['context'] = eval_df.apply(lambda r: [i for i in r['items'] if i != r['target']], axis=1)\n",
    "\n",
    "# Filter out rows where the hidden target is not in ni (i.e., not in train set)\n",
    "eval_df = eval_df[eval_df['target'].apply(lambda t: t in ni)]\n",
    "\n",
    "# Report n_eval and catalog coverage\n",
    "n_eval = len(eval_df)\n",
    "unique_targets = set(eval_df['target'])\n",
    "catalog_covered = len(unique_targets)\n",
    "catalog_total = len(ni)\n",
    "catalog_coverage = catalog_covered / catalog_total if catalog_total > 0 else 0.0\n",
    "\n",
    "print(f\"n_eval: {n_eval}\")\n",
    "print(f\"catalog coverage: {catalog_covered} of {catalog_total} ({catalog_coverage:.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcabfb",
   "metadata": {},
   "source": [
    "* For a basket’s current items (“context”), score other items by how similar they are to any item in the basket.\n",
    "* Sum those scores, take the top-10 as recs, and if fewer than 10, fill with popular items.\n",
    "* For evaluation, hide one item from each test basket and check if that hidden item appears in the top-10.\n",
    "* The final number is the fraction of baskets where we “hit” the hidden item — **HitRate\\@10**. 20% of recs had the actual item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f1db52be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2568500313741895"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed-K=10 eval (hide-1)\n",
    "def recommend10(ctx, per_anchor=10):\n",
    "    scores = {}\n",
    "    for a in ctx:\n",
    "        for pair in bm25_nbrs.get(a, [])[:per_anchor]:\n",
    "            if isinstance(pair, tuple):\n",
    "                b, s = pair\n",
    "            else:  # ID-only\n",
    "                b, s = pair, sim.get((a, pair), 0.0)\n",
    "            if b not in ctx:\n",
    "                scores[b] = scores.get(b, 0.0) + s\n",
    "    recs = [i for i, _ in sorted(scores.items(), key=lambda x: (-x[1], x[0]))[:10]]\n",
    "    recs += [i for i in bm25_pop if i not in ctx and i not in recs]\n",
    "    return recs[:10]\n",
    "\n",
    "\n",
    "hits = 0\n",
    "for _, r in eval_df.iterrows():\n",
    "    hits += int(r['target'] in recommend10(r['context']))\n",
    "hr10_cf = hits / len(eval_df)\n",
    "hr10_cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "187ed92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HR@10_hybrid': 0.25664087011085546}\n"
     ]
    }
   ],
   "source": [
    "# --- CF → category-pop only (no global pop); keep only truly similar CF (min_sim) ---\n",
    "\n",
    "MIN_SIM = 1e-3  # set on TRAIN only (e.g., 0.01)\n",
    "# assumes: bm25_nbrs, sim, bm25_pop_by_prefix (built on TRAIN), train, eval_df\n",
    "\n",
    "def recommend10_hybrid(ctx, topk=10, per_anchor=None, min_sim=MIN_SIM):\n",
    "    Z = max(1, len(ctx))\n",
    "    scores, source = {}, {}\n",
    "\n",
    "    # 1) CF scoring (only truly similar: s >= min_sim)\n",
    "    for a in ctx:\n",
    "        nbrs = bm25_nbrs.get(a, [])\n",
    "        if per_anchor is not None:\n",
    "            nbrs = nbrs[:per_anchor]\n",
    "        for pair in nbrs:\n",
    "            b, s = pair if isinstance(pair, tuple) else (pair, sim.get((a, pair), 0.0))\n",
    "            if b in ctx or s < min_sim:\n",
    "                continue\n",
    "            scores[b] = scores.get(b, 0.0) + s / Z\n",
    "            source.setdefault(b, \"CF\")\n",
    "\n",
    "    # ranked CF list\n",
    "    recs = [i for i, _ in sorted(scores.items(), key=lambda x: (-x[1], x[0]))]\n",
    "\n",
    "    # 2) Fill only with category popularity (prefix buckets), no global fallback\n",
    "    if len(recs) < topk:\n",
    "        for p in dict.fromkeys(str(a)[:2] for a in ctx):  # prefixes from context\n",
    "            for i in bm25_pop_by_prefix.get(p, []):\n",
    "                if i in ctx or i in scores or i in recs:\n",
    "                    continue\n",
    "                recs.append(i)\n",
    "                source.setdefault(i, \"POP(cat)\")\n",
    "                if len(recs) >= topk:\n",
    "                    break\n",
    "            if len(recs) >= topk:\n",
    "                break\n",
    "\n",
    "    return recs[:topk], scores, source  # may be < topk if category list is short\n",
    "\n",
    "# --- evaluation (HR@10; skips cold targets). Note: if recs < 10, it's still counted fairly. ---\n",
    "train_items = set(i for xs in train['items'] for i in xs)\n",
    "hits = n_eval = 0\n",
    "for _, r in eval_df.iterrows():\n",
    "    tgt = r['target']\n",
    "    if tgt not in train_items:\n",
    "        continue\n",
    "    recs, _, _ = recommend10_hybrid(r['context'], topk=10, per_anchor=10)\n",
    "    hits += int(tgt in recs)\n",
    "    n_eval += 1\n",
    "\n",
    "hr10_hybrid = hits / n_eval if n_eval else float('nan')\n",
    "print({'HR@10_hybrid': hr10_hybrid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6a27a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDER 779641  target=292250  context=['281410', '291120', '291625', '292607']\n",
      "candidate  cf_score top_anchor source  pop_score   hit\n",
      "   292789  0.052289     291120     CF   0.948478 False\n",
      "   292193  0.022584     291625     CF   0.850374 False\n",
      "   290291  0.007280     291120     CF   0.856368 False\n",
      "   290228  0.007118     291120     CF   0.865949 False\n",
      "   291088  0.006192     291120     CF   0.901357 False\n",
      "   291054  0.005961     291120     CF   0.885193 False\n",
      "   290290  0.005374     291120     CF   0.853776 False\n",
      "   294090  0.002361     291120     CF   0.931265 False\n",
      "   200304  0.001958     281410     CF   0.999324 False\n",
      "   291612  0.001569     291625     CF   0.564124 False\n",
      "\n",
      "ORDER 741446  target=200304  context=['270600']\n",
      "candidate  cf_score top_anchor   source  pop_score   hit\n",
      "   270599  0.002415     270600       CF   0.743463 False\n",
      "   210756  0.001759     270600       CF   0.844517 False\n",
      "   270597  0.001681     270600       CF   0.787533 False\n",
      "   270593  0.001425     270600       CF   0.844517 False\n",
      "   292250  0.001210     270600       CF   0.889335 False\n",
      "   241091  0.001078     270600       CF   0.901088 False\n",
      "   261427  0.001056     270600       CF   0.940334 False\n",
      "   270312  0.000000            POP(cat)   0.813494 False\n",
      "   270596  0.000000            POP(cat)   0.807946 False\n",
      "   270452  0.000000            POP(cat)   0.785743 False\n",
      "\n",
      "ORDER 767099  target=542087  context=['544976']\n",
      "candidate  cf_score top_anchor   source  pop_score   hit\n",
      "   546181       0.0            POP(cat)   0.751305 False\n",
      "   549005       0.0            POP(cat)   0.635717 False\n",
      "   542087       0.0            POP(cat)   0.603274  True\n",
      "   549999       0.0            POP(cat)   0.592146 False\n",
      "   543163       0.0            POP(cat)   0.536267 False\n",
      "   545906       0.0            POP(cat)   0.521908 False\n",
      "   546180       0.0            POP(cat)   0.505949 False\n",
      "   544920       0.0            POP(cat)   0.467460 False\n",
      "   544482       0.0            POP(cat)   0.461832 False\n",
      "   544806       0.0            POP(cat)   0.449869 False\n",
      "\n",
      "ORDER 752532  target=292359  context=['292367']\n",
      "candidate  cf_score top_anchor source  pop_score   hit\n",
      "   292359  0.045283     292367     CF   0.667733  True\n",
      "   290965  0.010435     292367     CF   0.765810 False\n",
      "   291229  0.006298     292367     CF   0.670440 False\n",
      "   292375  0.005048     292367     CF   0.650321 False\n",
      "   290143  0.003942     292367     CF   0.728167 False\n",
      "   290182  0.003647     292367     CF   0.574957 False\n",
      "   290303  0.002844     292367     CF   0.749771 False\n",
      "   290011  0.002236     292367     CF   0.761611 False\n",
      "   292771  0.001246     292367     CF   0.802709 False\n",
      "   290302  0.001084     292367     CF   0.414700 False\n",
      "\n",
      "ORDER 746148  target=261467  context=['261123']\n",
      "candidate  cf_score top_anchor   source  pop_score   hit\n",
      "   261864  0.002454     261123       CF   0.344041 False\n",
      "   261253  0.001170     261123       CF   0.572325 False\n",
      "   260965  0.001056     261123       CF   0.771225 False\n",
      "   265249  0.000000            POP(cat)   0.940946 False\n",
      "   261427  0.000000            POP(cat)   0.940334 False\n",
      "   264804  0.000000            POP(cat)   0.934281 False\n",
      "   261436  0.000000            POP(cat)   0.930172 False\n",
      "   261475  0.000000            POP(cat)   0.925716 False\n",
      "   260557  0.000000            POP(cat)   0.923894 False\n",
      "   264234  0.000000            POP(cat)   0.921351 False\n"
     ]
    }
   ],
   "source": [
    "# --- one-time (before visualize_one) ---\n",
    "import math\n",
    "from collections import Counter\n",
    "ni = Counter(i for xs in train['items'] for i in xs)   # TRAIN-only doc freq\n",
    "_max = max(ni.values()) if ni else 1\n",
    "pop_score = {i: math.log1p(ni[i]) / math.log1p(_max) for i in ni}  # ∈ [0,1]\n",
    "\n",
    "# --- visualizer (aligned with recommend10_hybrid) ---\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def visualize_one(r, topk=10, per_anchor=10, min_sim=MIN_SIM):\n",
    "    ctx, tgt = r['context'], r['target']\n",
    "    recs, scores, source = recommend10_hybrid(ctx, topk=topk, per_anchor=per_anchor, min_sim=min_sim)\n",
    "    Z = max(1, len(ctx))\n",
    "    rows = []\n",
    "    for i in recs:\n",
    "        if source.get(i) == \"CF\":\n",
    "            contrib = [(a, sim.get((a,i), 0.0)/Z) for a in ctx if sim.get((a,i), 0.0) >= min_sim]\n",
    "            ta = max(contrib, key=lambda x: x[1])[0] if contrib else \"\"\n",
    "        else:\n",
    "            ta = \"\"  # POP(cat)\n",
    "        rows.append((i, scores.get(i, 0.0), ta, source.get(i, \"POP(cat)\"), pop_score.get(i, 0.0)))\n",
    "    df = pd.DataFrame(rows, columns=[\"candidate\",\"cf_score\",\"top_anchor\",\"source\",\"pop_score\"])\n",
    "    df[\"hit\"] = df[\"candidate\"].eq(tgt)\n",
    "    return df\n",
    "\n",
    "# Example\n",
    "rng = np.random.default_rng()\n",
    "for idx in rng.choice(eval_df.index, size=min(5, len(eval_df)), replace=False):\n",
    "    r = eval_df.loc[idx]\n",
    "    print(f\"\\nORDER {r.get('orderId', idx)}  target={r['target']}  context={r['context']}\")\n",
    "    print(visualize_one(r).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86656276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc94d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
