{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "258afbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55a41d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_parquet(\n",
    "    \"/workspace/data/processed/articles_for_recs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0479d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 18 rows with priceSEK < 1\n"
     ]
    }
   ],
   "source": [
    "groups['priceSEK'] = pd.to_numeric(groups['priceSEK'], errors='coerce')\n",
    "before_count = len(groups)\n",
    "groups = groups[groups['priceSEK'] >= 1]\n",
    "after_count = len(groups)\n",
    "print(f\"Dropped {before_count - after_count} rows with priceSEK < 1\")\n",
    "\n",
    "if 'audienceId' in groups.columns:\n",
    "    groups = groups.drop(columns=['audienceId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae943454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MISSING = {\"\", \"unknown\", \"nan\", \"none\", None}\n",
    "\n",
    "def canon(s: str) -> str:\n",
    "    \"\"\"Normalize quotes, dashes, NBSP and whitespace; trim.\"\"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    s = re.sub(r\"\\u00A0\", \" \", s)                     # NBSP -> space\n",
    "    s = re.sub(r\"[\\u2010-\\u2015\\u2212\\-]+\", \"-\", s)   # hyphen family -> \"-\"\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def norm_categories(x):\n",
    "    \"\"\"Normalize, lowercase-dedupe (order-preserving), drop MISSING.\"\"\"\n",
    "    cats = [canon(c) for c in str(x).split(\",\") if str(c).strip() not in MISSING]\n",
    "    seen, out = set(), []\n",
    "    for c in cats:\n",
    "        key = c.lower()\n",
    "        if c and key not in seen:\n",
    "            seen.add(key)\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def short_desc(desc, max_words: int = 30):\n",
    "    \"\"\"Take the first sentence (if any) and cap at max_words.\"\"\"\n",
    "    if not desc:\n",
    "        return \"\"\n",
    "    first = re.split(r\"(?<=[.!?])\\s+\", desc)[0]\n",
    "    return \" \".join(first.split()[:max_words])\n",
    "\n",
    "def _split_multi(s: str, seps=\",/|;\"):\n",
    "    \"\"\"Split on any of the provided separators (regex-friendly), trimming whitespace.\"\"\"\n",
    "    # Build a character class from separators like \",/|;\" -> \"[,/|;]\"\n",
    "    pattern = r\"\\s*[\" + re.escape(seps) + r\"]\\s*\"\n",
    "    return re.split(pattern, s) if any(ch in s for ch in seps) else [s]\n",
    "\n",
    "def format_colors(col) -> str:\n",
    "    \"\"\"\n",
    "    Render colors as 'Svart, Grå' (no brackets). Accepts list/tuple/Series/ndarray\n",
    "    or strings like: \"['Svart' 'Grå']\", \"Grå,Svart\", \"Svart/Grå\".\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    if isinstance(col, (list, tuple, pd.Series, np.ndarray)):\n",
    "        seq = list(col)\n",
    "        for v in seq:\n",
    "            s = str(v).strip()\n",
    "            if not s or s.lower() in MISSING:\n",
    "                continue\n",
    "            parts = _split_multi(s, seps=\",/|;\")\n",
    "            vals.extend(parts)\n",
    "    else:\n",
    "        s = str(col).strip()\n",
    "        if s and s.lower() not in MISSING:\n",
    "            # handle quoted lists like \"['Svart' 'Grå']\" or '[\"Svart\",\"Grå\"]'\n",
    "            quoted = re.findall(r\"'([^']+)'|\\\"([^\\\"]+)\\\"\", s)\n",
    "            if quoted:\n",
    "                vals = [a or b for a, b in quoted]\n",
    "            else:\n",
    "                vals = _split_multi(s, seps=\",/|;\")\n",
    "\n",
    "    # order-preserving dedupe with normalization\n",
    "    out, seen = [], set()\n",
    "    for v in vals:\n",
    "        t = canon(v)\n",
    "        key = t.lower()\n",
    "        if t and key not in seen and key not in MISSING:\n",
    "            seen.add(key)\n",
    "            out.append(t)\n",
    "    return \", \".join(out)\n",
    "\n",
    "def format_sizes(sz) -> str:\n",
    "    \"\"\"\n",
    "    Render sizes as '36/38, 40/42' (no brackets).\n",
    "    Accepts list/tuple/Series/ndarray or strings like:\n",
    "    \"['36/38' '40/42']\", \"36/38,40/42\", \"36/38 | 40/42\".\n",
    "    NOTE: Do NOT split on '/' because '36/38' is a single size token.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    if isinstance(sz, (list, tuple, pd.Series, np.ndarray)):\n",
    "        for v in list(sz):\n",
    "            s = str(v).strip()\n",
    "            if not s or s.lower() in MISSING:\n",
    "                continue\n",
    "            parts = _split_multi(s, seps=\",|;\")  # no '/' here\n",
    "            vals.extend(parts)\n",
    "    else:\n",
    "        s = str(sz).strip()\n",
    "        if s and s.lower() not in MISSING:\n",
    "            quoted = re.findall(r\"'([^']+)'|\\\"([^\\\"]+)\\\"\", s)\n",
    "            if quoted:\n",
    "                vals = [a or b for a, b in quoted]\n",
    "            else:\n",
    "                vals = _split_multi(s, seps=\",|;\")  # no '/'\n",
    "\n",
    "    out, seen = [], set()\n",
    "    for v in vals:\n",
    "        t = canon(v)\n",
    "        key = t.lower()\n",
    "        if t and key not in seen and key not in MISSING:\n",
    "            seen.add(key)\n",
    "            out.append(t)\n",
    "    return \", \".join(out)\n",
    "\n",
    "def build_texts_for_ir(r):\n",
    "    \"\"\"\n",
    "    Create two strings:\n",
    "      - text_embed: compact, instruction-prefixed for embedding (\"passage: ...\")\n",
    "      - text_rerank: richer, for cross-encoder reranking\n",
    "    \"\"\"\n",
    "    name  = canon(r.get(\"name\", \"\"))\n",
    "    desc  = short_desc(canon(r.get(\"description\", \"\")), 30)\n",
    "    brand = canon(r.get(\"brand\", \"\"))\n",
    "    cats  = r.get(\"categories\", []) or []\n",
    "    cols  = r.get(\"colors_str\", \"\")\n",
    "    sizes = r.get(\"sizes_str\", \"\")\n",
    "    aud   = canon(r.get(\"audience\", \"\"))\n",
    "\n",
    "    # Make categories explicit tokens so queries like \"bh bygel\" hit\n",
    "    # Add common Swedish synonyms if you use them in your data.\n",
    "    cat_str = \", \".join(cats)\n",
    "\n",
    "    # EMBEDDING TEXT (compact, labeled fields)\n",
    "    embed_parts = [\n",
    "        f\"passage: {name}.\"\n",
    "    ]\n",
    "    if desc:\n",
    "        embed_parts.append(desc)\n",
    "    if brand:\n",
    "        embed_parts.append(f\"Brand: {brand}.\")\n",
    "    if aud:\n",
    "        embed_parts.append(f\"Audience: {aud}.\")\n",
    "    if cat_str:\n",
    "        embed_parts.append(f\"Categories: {cat_str}.\")\n",
    "    if cols:\n",
    "        embed_parts.append(f\"Colors: {cols}.\")\n",
    "    if sizes:\n",
    "        embed_parts.append(f\"Sizes: {sizes}.\")\n",
    "    text_embed = \" \".join(embed_parts)\n",
    "\n",
    "    # RERANK TEXT (richer; CE can use longer input)\n",
    "    rerank_parts = [\n",
    "        f\"{name}.\",\n",
    "        desc if desc else \"\",\n",
    "        f\"Brand: {brand}.\" if brand else \"\",\n",
    "        f\"Audience: {aud}.\" if aud else \"\",\n",
    "        f\"Categories: {cat_str}.\" if cat_str else \"\",\n",
    "        f\"Colors: {cols}.\" if cols else \"\",\n",
    "        f\"Sizes: {sizes}.\" if sizes else \"\",\n",
    "    ]\n",
    "    text_rerank = \" \".join(p for p in rerank_parts if p).strip()\n",
    "    return text_embed, text_rerank\n",
    "\n",
    "def prepare_group_corpus(groups: pd.DataFrame) -> tuple[pd.DataFrame, list[str]]:\n",
    "    g = groups.copy()\n",
    "    if \"color\" not in g.columns:\n",
    "        g[\"color\"] = \"\"\n",
    "    if \"size\" not in g.columns:\n",
    "        g[\"size\"] = \"\"\n",
    "\n",
    "    g[\"categories\"] = g[\"category\"].apply(norm_categories)\n",
    "    g[\"colors_str\"] = g[\"color\"].apply(format_colors)\n",
    "    g[\"sizes_str\"]  = g[\"size\"].apply(format_sizes)\n",
    "\n",
    "    texts = g.apply(lambda r: build_texts_for_ir(r), axis=1)\n",
    "    g[\"text\"]        = [t[0] for t in texts]  # for embeddings (passage: ...)\n",
    "    g[\"text_rerank\"] = [t[1] for t in texts]  # for cross-encoder\n",
    "\n",
    "    cols = [\"groupId\",\"text\",\"text_rerank\",\"audience\",\"color\",\"colors_str\",\"size\",\n",
    "            \"sizes_str\",\"categories\",\"brand\",\"name\"]\n",
    "    present = [c for c in cols if c in g.columns]\n",
    "    group_df = g[present].reset_index(drop=True)\n",
    "    corpus = group_df[\"text\"].tolist()  # this is what you embed/index\n",
    "    return group_df, corpus\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "group_df, corpus = prepare_group_corpus(groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b75fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbf995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009052f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7d218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c3421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4facf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (itcm-recsys)",
   "language": "python",
   "name": "itcm-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
