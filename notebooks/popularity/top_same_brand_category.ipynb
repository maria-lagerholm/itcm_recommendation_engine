{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2f3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_filtered_transactions(\n",
    "    trans_path=\"/workspace/data/processed/transactions_clean.parquet\",\n",
    "    avail_path=\"/workspace/data/processed/articles_for_recs.parquet\",\n",
    "    bad_ids={\"12025DK\", \"12025FI\", \"12025NO\", \"12025SE\", \"970300\", \"459978\"},\n",
    "    cols=(\"shopUserId\", \"orderId\", \"groupId\", \"category\", \"brand\", \"audience\"),\n",
    "):\n",
    "    global df \n",
    "    df = pd.read_parquet(trans_path, columns=list(cols))\n",
    "    avail_df = pd.read_parquet(avail_path)\n",
    "\n",
    "    gid = df[\"groupId\"].astype(str).str.strip()\n",
    "    avail_ids = set(avail_df[\"groupId\"].astype(str).str.strip().unique())\n",
    "\n",
    "    df = df.loc[gid.isin(avail_ids) & ~gid.isin(bad_ids)].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = load_filtered_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be982ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aggregate_by_groupid(\n",
    "    df: pd.DataFrame,\n",
    "    item_col: str = \"groupId\",\n",
    "    brand_col: str = \"brand\",\n",
    "    category_col: str = \"category\",\n",
    "    audience_col: str = \"audience\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate by groupId, count occurrences, and keep brand and category.\n",
    "    Returns a DataFrame with [groupId, brand, category, transactions].\n",
    "    \"\"\"\n",
    "    agg_df = (\n",
    "        df.groupby([item_col, brand_col, category_col, audience_col])\n",
    "          .size()\n",
    "          .reset_index(name=\"transactions\")\n",
    "    )\n",
    "    return agg_df\n",
    "\n",
    "pairs = aggregate_by_groupid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201130ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>audience</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>261637</td>\n",
       "      <td>Locköstrumpan</td>\n",
       "      <td>Stödstrumpor,Strumpor,Underkläder</td>\n",
       "      <td>dam</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>260695</td>\n",
       "      <td>Louise</td>\n",
       "      <td>Bh-toppar,Bh,Bh utan kupstorlek,Underkläder</td>\n",
       "      <td>dam</td>\n",
       "      <td>5725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>240187</td>\n",
       "      <td>Åshild</td>\n",
       "      <td>Mjukisbyxor,Mysplagg,Byxor</td>\n",
       "      <td>dam</td>\n",
       "      <td>4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>210338</td>\n",
       "      <td>Åshild</td>\n",
       "      <td>Toppar,Överdelar,T-shirts</td>\n",
       "      <td>dam</td>\n",
       "      <td>4069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>210695</td>\n",
       "      <td>Åshild</td>\n",
       "      <td>Toppar,Överdelar</td>\n",
       "      <td>dam</td>\n",
       "      <td>3962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>432036</td>\n",
       "      <td>Cobble Hill</td>\n",
       "      <td>Hobbyhörnan,Pussel,Pussel 2000 bitar</td>\n",
       "      <td>generic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>432043</td>\n",
       "      <td>Cobble Hill</td>\n",
       "      <td>Hobbyhörnan,Pussel,Pussel 1000 bitar</td>\n",
       "      <td>generic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>432050</td>\n",
       "      <td>Cobble Hill</td>\n",
       "      <td>Hobbyhörnan,Pussel,Pussel 1000 bitar</td>\n",
       "      <td>generic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>432051</td>\n",
       "      <td>Cobble Hill</td>\n",
       "      <td>Hobbyhörnan,Pussel,Pussel 1000 bitar</td>\n",
       "      <td>generic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>342699</td>\n",
       "      <td>Trefl</td>\n",
       "      <td>Hobbyhörnan,Pussel,Pussel 1000 bitar</td>\n",
       "      <td>generic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1419 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     groupId          brand                                     category  \\\n",
       "454   261637  Locköstrumpan            Stödstrumpor,Strumpor,Underkläder   \n",
       "278   260695         Louise  Bh-toppar,Bh,Bh utan kupstorlek,Underkläder   \n",
       "121   240187         Åshild                   Mjukisbyxor,Mysplagg,Byxor   \n",
       "30    210338         Åshild                    Toppar,Överdelar,T-shirts   \n",
       "35    210695         Åshild                             Toppar,Överdelar   \n",
       "...      ...            ...                                          ...   \n",
       "1154  432036    Cobble Hill         Hobbyhörnan,Pussel,Pussel 2000 bitar   \n",
       "1156  432043    Cobble Hill         Hobbyhörnan,Pussel,Pussel 1000 bitar   \n",
       "1159  432050    Cobble Hill         Hobbyhörnan,Pussel,Pussel 1000 bitar   \n",
       "1160  432051    Cobble Hill         Hobbyhörnan,Pussel,Pussel 1000 bitar   \n",
       "1087  342699          Trefl         Hobbyhörnan,Pussel,Pussel 1000 bitar   \n",
       "\n",
       "     audience  transactions  \n",
       "454       dam          6246  \n",
       "278       dam          5725  \n",
       "121       dam          4570  \n",
       "30        dam          4069  \n",
       "35        dam          3962  \n",
       "...       ...           ...  \n",
       "1154  generic             1  \n",
       "1156  generic             1  \n",
       "1159  generic             1  \n",
       "1160  generic             1  \n",
       "1087  generic             1  \n",
       "\n",
       "[1419 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sort_values(by=\"transactions\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05f749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all unique values of audience present in the pairs DataFrame\n",
    "#unique_audiences = sorted(pairs[\"audience\"].unique())\n",
    "#unique_audiences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904ea1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all fully unique category values present in the pairs DataFrame (no splitting)\n",
    "#unique_categories = sorted(pairs['category'].dropna().unique())\n",
    "#unique_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9808b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 33 rows due to Unknown brand\n",
      "Removed 76 groupIds due to having fewer than 1 recommendations\n",
      "Saved 1297 rows to /workspace/data/processed/top_same_brand.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "GENDER_TOKENS = {\"dam\", \"herr\"} \n",
    "\n",
    "def cat_to_set(s):\n",
    "    if pd.isna(s): return set()\n",
    "    # split on commas; keep tokens like \"Mössor & hattar\" as a single concept\n",
    "    toks = {t.strip().lower() for t in str(s).split(\",\") if t.strip()}\n",
    "    return {t for t in toks if t != \"unknown\"}\n",
    "\n",
    "def preprocess(pairs: pd.DataFrame):\n",
    "    df = pairs.copy()\n",
    "    df[\"brand_norm\"] = df[\"brand\"].astype(str).str.strip().str.lower()\n",
    "    df[\"aud_norm\"] = df[\"audience\"].astype(str).str.strip().str.lower()\n",
    "    is_unknown = df[\"brand_norm\"].eq(\"unknown\")\n",
    "    skipped = int(is_unknown.sum())\n",
    "    df = df.loc[~is_unknown].copy()\n",
    "    df[\"cat_set\"] = df[\"category\"].map(cat_to_set)\n",
    "    return df, skipped\n",
    "\n",
    "def categories_match(a: set[str], b: set[str]) -> bool:\n",
    "    \"\"\"\n",
    "    True if:\n",
    "      - there is at least one shared NON-gender token, AND\n",
    "      - if 'dam' is in A, then 'dam' must be in B; similarly for 'herr'.\n",
    "    If A has no gender token, gender is not enforced (e.g., 'badrum/wc' can match anything).\n",
    "    \"\"\"\n",
    "    core_a = a - GENDER_TOKENS\n",
    "    core_b = b - GENDER_TOKENS\n",
    "    if not (core_a & core_b):\n",
    "        return False\n",
    "\n",
    "    # enforce gender symmetry only if present in A\n",
    "    if \"dam\" in a and \"dam\" not in b:\n",
    "        return False\n",
    "    if \"herr\" in a and \"herr\" not in b:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def build_recs(filtered_pairs: pd.DataFrame, min_recs=4, max_recs=10):\n",
    "    recs, insufficient = {}, 0\n",
    "    fp = filtered_pairs.copy()\n",
    "    fp[\"transactions\"] = pd.to_numeric(fp[\"transactions\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    for _, g in fp.groupby(\"brand_norm\", sort=False):\n",
    "        g = g.sort_values(\"transactions\", ascending=False)\n",
    "        cat_map = g[\"cat_set\"].to_dict()\n",
    "        cutoff = g[\"transactions\"].quantile(0.96)\n",
    "        is_bestseller = g[\"transactions\"] >= cutoff\n",
    "\n",
    "        for idx, row in g.iterrows():\n",
    "            gid = str(row[\"groupId\"])\n",
    "            my_cats = row[\"cat_set\"]\n",
    "            my_aud  = row[\"aud_norm\"]\n",
    "            if not my_cats:\n",
    "                insufficient += 1\n",
    "                continue\n",
    "\n",
    "            mask = (\n",
    "                (g[\"groupId\"].astype(str) != gid)\n",
    "                & (g.index != idx)\n",
    "                & (~is_bestseller)                          # drop top 5% by popularity\n",
    "                & (g[\"aud_norm\"] == my_aud)                 # exact audience match\n",
    "                & g.index.map(lambda j: categories_match(my_cats, cat_map[j]))\n",
    "            )\n",
    "\n",
    "            tops = g.loc[mask, \"groupId\"].astype(str).head(max_recs).tolist()\n",
    "            if len(tops) >= min_recs:\n",
    "                recs[gid] = {f\"Top {i+1}\": t for i, t in enumerate(tops)}\n",
    "            else:\n",
    "                insufficient += 1\n",
    "\n",
    "    rows = [{\"Product ID\": k, **v} for k, v in recs.items()]\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        ordered = [\"Product ID\"] + [c for i in range(1, max_recs + 1) if (c := f\"Top {i}\") in df.columns]\n",
    "        df = df[ordered]\n",
    "    return df, insufficient\n",
    "\n",
    "def save_parquet(df: pd.DataFrame, path: str):\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, path)\n",
    "\n",
    "def run(pairs: pd.DataFrame, min_recs=4, max_recs=10, out_path=\"/workspace/data/processed/top_same_brand.parquet\"):\n",
    "    filtered, skipped = preprocess(pairs)\n",
    "    export_df, insufficient = build_recs(filtered, min_recs=min_recs, max_recs=max_recs)\n",
    "    save_parquet(export_df, out_path)\n",
    "    print(f\"Skipped {skipped} rows due to Unknown brand\")\n",
    "    print(f\"Removed {insufficient} groupIds due to having fewer than {min_recs} recommendations\")\n",
    "    print(f\"Saved {len(export_df)} rows to {out_path}\")\n",
    "    return export_df\n",
    "\n",
    "export_df = run(pairs, min_recs=1, max_recs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eabc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (itcm-recsys)",
   "language": "python",
   "name": "itcm-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
