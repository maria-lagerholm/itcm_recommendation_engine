{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18fb56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tx = pd.read_parquet(\"../data/processed/transactions_clean.parquet\")\n",
    "articles  = pd.read_parquet(\"../data/processed/articles_clean.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e76633",
   "metadata": {},
   "source": [
    "## Build json for mental mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66547eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Setup & Constants\n",
    "\n",
    "# %%\n",
    "import re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "NORDICS = [\"Sweden\", \"Denmark\", \"Finland\", \"Norway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bbeea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Generic helpers\n",
    "# Small utilities reused across the pipeline.\n",
    "\n",
    "# %%\n",
    "def status_from_orders(n: int) -> str:\n",
    "    return \"New\" if n <= 1 else (\"Returning\" if n <= 3 else \"Loyal\")\n",
    "\n",
    "\n",
    "def mode_or_first(s: pd.Series):\n",
    "    m = s.mode()\n",
    "    if not m.empty:\n",
    "        return m.iat[0]\n",
    "    s = s.dropna()\n",
    "    return s.iat[0] if not s.empty else None\n",
    "\n",
    "def _pick(tx: pd.DataFrame, names, default=None) -> pd.Series:\n",
    "    for n in names:\n",
    "        if n in tx.columns:\n",
    "            return tx[n]\n",
    "    return pd.Series([default] * len(tx), index=tx.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f454321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Normalization helpers\n",
    "# Standardize ids and small categorical fields.\n",
    "\n",
    "# %%\n",
    "def _norm_id(s: pd.Series) -> pd.Series:\n",
    "    # to string, strip, drop trailing \".0\"\n",
    "    s = s.astype(\"string[python]\").str.strip()\n",
    "    return s.str.replace(r\"\\.0+$\", \"\", regex=True)\n",
    "\n",
    "def _norm_gender(s: pd.Series):\n",
    "    if s is None:\n",
    "        return s\n",
    "    return s.astype(\"string[python]\").str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00a2e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Tx base-frame builder\n",
    "# Make a clean base transaction frame with unified schema.\n",
    "\n",
    "# %%\n",
    "def _build_base_tx(tx: pd.DataFrame) -> pd.DataFrame:\n",
    "    # country & city (no defaulting if you know they exist)\n",
    "    country = tx[\"country\"].astype(\"string[python]\").str.strip()\n",
    "    city = _pick(tx, [\"invoiceCity\", \"city\"], \"Unknown\").astype(object)\n",
    "\n",
    "    # ids\n",
    "    shop = _norm_id(tx[\"shopUserId\"])\n",
    "    order_id = tx[\"orderId\"].astype(\"string[python]\").str.strip()\n",
    "\n",
    "    # dates\n",
    "    created_raw = tx[\"created\"]\n",
    "    created = created_raw if np.issubdtype(created_raw.dtype, np.datetime64) else pd.to_datetime(created_raw, errors=\"coerce\")\n",
    "    if isinstance(created, pd.Series) and np.issubdtype(created.dtype, np.datetime64):\n",
    "        try:\n",
    "            if getattr(created.dt, \"tz\", None) is not None:\n",
    "                created = created.dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # price & misc\n",
    "    rev = pd.to_numeric(tx.get(\"line_total_sek\"), errors=\"coerce\").fillna(0)\n",
    "    typ = tx[\"type\"] if \"type\" in tx.columns else pd.Series([None] * len(tx), index=tx.index)\n",
    "    price = tx[\"price\"] if \"price\" in tx.columns else pd.Series([None] * len(tx), index=tx.index)\n",
    "\n",
    "    age = pd.to_numeric(tx.get(\"Age\"), errors=\"coerce\").astype(\"Float64\") if \"Age\" in tx.columns else pd.Series([pd.NA] * len(tx), index=tx.index, dtype=\"Float64\")\n",
    "    gender = tx.get(\"Gender\") if \"Gender\" in tx.columns else pd.Series([pd.NA] * len(tx), index=tx.index, dtype=\"object\")\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"country\": country,\n",
    "            \"city\": city,\n",
    "            \"shopUserId\": shop,\n",
    "            \"orderId\": order_id,\n",
    "            \"rev\": rev,\n",
    "            \"created\": created,\n",
    "            \"type\": typ,\n",
    "            \"price\": price,\n",
    "            \"Age\": age,\n",
    "            \"Gender\": gender,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77fe78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORDICS = [\"Sweden\", \"Denmark\", \"Finland\", \"Norway\"]\n",
    "\n",
    "def split_nordics(tx: pd.DataFrame) -> dict:\n",
    "    base_tx = _build_base_tx(tx)\n",
    "    return {cname: base_tx[base_tx[\"country\"] == cname].copy() for cname in NORDICS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0da06a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Export helpers: totals & aggregates\n",
    "# Small builders used by the JSON exporter.\n",
    "\n",
    "# %%\n",
    "def _country_totals(tx: pd.DataFrame):\n",
    "    total_revenue = int(np.rint(tx[\"rev\"].sum()))\n",
    "    customers_cnt = int(tx[\"shopUserId\"].nunique())\n",
    "    total_orders = int(tx[\"orderId\"].nunique())\n",
    "    aov_country = None if total_orders == 0 else int(round(float(total_revenue) / total_orders))\n",
    "    return total_revenue, customers_cnt, total_orders, aov_country\n",
    "\n",
    "def _agg_city(tx: pd.DataFrame):\n",
    "    agg_city = (\n",
    "        tx.groupby(\"city\", dropna=False, sort=False)\n",
    "        .agg(total_revenue_sek=(\"rev\", \"sum\"), customers_count=(\"shopUserId\", \"nunique\"))\n",
    "    )\n",
    "    agg_city[\"total_revenue_sek\"] = np.rint(agg_city[\"total_revenue_sek\"]).astype(\"int64\")\n",
    "    agg_city[\"customers_count\"] = agg_city[\"customers_count\"].astype(\"int64\")\n",
    "    city_orders = tx.groupby(\"city\", dropna=False)[\"orderId\"].nunique().rename(\"total_orders\").astype(\"int64\")\n",
    "    return agg_city, city_orders\n",
    "\n",
    "def _agg_order(tx: pd.DataFrame):\n",
    "    tx_cust = tx[tx[\"shopUserId\"].notna()].copy()\n",
    "    agg_order = (\n",
    "        tx_cust.groupby([\"city\", \"shopUserId\", \"orderId\"], dropna=False, sort=False)\n",
    "        .agg(\n",
    "            order_total_sek=(\"rev\", \"sum\"),\n",
    "            n_items=(\"orderId\", \"size\"),\n",
    "            created=(\"created\", \"min\"),\n",
    "            order_type=(\"type\", mode_or_first),\n",
    "            price=(\"price\", mode_or_first),\n",
    "        )\n",
    "    )\n",
    "    agg_order[\"order_total_sek\"] = np.rint(agg_order[\"order_total_sek\"]).astype(\"int64\")\n",
    "    agg_order = agg_order.sort_index(level=[\"city\", \"shopUserId\", \"orderId\"])\n",
    "    return agg_order\n",
    "\n",
    "def _agg_city_monthly(tx: pd.DataFrame) -> dict[str, dict[str, int]]:\n",
    "    \"\"\"\n",
    "    sum revenue by city and calendar month (YYYY-MM).\n",
    "    Returns {city { 'YYYY-MM': total_revenue_sek_int, ... }, ...}\n",
    "    \"\"\"\n",
    "    txm = tx.copy()\n",
    "    # Ensure naive, month string\n",
    "    ym = txm[\"created\"]\n",
    "    if getattr(ym.dt, \"tz\", None) is not None:\n",
    "        ym = ym.dt.tz_localize(None)\n",
    "    txm[\"year_month\"] = ym.dt.to_period(\"M\").astype(str)\n",
    "\n",
    "    g = (\n",
    "        txm.groupby([\"city\", \"year_month\"], dropna=False)[\"rev\"]\n",
    "        .sum()\n",
    "        .round()\n",
    "        .astype(\"int64\")\n",
    "    )\n",
    "    out: dict[str, dict[str, int]] = {}\n",
    "    for (cty, ym), val in g.items():\n",
    "        ckey = \"Unknown\" if pd.isna(cty) else str(cty)\n",
    "        out.setdefault(ckey, {})[ym] = int(val)\n",
    "    return out\n",
    "\n",
    "def _customers_by_channel(tx: pd.DataFrame) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count distinct customers per 'type' (channel).\n",
    "    \"\"\"\n",
    "    if \"type\" not in tx.columns:\n",
    "        return {}\n",
    "    tmp = tx[[\"shopUserId\", \"type\"]].dropna().copy()\n",
    "\n",
    "    tmp[\"channel\"] = tmp[\"type\"]\n",
    "\n",
    "    # distinct customers per channel\n",
    "    g = (\n",
    "        tmp.dropna(subset=[\"channel\", \"shopUserId\"])\n",
    "           .groupby(\"channel\")[\"shopUserId\"]\n",
    "           .nunique()\n",
    "           .astype(int)\n",
    "    )\n",
    "    return {k: int(v) for k, v in g.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ddc6856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _agg_customer(tx: pd.DataFrame):\n",
    "    tx_cust = tx[tx[\"shopUserId\"].notna()].copy()\n",
    "    agg_customer = (\n",
    "        tx_cust.groupby([\"city\", \"shopUserId\"], dropna=False, sort=False)\n",
    "        .agg(\n",
    "            total_spent_sek=(\"rev\", \"sum\"),\n",
    "            total_orders=(\"orderId\", \"nunique\"),\n",
    "            first_order=(\"created\", \"min\"),\n",
    "            last_order=(\"created\", \"max\"),\n",
    "            age=(\"Age\", mode_or_first),\n",
    "            gender=(\"Gender\", mode_or_first),\n",
    "        )\n",
    "    )\n",
    "    agg_customer[\"total_spent_sek\"] = np.rint(agg_customer[\"total_spent_sek\"]).astype(\"int64\")\n",
    "    return agg_customer.sort_index(level=[\"city\", \"shopUserId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a695f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Export helpers: items extraction\n",
    "# Build items_tx from original tx aligned to country tx indices.\n",
    "\n",
    "# %%\n",
    "def _build_items_grouped(tx_country: pd.DataFrame, tx: pd.DataFrame, articles: pd.DataFrame | None = None):\n",
    "    item_cols = [\"sku\",\"groupId\",\"created\",\"quantity\",\"price_sek\",\"name\",\"line_total_sek\",\"type\",\"brand\",\"category\",\"price\"]\n",
    "    present   = [c for c in item_cols if c in tx.columns]\n",
    "\n",
    "    items_tx = pd.DataFrame({\"city\": tx_country[\"city\"], \"shopUserId\": tx_country[\"shopUserId\"], \"orderId\": tx_country[\"orderId\"]})\n",
    "    for c in present:\n",
    "        if c == \"created\":\n",
    "            col_created = tx_country[\"created\"]\n",
    "            try:\n",
    "                if getattr(col_created.dt, \"tz\", None) is not None:\n",
    "                    col_created = col_created.dt.tz_localize(None)\n",
    "            except Exception:\n",
    "                pass\n",
    "            items_tx[c] = col_created\n",
    "        else:\n",
    "            items_tx[c] = tx.loc[tx_country.index, c] if c in tx.columns else None\n",
    "\n",
    "    # enrich brand/category from articles ---\n",
    "    if articles is not None:\n",
    "        art = articles.copy()\n",
    "\n",
    "        # normalize join keys\n",
    "        for key in (\"sku\", \"groupId\"):\n",
    "            if key in art.columns:\n",
    "                art[key] = art[key].astype(\"string[python]\").str.strip()\n",
    "        if \"sku\" in items_tx.columns:\n",
    "            items_tx[\"sku\"] = items_tx[\"sku\"].astype(\"string[python]\").str.strip()\n",
    "        if \"groupId\" in items_tx.columns:\n",
    "            items_tx[\"groupId\"] = items_tx[\"groupId\"].astype(\"string[python]\").str.strip()\n",
    "\n",
    "        # ensure target columns exist\n",
    "        if \"brand\" not in items_tx.columns:\n",
    "            items_tx[\"brand\"] = pd.NA\n",
    "        if \"category\" not in items_tx.columns:\n",
    "            items_tx[\"category\"] = pd.NA\n",
    "\n",
    "        # maps by SKU (preferred)\n",
    "        if \"sku\" in art.columns:\n",
    "            if \"brand\" in art.columns:\n",
    "                sku_brand = art.dropna(subset=[\"sku\"]).drop_duplicates(\"sku\").set_index(\"sku\")[\"brand\"]\n",
    "                items_tx[\"brand\"] = items_tx[\"brand\"].fillna(items_tx.get(\"sku\").map(sku_brand))\n",
    "            if \"category\" in art.columns:\n",
    "                sku_cat = art.dropna(subset=[\"sku\"]).drop_duplicates(\"sku\").set_index(\"sku\")[\"category\"]\n",
    "                items_tx[\"category\"] = items_tx[\"category\"].fillna(items_tx.get(\"sku\").map(sku_cat))\n",
    "\n",
    "        # fallback maps by groupId\n",
    "        if \"groupId\" in art.columns:\n",
    "            if \"brand\" in art.columns:\n",
    "                gid_brand = art.dropna(subset=[\"groupId\"]).drop_duplicates(\"groupId\").set_index(\"groupId\")[\"brand\"]\n",
    "                items_tx[\"brand\"] = items_tx[\"brand\"].fillna(items_tx.get(\"groupId\").map(gid_brand))\n",
    "            if \"category\" in art.columns:\n",
    "                gid_cat = art.dropna(subset=[\"groupId\"]).drop_duplicates(\"groupId\").set_index(\"groupId\")[\"category\"]\n",
    "                items_tx[\"category\"] = items_tx[\"category\"].fillna(items_tx.get(\"groupId\").map(gid_cat))\n",
    "\n",
    "    items_tx = items_tx[tx_country[\"shopUserId\"].notna()].copy()\n",
    "    items_tx[\"city\"] = items_tx[\"city\"].fillna(\"Unknown\")\n",
    "    return items_tx.groupby([\"city\",\"shopUserId\",\"orderId\"], dropna=False, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Export helpers: JSON node builders\n",
    "# Convert rows to JSON-friendly dicts.\n",
    "\n",
    "# %%\n",
    "def _item_dict(row: pd.Series):\n",
    "    cr = row.get(\"created\")\n",
    "    if isinstance(cr, pd.Timestamp):\n",
    "        cr = cr.isoformat(sep=\" \")\n",
    "    def nz(v): return None if pd.isna(v) else v\n",
    "    def to_int(v): return None if pd.isna(v) else int(v)\n",
    "    def to_float(v): return None if pd.isna(v) else float(v)\n",
    "    return {\n",
    "        \"sku\": nz(row.get(\"sku\")),\n",
    "        \"groupId\": nz(row.get(\"groupId\")),\n",
    "        \"created\": nz(cr),\n",
    "        \"quantity\": to_int(row.get(\"quantity\")),\n",
    "        \"price_sek\": to_int(row.get(\"price_sek\")),\n",
    "        \"name\": nz(row.get(\"name\")),\n",
    "        \"line_total_sek\": to_int(row.get(\"line_total_sek\")),\n",
    "        \"type\": nz(row.get(\"type\")),\n",
    "        \"brand\": nz(row.get(\"brand\")),\n",
    "        \"category\": nz(row.get(\"category\")),\n",
    "        \"price\": to_float(row.get(\"price\")),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc6a4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\n",
    "# %%\n",
    "def export_country_json(tx_country: pd.DataFrame, tx_full: pd.DataFrame, country_name: str, out_dir=\"/workspace/data/processed\", articles: pd.DataFrame | None = None):\n",
    "    tx_c = tx_country.copy()\n",
    "    tx_c[\"city\"] = tx_c[\"city\"].fillna(\"Unknown\")\n",
    "\n",
    "    total_revenue, customers_cnt, total_orders, aov_country = _country_totals(tx_c)\n",
    "    agg_city, city_orders = _agg_city(tx_c)\n",
    "    agg_customer = _agg_customer(tx_c)\n",
    "    agg_order = _agg_order(tx_c)\n",
    "    city_monthly_map = _agg_city_monthly(tx_c)\n",
    "    customers_by_channel = _customers_by_channel(tx_c)\n",
    "\n",
    "    items_grouped = _build_items_grouped(tx_c, tx_full, articles=articles)\n",
    " \n",
    "\n",
    "    # ---------- build JSON ----------\n",
    "    top_key = country_name.lower()\n",
    "    result = {\n",
    "        top_key: {\n",
    "            \"total_revenue_sek\": int(total_revenue),\n",
    "            \"customers_count\": int(customers_cnt),\n",
    "            \"total_orders\": int(total_orders),\n",
    "            \"avg_order_value_sek\": aov_country,\n",
    "            \"customers_by_channel\": customers_by_channel,\n",
    "            \"cities\": {},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # cities\n",
    "    for cty, row in agg_city.iterrows():\n",
    "        ckey = \"Unknown\" if pd.isna(cty) else str(cty)\n",
    "        orders_c = int(city_orders.get(cty, 0))\n",
    "        rev_c = int(row[\"total_revenue_sek\"])\n",
    "        aov_c = None if orders_c == 0 else int(round(float(rev_c) / orders_c))\n",
    "\n",
    "        result[top_key][\"cities\"][ckey] = {\n",
    "            \"total_revenue_sek\": rev_c,\n",
    "            \"customers_count\": int(row[\"customers_count\"]),\n",
    "            \"total_orders\": orders_c,\n",
    "            \"avg_order_value_sek\": aov_c,\n",
    "            # NEW: monthly breakdown here\n",
    "            \"monthly_revenue_sek\": city_monthly_map.get(ckey, {}),\n",
    "            \"customers\": {},\n",
    "        }\n",
    "\n",
    "    # customers + orders + items (unchanged)\n",
    "    for (cty, uid), row in agg_customer.iterrows():\n",
    "        status = status_from_orders(int(row[\"total_orders\"]))\n",
    "        first_iso = row[\"first_order\"].isoformat(sep=\" \") if pd.notna(row[\"first_order\"]) else None\n",
    "        last_iso = row[\"last_order\"].isoformat(sep=\" \") if pd.notna(row[\"last_order\"]) else None\n",
    "\n",
    "        age_val = None\n",
    "        if \"age\" in row and pd.notna(row[\"age\"]):\n",
    "            try:\n",
    "                age_val = int(row[\"age\"])\n",
    "            except Exception:\n",
    "                age_val = None\n",
    "        gender_val = None if \"gender\" not in row or pd.isna(row[\"gender\"]) else str(row[\"gender\"])\n",
    "\n",
    "        cust_node = {\n",
    "            \"summary\": {\n",
    "                \"total_orders\": int(row[\"total_orders\"]),\n",
    "                \"total_spent_sek\": int(row[\"total_spent_sek\"]),\n",
    "                \"first_order\": first_iso,\n",
    "                \"last_order\": last_iso,\n",
    "                \"status\": status,\n",
    "                \"age\": age_val,\n",
    "                \"gender\": gender_val,\n",
    "            },\n",
    "            \"orders\": {},\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            cust_orders = agg_order.loc[(cty, uid)]\n",
    "            if isinstance(cust_orders, pd.Series):\n",
    "                cust_orders = cust_orders.to_frame().T\n",
    "            for oid, orow in cust_orders.iterrows():\n",
    "                try:\n",
    "                    items_for_order = items_grouped.get_group((cty, uid, oid))\n",
    "                    items = [_item_dict(r) for _, r in items_for_order.iterrows()]\n",
    "                except KeyError:\n",
    "                    items = []\n",
    "                cust_node[\"orders\"][str(oid)] = {\n",
    "                    \"created\": orow[\"created\"].isoformat(sep=\" \") if pd.notna(orow[\"created\"]) else None,\n",
    "                    \"order_total_sek\": int(orow[\"order_total_sek\"]),\n",
    "                    \"n_items\": int(orow[\"n_items\"]),\n",
    "                    \"order_type\": None if pd.isna(orow[\"order_type\"]) else orow[\"order_type\"],\n",
    "                    \"price\": None if pd.isna(orow.get(\"price\")) else float(orow.get(\"price\")),\n",
    "                    \"items\": items,\n",
    "                }\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        ckey = \"Unknown\" if pd.isna(cty) else str(cty)\n",
    "        result[top_key][\"cities\"][ckey][\"customers\"][str(uid)] = cust_node\n",
    "\n",
    "    # write\n",
    "    out_path = Path(out_dir) / f\"{country_name}.json\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfb6c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/data/processed/Sweden.json\n",
      "Saved: /workspace/data/processed/Denmark.json\n",
      "Saved: /workspace/data/processed/Finland.json\n",
      "Saved: /workspace/data/processed/Norway.json\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# %%\n",
    "countries = split_nordics(tx)\n",
    "export_country_json(countries[\"Sweden\"],  tx, \"Sweden\", articles=articles)\n",
    "export_country_json(countries[\"Denmark\"], tx, \"Denmark\", articles=articles)\n",
    "export_country_json(countries[\"Finland\"], tx, \"Finland\", articles=articles)\n",
    "export_country_json(countries[\"Norway\"],  tx, \"Norway\",  articles=articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51f7ae",
   "metadata": {},
   "source": [
    "## Flatten json for quick math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a699804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Imports & Futures\n",
    "\n",
    "# %%\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de4a5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Paths & Config\n",
    "\n",
    "# %%\n",
    "INPUT_DIR  = Path(\"../data/processed\")\n",
    "OUTPUT_DIR = Path(\"../data/processed\")\n",
    "\n",
    "COUNTRY_FILES = {\n",
    "    \"Sweden\":  INPUT_DIR / \"Sweden.json\",\n",
    "    \"Denmark\": INPUT_DIR / \"Denmark.json\",\n",
    "    \"Finland\": INPUT_DIR / \"Finland.json\",\n",
    "    \"Norway\":  INPUT_DIR / \"Norway.json\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c9c8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Stable Column Schemas\n",
    "\n",
    "# %%\n",
    "CS_COUNTRY = [\"country\",\"total_revenue_sek\",\"customers_count\",\"total_orders\",\"avg_order_value_sek\"]\n",
    "CS_CITY    = [\"country\",\"city\",\"total_revenue_sek\",\"customers_count\",\"total_orders\",\"avg_order_value_sek\"]\n",
    "\n",
    "# Added age & gender here\n",
    "CS_CUST    = [\"country\",\"city\",\"customer_id\",\"total_orders\",\"total_spent_sek\",\n",
    "              \"first_order\",\"last_order\",\"status\",\"age\",\"gender\"]\n",
    "\n",
    "CS_ORDERS  = [\"country\",\"city\",\"customer_id\",\"order_id\",\"created\",\"order_total_sek\",\"n_items\",\"order_type\",\"price\"]\n",
    "CS_ITEMS   = [\"country\",\"city\",\"customer_id\",\"order_id\",\"sku\",\"groupId\",\"created\",\"quantity\",\"price_sek\",\"name\",\"line_total_sek\",\"type\",\"brand\",\"category\",\"price\"]\n",
    "\n",
    "# monthly revenue per city\n",
    "CS_CITY_MONTHLY = [\"country\",\"city\",\"year_month\",\"total_revenue_sek\"]\n",
    "\n",
    "# customers by channel per country\n",
    "CS_COUNTRY_CHANNEL = [\"country\",\"channel\",\"customers_count\"]\n",
    "CS_COUNTRY_CHANNEL_BY_MONTH = [\"country\",\"channel\",\"year_month\",\"customers_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b4054d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # I/O Helpers\n",
    "\n",
    "# %%\n",
    "def load_json(path: Path) -> dict:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_parquet(tx: pd.DataFrame, path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tx.to_parquet(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca5da16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # DataFrame Utilities\n",
    "\n",
    "# %%\n",
    "def _ensure(tx: pd.DataFrame | None, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Ensure columns exist, preserve dtypes, and reorder.\"\"\"\n",
    "    if tx is None or tx.empty:\n",
    "        return pd.DataFrame({c: pd.Series([], dtype=\"object\") for c in cols})[cols]\n",
    "    for c in cols:\n",
    "        if c not in tx.columns:\n",
    "            tx[c] = pd.NA\n",
    "    return tx[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "13e7244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # JSON Shape Helpers\n",
    "\n",
    "# %%\n",
    "def _unwrap(obj: dict, hint: str) -> tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Accept {\"denmark\": {...}} or {...}.\n",
    "    Returns (country_name_capitalized, payload_dict).\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict) and len(obj) == 1 and isinstance(next(iter(obj.values())), dict):\n",
    "        k = next(iter(obj.keys()))\n",
    "        return k.capitalize(), next(iter(obj.values()))\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Top-level JSON must be an object/dict\")\n",
    "    return hint, obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad3680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # Flatten: Country → Row Buckets\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "def flatten_country(obj: dict, country_hint: str) -> dict[str, list[dict]]:\n",
    "    country, root = _unwrap(obj, country_hint)\n",
    "    out = {\n",
    "        \"country_summary\": [{\n",
    "            \"country\": country,\n",
    "            \"total_revenue_sek\": root.get(\"total_revenue_sek\"),\n",
    "            \"customers_count\": root.get(\"customers_count\"),\n",
    "            \"total_orders\": root.get(\"total_orders\"),\n",
    "            \"avg_order_value_sek\": root.get(\"avg_order_value_sek\"),\n",
    "        }],\n",
    "        \"country_channels\": [],\n",
    "        \"country_channels_by_month\": [],\n",
    "        \"city_summary\": [],\n",
    "        \"city_monthly\": [],\n",
    "        \"customer_summary\": [],\n",
    "        \"orders\": [],\n",
    "        \"order_items\": [],\n",
    "    }\n",
    "\n",
    "    # keep the overall-by-channel counts from the root (already provided in JSON)\n",
    "    for ch, cnt in (root.get(\"customers_by_channel\") or {}).items():\n",
    "        out[\"country_channels\"].append({\n",
    "            \"country\": country,\n",
    "            \"channel\": ch,\n",
    "            \"customers_count\": cnt,\n",
    "        })\n",
    "\n",
    "    # --- derive monthly unique customers per channel from orders ---\n",
    "    # key: (channel, \"YYYY-MM\") -> set of customer_ids\n",
    "    cc_monthly_sets: dict[tuple[str, str], set] = defaultdict(set)\n",
    "\n",
    "    for city, cnode in (root.get(\"cities\") or {}).items():\n",
    "        out[\"city_summary\"].append({\n",
    "            \"country\": country, \"city\": city,\n",
    "            \"total_revenue_sek\": cnode.get(\"total_revenue_sek\"),\n",
    "            \"customers_count\": cnode.get(\"customers_count\"),\n",
    "            \"total_orders\": cnode.get(\"total_orders\"),\n",
    "            \"avg_order_value_sek\": cnode.get(\"avg_order_value_sek\"),\n",
    "        })\n",
    "\n",
    "        # monthly map { 'YYYY-MM': revenue }\n",
    "        for ym, rev in (cnode.get(\"monthly_revenue_sek\") or {}).items():\n",
    "            out[\"city_monthly\"].append({\n",
    "                \"country\": country,\n",
    "                \"city\": city,\n",
    "                \"year_month\": ym,\n",
    "                \"total_revenue_sek\": rev,\n",
    "            })\n",
    "\n",
    "        for cust_id, cst in (cnode.get(\"customers\") or {}).items():\n",
    "            summ = cst.get(\"summary\") or {}\n",
    "            out[\"customer_summary\"].append({\n",
    "                \"country\": country,\n",
    "                \"city\": city,\n",
    "                \"customer_id\": cust_id,\n",
    "                \"total_orders\": summ.get(\"total_orders\"),\n",
    "                \"total_spent_sek\": summ.get(\"total_spent_sek\"),\n",
    "                \"first_order\": summ.get(\"first_order\"),\n",
    "                \"last_order\": summ.get(\"last_order\"),\n",
    "                \"status\": summ.get(\"status\"),\n",
    "                \"age\": summ.get(\"age\"),\n",
    "                \"gender\": summ.get(\"gender\"),\n",
    "            })\n",
    "\n",
    "            for order_id, ordn in (cst.get(\"orders\") or {}).items():\n",
    "                created = ordn.get(\"created\")\n",
    "                order_type = ordn.get(\"order_type\")  # channel\n",
    "                if order_type and isinstance(created, str):  # guard just in case\n",
    "                    ym = created[:7]  # \"YYYY-MM\"\n",
    "                    cc_monthly_sets[(order_type, ym)].add(str(cust_id))\n",
    "\n",
    "                out[\"orders\"].append({\n",
    "                    \"country\": country, \"city\": city, \"customer_id\": cust_id, \"order_id\": order_id,\n",
    "                    \"created\": created,\n",
    "                    \"order_total_sek\": ordn.get(\"order_total_sek\"),\n",
    "                    \"n_items\": ordn.get(\"n_items\"),\n",
    "                    \"order_type\": order_type,\n",
    "                    \"price\": ordn.get(\"price\"),\n",
    "                })\n",
    "                for it in (ordn.get(\"items\") or []):\n",
    "                    out[\"order_items\"].append({\n",
    "                        \"country\": country, \"city\": city, \"customer_id\": cust_id, \"order_id\": order_id,\n",
    "                        \"sku\": it.get(\"sku\"), \"groupId\": it.get(\"groupId\"), \"created\": it.get(\"created\"),\n",
    "                        \"quantity\": it.get(\"quantity\"), \"price_sek\": it.get(\"price_sek\"), \"name\": it.get(\"name\"),\n",
    "                        \"line_total_sek\": it.get(\"line_total_sek\"), \"type\": it.get(\"type\"),\n",
    "                        \"brand\": it.get(\"brand\"), \"category\": it.get(\"category\"), \"price\": it.get(\"price\"),\n",
    "                    })\n",
    "\n",
    "\n",
    "    for (channel, year_month), cust_set in sorted(cc_monthly_sets.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "        out[\"country_channels_by_month\"].append({\n",
    "            \"country\": country,\n",
    "            \"channel\": channel,\n",
    "            \"year_month\": year_month,\n",
    "            \"customers_count\": len(cust_set),\n",
    "        })\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bc676bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Aggregation\n",
    "\n",
    "# %%\n",
    "def collect_buckets(country_files: dict[str, Path]) -> dict[str, list[dict]]:\n",
    "    buckets = {k: [] for k in [\n",
    "        \"country_summary\",\"country_channels\",\"country_channels_by_month\",\"city_summary\",\"city_monthly\",\"customer_summary\",\"orders\",\"order_items\"\n",
    "    ]}\n",
    "    for name, path in country_files.items():\n",
    "        if not path.exists():\n",
    "            print(f\"[warn] missing: {path}\")\n",
    "            continue\n",
    "        rows = flatten_country(load_json(path), name)\n",
    "        for k, v in rows.items():\n",
    "            buckets[k].extend(v)\n",
    "        print(f\"[ok] parsed {name}\")\n",
    "    return buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac9c7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Materialize dfs\n",
    "\n",
    "# %%\n",
    "def to_dataframes(buckets: dict[str, list[dict]]) -> dict[str, pd.DataFrame]:\n",
    "    tx_country = _ensure(pd.DataFrame(buckets[\"country_summary\"]),   CS_COUNTRY)\n",
    "    tx_cc      = _ensure(pd.DataFrame(buckets[\"country_channels\"]),  CS_COUNTRY_CHANNEL)\n",
    "    tx_cc_by_month = _ensure(pd.DataFrame(buckets[\"country_channels_by_month\"]), CS_COUNTRY_CHANNEL_BY_MONTH)\n",
    "    tx_city    = _ensure(pd.DataFrame(buckets[\"city_summary\"]),      CS_CITY)\n",
    "    tx_city_m  = _ensure(pd.DataFrame(buckets[\"city_monthly\"]),      CS_CITY_MONTHLY)\n",
    "    tx_cust    = _ensure(pd.DataFrame(buckets[\"customer_summary\"]),  CS_CUST)\n",
    "    tx_orders  = _ensure(pd.DataFrame(buckets[\"orders\"]),            CS_ORDERS)\n",
    "    order_items   = _ensure(pd.DataFrame(buckets[\"order_items\"]),       CS_ITEMS)\n",
    "    return {\n",
    "        \"country_summary\": tx_country,\n",
    "        \"country_channels\": tx_cc,\n",
    "        \"country_channels_by_month\": tx_cc_by_month,\n",
    "        \"city_summary\": tx_city,\n",
    "        \"city_monthly\": tx_city_m,\n",
    "        \"customer_summary\": tx_cust,\n",
    "        \"orders\": tx_orders,\n",
    "        \"order_items\": order_items,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f7d74eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # save\n",
    "\n",
    "# %%\n",
    "def write_all_parquet(txs: dict[str, pd.DataFrame], out_dir: Path) -> None:\n",
    "    save_parquet(txs[\"country_summary\"],   out_dir / \"country_summary.parquet\")\n",
    "    save_parquet(txs[\"country_channels\"],  out_dir / \"country_customers_by_channel.parquet\")\n",
    "    save_parquet(txs[\"country_channels_by_month\"],  out_dir / \"country_customers_by_channel_by_month.parquet\")\n",
    "    save_parquet(txs[\"city_summary\"],      out_dir / \"city_summary.parquet\")\n",
    "    save_parquet(txs[\"city_monthly\"],      out_dir / \"city_monthly_revenue.parquet\")\n",
    "    save_parquet(txs[\"customer_summary\"],  out_dir / \"customer_summary.parquet\")\n",
    "    save_parquet(txs[\"orders\"],            out_dir / \"orders.parquet\")\n",
    "    save_parquet(txs[\"order_items\"],       out_dir / \"order_items.parquet\")\n",
    "    print(f\"[done] wrote Parquet files to {out_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5932b3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] parsed Sweden\n",
      "[ok] parsed Denmark\n",
      "[ok] parsed Finland\n",
      "[ok] parsed Norway\n",
      "[done] wrote Parquet files to /workspace/data/processed\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Main\n",
    "\n",
    "# %%\n",
    "def main():\n",
    "    buckets = collect_buckets(COUNTRY_FILES)\n",
    "    txs = to_dataframes(buckets)\n",
    "    write_all_parquet(txs, OUTPUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda887b3",
   "metadata": {},
   "source": [
    "## do analytics and recs on order id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b327b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = pd.read_parquet(OUTPUT_DIR / \"order_items.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "643f5ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9150 rows; 306454 remain.\n"
     ]
    }
   ],
   "source": [
    "# drop non-product groupIds\n",
    "BAD = {\"12025DK\",\"12025FI\",\"12025NO\",\"12025SE\",\"970300\",\"459978\"}\n",
    "order_items[\"groupId\"] = order_items[\"groupId\"].astype(str).str.strip()\n",
    "n0 = len(order_items)\n",
    "order_items = order_items[~order_items[\"groupId\"].isin(BAD)].reset_index(drop=True)\n",
    "print(f\"Removed {n0 - len(order_items)} rows; {len(order_items)} remain.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5eed2682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] wrote /workspace/data/processed/top_categories_by_season.parquet\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Top Categories by Season\n",
    "\n",
    "def _season_from_month(m: int) -> str:\n",
    "    # Winter: Dec–Feb, Spring: Mar–May, Summer: Jun–Aug, Autumn: Sep–Nov\n",
    "    if m in (12, 1, 2):   return \"Winter\"\n",
    "    if m in (3, 4, 5):    return \"Spring\"\n",
    "    if m in (6, 7, 8):    return \"Summer\"\n",
    "    return \"Autumn\"\n",
    "\n",
    "def build_top_categories_by_season(\n",
    "    order_items: pd.DataFrame,\n",
    "    category_sep: str = \",\",\n",
    "    keep_top_n: int = 10,\n",
    ") -> pd.DataFrame:\n",
    "    tx = order_items.copy()\n",
    "\n",
    "    # --- types & defaults ---\n",
    "    tx[\"created\"]  = pd.to_datetime(tx[\"created\"], errors=\"coerce\")\n",
    "    tx[\"quantity\"] = pd.to_numeric(tx.get(\"quantity\"), errors=\"coerce\").fillna(1).astype(\"int64\")\n",
    "\n",
    "    def _norm(s: pd.Series) -> pd.Series:\n",
    "        s = s.astype(\"string[python]\")\n",
    "        s = s.where(~s.isna(), \"Unknown\")\n",
    "        return s.str.strip().fillna(\"Unknown\")\n",
    "\n",
    "    tx[\"country\"]  = _norm(tx.get(\"country\"))\n",
    "    tx[\"category\"] = _norm(tx.get(\"category\"))\n",
    "\n",
    "    # --- season label  ---\n",
    "    m = tx[\"created\"].dt.month\n",
    "    y = tx[\"created\"].dt.year\n",
    "    season = m.map(_season_from_month).fillna(\"Unknown\")\n",
    "    season_year = y - (m <= 2).astype(int)  # Jan–Feb belong to previous December’s year\n",
    "    tx[\"season_label\"] = (season + \" \" + season_year.astype(str)).astype(\"string[python]\")\n",
    "\n",
    "    # --- explode categories ---\n",
    "    cat_lists = (\n",
    "        tx[\"category\"]\n",
    "          .str.split(category_sep)\n",
    "          .apply(lambda parts: list(dict.fromkeys([p.strip() for p in (parts or []) if p and p.strip()])))\n",
    "    )\n",
    "    tx_exp = tx.loc[cat_lists.index, [\"country\",\"season_label\",\"quantity\"]].copy()\n",
    "    tx_exp[\"category\"] = cat_lists\n",
    "    tx_exp = tx_exp.explode(\"category\", ignore_index=True)\n",
    "    tx_exp[\"category\"] = _norm(tx_exp[\"category\"])\n",
    "\n",
    "    # --- aggregate & rank ---\n",
    "    agg = (\n",
    "        tx_exp.groupby([\"country\",\"season_label\",\"category\"], dropna=False)[\"quantity\"]\n",
    "              .sum().reset_index(name=\"count\")\n",
    "    )\n",
    "    agg[\"count\"] = agg[\"count\"].astype(\"int64\")\n",
    "\n",
    "    agg = agg.sort_values([\"country\",\"season_label\",\"count\"], ascending=[True, True, False])\n",
    "    agg[\"rank\"] = (\n",
    "        agg.groupby([\"country\",\"season_label\"])[\"count\"]\n",
    "           .rank(method=\"first\", ascending=False).astype(int)\n",
    "    )\n",
    "\n",
    "    top = (\n",
    "        agg[agg[\"rank\"] <= keep_top_n]\n",
    "        .sort_values([\"country\",\"season_label\",\"rank\"], ascending=[True, True, True])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return top[[\"country\",\"season_label\",\"category\",\"count\",\"rank\"]]\n",
    "\n",
    "tx_top = build_top_categories_by_season(order_items)\n",
    "tx_top.to_parquet(OUTPUT_DIR / \"top_categories_by_season.parquet\", index=False)\n",
    "print(f\"[done] wrote {(OUTPUT_DIR / 'top_categories_by_season.parquet').resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29cb560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] wrote /workspace/data/processed/top_groupids_by_season.parquet\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Top Products by Season\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def _season_from_month(m: int) -> str:\n",
    "    if m in (12, 1, 2):   return \"Winter\"\n",
    "    if m in (3, 4, 5):    return \"Spring\"\n",
    "    if m in (6, 7, 8):    return \"Summer\"\n",
    "    return \"Autumn\"\n",
    "\n",
    "def build_top_groupids_by_season(\n",
    "    order_items: pd.DataFrame,\n",
    "    keep_top_n: int = 100,\n",
    ") -> pd.DataFrame:\n",
    "    tx = order_items.copy()\n",
    "\n",
    "    # --- types & defaults ---\n",
    "    tx[\"created\"]  = pd.to_datetime(tx[\"created\"], errors=\"coerce\")\n",
    "    tx[\"quantity\"] = pd.to_numeric(tx.get(\"quantity\"), errors=\"coerce\").fillna(1).astype(\"int64\")\n",
    "\n",
    "    def _norm(s: pd.Series) -> pd.Series:\n",
    "        s = s.astype(\"string[python]\")\n",
    "        s = s.where(~s.isna(), \"Unknown\")\n",
    "        return s.str.strip().fillna(\"Unknown\")\n",
    "\n",
    "    tx[\"country\"] = _norm(tx.get(\"country\"))\n",
    "    tx[\"groupId\"] = _norm(tx.get(\"groupId\"))\n",
    "    tx[\"brand\"]   = _norm(tx.get(\"brand\"))\n",
    "    tx[\"name\"] = _norm(tx[\"name\"])\n",
    "\n",
    "    # --- season label (Winter labeled by December’s year: Dec–Feb) ---\n",
    "    m = tx[\"created\"].dt.month\n",
    "    y = tx[\"created\"].dt.year\n",
    "    season = m.map(_season_from_month).fillna(\"Unknown\")\n",
    "    season_year = y - (m <= 2).astype(int)  # Jan–Feb belong to previous December’s year\n",
    "    tx[\"season_label\"] = (season + \" \" + season_year.astype(str)).astype(\"string[python]\")\n",
    "\n",
    "    # --- aggregate counts by groupId ---\n",
    "    gid_agg = (\n",
    "        tx.groupby([\"country\",\"season_label\",\"groupId\"], dropna=False)[\"quantity\"]\n",
    "          .sum()\n",
    "          .reset_index(name=\"count\")\n",
    "    )\n",
    "    gid_agg[\"count\"] = gid_agg[\"count\"].astype(\"int64\")\n",
    "\n",
    "    # representative (name, brand) per (country, season_label, groupId)\n",
    "    rep_meta = (\n",
    "        tx.groupby([\"country\",\"season_label\",\"groupId\",\"name\",\"brand\"], dropna=False)[\"quantity\"]\n",
    "          .sum().reset_index(name=\"qty\")\n",
    "          .sort_values([\"country\",\"season_label\",\"groupId\",\"qty\",\"name\",\"brand\"],\n",
    "                       ascending=[True, True, True, False, True, True])\n",
    "          .drop_duplicates([\"country\",\"season_label\",\"groupId\"])\n",
    "          .rename(columns={\"name\":\"rep_name\",\"brand\":\"rep_brand\"})\n",
    "          [[\"country\",\"season_label\",\"groupId\",\"rep_name\",\"rep_brand\"]]\n",
    "    )\n",
    "    gid_agg = gid_agg.merge(rep_meta, on=[\"country\",\"season_label\",\"groupId\"], how=\"left\")\n",
    "\n",
    "    # --- rank within (country, season) and take top N ---\n",
    "    gid_agg = gid_agg.sort_values([\"country\",\"season_label\",\"count\"], ascending=[True, True, False])\n",
    "    gid_agg[\"rank\"] = (\n",
    "        gid_agg.groupby([\"country\",\"season_label\"])[\"count\"]\n",
    "               .rank(method=\"first\", ascending=False).astype(int)\n",
    "    )\n",
    "    top = (\n",
    "        gid_agg[gid_agg[\"rank\"] <= keep_top_n]\n",
    "        .sort_values([\"country\",\"season_label\",\"rank\"])\n",
    "        .rename(columns={\"groupId\":\"value\", \"rep_name\":\"name\", \"rep_brand\":\"brand\"})\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # schema\n",
    "    return top[[\"country\",\"season_label\",\"value\",\"name\",\"brand\",\"count\",\"rank\"]]\n",
    "\n",
    "tx_top = build_top_groupids_by_season(order_items)\n",
    "tx_top.to_parquet(OUTPUT_DIR / \"top_groupids_by_season.parquet\", index=False)\n",
    "print(f\"[done] wrote {(OUTPUT_DIR / 'top_groupids_by_season.parquet').resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ebaebd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Top Repurchased Products by Country\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def build_top_repurchase_groupids_by_country_unique_days(\n",
    "    order_items: pd.DataFrame,\n",
    "    unique_days_threshold: int = 1,   # more than 2 different dates\n",
    "    keep_top_n: int = 100,\n",
    ") -> pd.DataFrame:\n",
    "    tx = order_items.copy()\n",
    "\n",
    "    # --- types & normalization ---\n",
    "    tx[\"created\"] = pd.to_datetime(tx.get(\"created\"), errors=\"coerce\")\n",
    "    tx = tx.dropna(subset=[\"created\"])\n",
    "    tx[\"purchase_date\"] = tx[\"created\"].dt.normalize()\n",
    "\n",
    "    # quantity: convert to int, no fillna necessary as quantity is never missing\n",
    "    tx[\"quantity\"] = pd.to_numeric(tx[\"quantity\"], errors=\"coerce\").astype(\"int64\")\n",
    "\n",
    "    def _safe_series(colname: str) -> pd.Series:\n",
    "        return tx[colname] if colname in tx.columns else pd.Series(pd.NA, index=tx.index)\n",
    "\n",
    "    def _norm(s: pd.Series) -> pd.Series:\n",
    "        s = s.astype(\"string[python]\")\n",
    "        s = s.where(~s.isna(), \"Unknown\")\n",
    "        return s.str.strip().fillna(\"Unknown\")\n",
    "\n",
    "    tx[\"country\"]     = _norm(_safe_series(\"country\"))\n",
    "    tx[\"groupId\"]     = _norm(_safe_series(\"groupId\"))\n",
    "    tx[\"customer_id\"] = _norm(_safe_series(\"customer_id\"))\n",
    "    tx[\"brand\"]       = _norm(_safe_series(\"brand\"))\n",
    "    tx[\"name\"] = _norm(tx[\"name\"])\n",
    "\n",
    "    # ---------- per customer, per (country, groupId): count unique purchase dates ----------\n",
    "    per_cust = (\n",
    "        tx.groupby([\"country\",\"groupId\",\"customer_id\"], dropna=False)\n",
    "          .agg(unique_days=(\"purchase_date\", pd.Series.nunique))\n",
    "          .reset_index()\n",
    "    )\n",
    "    eligible = per_cust[per_cust[\"unique_days\"] > unique_days_threshold].copy()\n",
    "\n",
    "    # ---------- # of repurchasing customers per (country, groupId) ----------\n",
    "    rep_counts = (\n",
    "        eligible.groupby([\"country\",\"groupId\"], dropna=False)[\"customer_id\"]\n",
    "                .nunique().reset_index(name=\"repurchasers\")\n",
    "        .astype({\"repurchasers\":\"int64\"})\n",
    "    )\n",
    "\n",
    "    # ---------- representative (name, brand) computed among repurchasers only ----------\n",
    "    rep_keys = eligible[[\"country\",\"groupId\",\"customer_id\"]]\n",
    "    tx_rep = tx.merge(rep_keys, on=[\"country\",\"groupId\",\"customer_id\"], how=\"inner\")\n",
    "\n",
    "    name_weight = (\n",
    "        tx_rep.groupby([\"country\",\"groupId\",\"name\",\"brand\"], dropna=False)[\"quantity\"]\n",
    "              .sum().reset_index(name=\"qty\")\n",
    "    )\n",
    "    # pick (name, brand) with highest qty; tie-break by name\n",
    "    rep_meta = (\n",
    "        name_weight.sort_values([\"country\",\"groupId\",\"qty\",\"name\",\"brand\"],\n",
    "                                ascending=[True, True, False, True, True])\n",
    "                   .drop_duplicates([\"country\",\"groupId\"])\n",
    "                   .rename(columns={\"name\":\"rep_name\", \"brand\":\"rep_brand\"})\n",
    "                   [[\"country\",\"groupId\",\"rep_name\",\"rep_brand\"]]\n",
    "    )\n",
    "\n",
    "    out = rep_counts.merge(rep_meta, on=[\"country\",\"groupId\"], how=\"left\")\n",
    "\n",
    "    # ---------- rank within country & top-N ----------\n",
    "    out = out.sort_values([\"country\",\"repurchasers\"], ascending=[True, False])\n",
    "    out[\"rank\"] = out.groupby(\"country\")[\"repurchasers\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "\n",
    "    top = (out[out[\"rank\"] <= keep_top_n]\n",
    "           .sort_values([\"country\",\"rank\"])\n",
    "           .rename(columns={\"groupId\":\"value\", \"rep_name\":\"name\", \"rep_brand\":\"brand\"})\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "    return top[[\"country\",\"value\",\"name\",\"brand\",\"repurchasers\",\"rank\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3d1a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] wrote /workspace/data/processed/top_repurchase_groupids_by_country.parquet\n",
      " value                                                         name                 brand  repurchasers  rank\n",
      "260695                                              Seamless BH-top                Louise            85     1\n",
      "260646                                            Dametrusser 3-pak                Åshild            63     2\n",
      "240187                                                  Fritidsbuks                Åshild            57     3\n",
      "241562                                                 Velourbukser                Åshild            57     4\n",
      "260513                                                BH uden bøjle             Glamorise            57     5\n",
      "261637                                              Ankelsokker VID         Locköstrumpan            53     6\n",
      "210338                                                T-shirt 2-pak                Åshild            42     7\n",
      "265843 Bomulds-BH uden bøjle med Magic Lift-function Cotton Support             Glamorise            41     8\n",
      "210695                                            T-shirt Langærmet                Åshild            40     9\n",
      "263988                                             Støtteknæstrømpe             Funq Wear            40    10\n",
      "210186                                                   Turtleneck                Åshild            37    11\n",
      "263855                                                BH uden bøjle             Glamorise            36    12\n",
      "260596                                          BH uden bøjle Stars              Swegmark            35    13\n",
      "261370                                    BH uden bøjle Cotton Dots             Miss Mary            27    14\n",
      "260406                                                BH uden bøjle                Louise            26    15\n",
      "260802                              BH uden bøjle Broderie Anglaise             Miss Mary            26    16\n",
      "264804                                                BH uden bøjle             Glamorise            26    17\n",
      "261618                             Stretchtrusse 2-pak Control Maxi                Sloggi            23    18\n",
      "260711                                        BH uden bøjle Diamond             Miss Mary            22    19\n",
      "260463                                         Trusser 3-pak Louise                Louise            20    20\n",
      "260313                        BH uden bøjle med Magic-lift funktion             Glamorise            18    21\n",
      "266494                                             Støtteknæstrømpe             Funq Wear            18    22\n",
      "240176                                    Bukser med elastiklinning                Åshild            17    23\n",
      "242305                                                        Jeans                Åshild            17    24\n",
      "250128                                                  Fleecejakke                Åshild            17    25\n",
      "242289                                                          WCT                Åshild            16    26\n",
      "265298                                                Trusser 2-pak                Louise            16    27\n",
      "242024                                                     Leggings                Åshild            15    28\n",
      "260474                                               Frontlukket BH                Louise            15    29\n",
      "261040                                 Medicinske knæstrømper 2-pak                Louise            15    30\n",
      "265041                                                      Leggins                Louise            15    31\n",
      "266072                                                    Sports-BH             Glamorise            15    32\n",
      "210737                                  T-shirt med blomstermønster                Åshild            14    33\n",
      "218982                                                      T-shirt                Åshild            14    34\n",
      "240144                                                       Bukser                Åshild            14    35\n",
      "240184                                     Jeans med elastiklinning                Åshild            14    36\n",
      "240191                                              Bukser Krøllede                Åshild            14    37\n",
      "242511                               Bomuldsbukser Julia Lang model                Åshild            14    38\n",
      "261610                              Stretchtrusser 2-pak Basic Maxi                Sloggi            14    39\n",
      "261933                                         Stretchtrusser 3-pak                Louise            14    40\n",
      "261990                                         Stretchtrusser 3-pak                Louise            14    41\n",
      "290206                                          Engangslagen 25 stk              Hartmann            14    42\n",
      "200400                                    Sort taske med skulderrem                Åshild            13    43\n",
      "242214                                                   Bukser 7/8                Åshild            13    44\n",
      "260455                                                Trusser 4-pak                Louise            13    45\n",
      "261475                                                    Benklæder                Louise            13    46\n",
      "261595                                   Strømpebukser 5-pak Emilia                Emilia            12    47\n",
      "264234                                          BH-forlængere 2-pak                 Trofé            12    48\n",
      "210691                                       Polojumper med mønster                Åshild            11    49\n",
      "210752                                         Bluse med flæseærmer                Åshild            11    50\n",
      "242131                                                       Bukser                Åshild            11    51\n",
      "260620                                         Stretchtrusser 3-pak                Louise            11    52\n",
      "260949                                                  Toppe 2 pak                Louise            11    53\n",
      "260973                                       Maxitrusser Gill 3-pak                Louise            11    54\n",
      "261616                                   Stretchtrusse Control Maxi                Sloggi            11    55\n",
      "261620                                        Stretchtrusse Romance                Sloggi            11    56\n",
      "261699                                        Anti-skridsokker Safe         Locköstrumpan            11    57\n",
      "266064                                         Bøjle-BH Frontlukket             Glamorise            11    58\n",
      "210686                                        Trøje Lang gråmeleret                Åshild            10    59\n",
      "210735                                   Tunika med blomstermønster                Åshild            10    60\n",
      "210746                                    Kortærmet strikket jumper                Åshild            10    61\n",
      "260557                                          Boksertrusse sømløs                Louise            10    62\n",
      "260965                                            Body Happy Hearts             Miss Mary            10    63\n",
      "261924                                   Kompressionstrømper bambus The Doctor Recommends            10    64\n",
      "266643                                          BH uden bøjle Betty                 Trofé            10    65\n",
      "210756                                                       Tunika                Åshild             9    66\n",
      "221416                                                Jeansnederdel                Åshild             9    67\n",
      "240108                                  Bomuldsbukser i capri model                Åshild             9    68\n",
      "241091                                                  Capribukser                Åshild             9    69\n",
      "241653                                                       Bukser                Åshild             9    70\n",
      "241687                                                     Leggings                Åshild             9    71\n",
      "260182                                       Støtteknæstrømpe 2-pak                Louise             9    72\n",
      "260257                                       Støtteknæstrømpe 2-pak                Louise             9    73\n",
      "263343             BH uden bøjle Miss Mary Lovely Jaquard Miss Mary             Miss Mary             9    74\n",
      "264275                                                Trusser 3-pak                Louise             9    75\n",
      "266825                                       BH uden bøjle Treasure              Swegmark             9    76\n",
      "270535                                         Velourdress Viktoria                Åshild             9    77\n",
      "210150                                                   Turtleneck                Åshild             8    78\n",
      "210727                                                        Bluse                Åshild             8    79\n",
      "240276                                                 Bukser Karla                Åshild             8    80\n",
      "240995                                                Culottebukser                Åshild             8    81\n",
      "250209                                                  Helsetøffel                Åshild             8    82\n",
      "260935                                                   Mamelukker                Åshild             8    83\n",
      "260976                                             Undertrøje i uld                Åshild             8    84\n",
      "261123                                        Body  Fanstatic Flair             Miss Mary             8    85\n",
      "261192                                            Knæstrømper 5-pak                Emilia             8    86\n",
      "261427                                                Trusser 3-pak                Louise             8    87\n",
      "261476                                                Trusser 3-pak                Louise             8    88\n",
      "261881                                                   Bomulds-BH                Emilia             8    89\n",
      "261888                                                 Top i bambus                Louise             8    90\n",
      "270544                                     Natkjole med V-udskæring               unknown             8    91\n",
      "270599                                     Natkjole med V-udskæring               unknown             8    92\n",
      "220027                                               Denim nederdel                Åshild             7    93\n",
      "250130                                                        Jakke                Åshild             7    94\n",
      "260090                                         Trofé Bøjle-BH Sanna                 Trofé             7    95\n",
      "260174                                       Knæstøtte med magneter           Good Living             7    96\n",
      "260230                                        Bomulds-BH uden bøjle                Louise             7    97\n",
      "260380                                                 Støttetrusse                Louise             7    98\n",
      "260601                                BH uden bøjle med flot blonde                Louise             7    99\n",
      "261436                                                  Uldstrømper                Åshild             7   100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tx_top_repurchase_country = build_top_repurchase_groupids_by_country_unique_days(\n",
    "    order_items,\n",
    ")\n",
    "\n",
    "out_path = OUTPUT_DIR / \"top_repurchase_groupids_by_country.parquet\"\n",
    "tx_top_repurchase_country.to_parquet(out_path, index=False)\n",
    "print(f\"[done] wrote {out_path.resolve()}\")\n",
    "\n",
    "#  peek for Denmark\n",
    "print(\n",
    "    tx_top_repurchase_country.query(\"country == 'Denmark'\")\n",
    "                             .sort_values(\"rank\")[[\"value\",\"name\", \"brand\", \"repurchasers\",\"rank\"]]\n",
    "                             .to_string(index=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72eb6d9",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\mathrm{tf}_{ij} &\\coloneqq \\text{\\# orders containing both } i \\text{ and } j \\\\[2pt]\n",
    "\\mathrm{df}_i    &\\coloneqq \\text{\\# orders containing } i \\\\[2pt]\n",
    "\\mathrm{df}_j    &\\coloneqq \\text{\\# orders containing } j \\\\[2pt]\n",
    "N                &\\coloneqq \\text{total \\# orders}\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "### Support floor\n",
    "\n",
    "$$\n",
    "\\mathrm{tf}_{ij} \\;\\ge\\; S_{\\min}\\quad(\\text{use } S_{\\min}=40)\n",
    "$$\n",
    "\n",
    "### Beats chance (log-lift)\n",
    "\n",
    "$$\n",
    "E_{ij} \\;=\\; \\frac{\\mathrm{df}_i \\cdot \\mathrm{df}_j}{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{lift}_{ij} \\;=\\; \\frac{\\mathrm{tf}_{ij}}{E_{ij}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\log\\mathrm{lift}_{ij} \\;=\\; \\ln\\!\\big(\\mathrm{lift}_{ij}\\big) \\;\\;\\;\\text{and we keep pairs with }\\; \\log\\mathrm{lift}_{ij} \\ge 0.5\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a12c601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_a</th>\n",
       "      <th>item_a_name</th>\n",
       "      <th>item_b</th>\n",
       "      <th>item_b_name</th>\n",
       "      <th>pair_orders</th>\n",
       "      <th>itemA_orders</th>\n",
       "      <th>itemB_orders</th>\n",
       "      <th>lift</th>\n",
       "      <th>log_lift</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200965</td>\n",
       "      <td>Stickad mössa</td>\n",
       "      <td>200970</td>\n",
       "      <td>Stickad tumvante</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>1347.864630</td>\n",
       "      <td>7.206277</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270307</td>\n",
       "      <td>Bikini-bh Bondi</td>\n",
       "      <td>270308</td>\n",
       "      <td>Bikinitrosa Bondi</td>\n",
       "      <td>74</td>\n",
       "      <td>118</td>\n",
       "      <td>88</td>\n",
       "      <td>801.806818</td>\n",
       "      <td>6.686868</td>\n",
       "      <td>0.042369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210412</td>\n",
       "      <td>Topp</td>\n",
       "      <td>240034</td>\n",
       "      <td>Byxa av bambu</td>\n",
       "      <td>44</td>\n",
       "      <td>91</td>\n",
       "      <td>280</td>\n",
       "      <td>194.292465</td>\n",
       "      <td>5.269365</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261405</td>\n",
       "      <td>Undertröja älg</td>\n",
       "      <td>261426</td>\n",
       "      <td>Långkalsong</td>\n",
       "      <td>117</td>\n",
       "      <td>180</td>\n",
       "      <td>465</td>\n",
       "      <td>157.276237</td>\n",
       "      <td>5.058004</td>\n",
       "      <td>0.016490</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>503380</td>\n",
       "      <td>Örngott 50x60 cm 1-Pack</td>\n",
       "      <td>507863</td>\n",
       "      <td>Underlakan 150x250 cm</td>\n",
       "      <td>59</td>\n",
       "      <td>283</td>\n",
       "      <td>262</td>\n",
       "      <td>89.529671</td>\n",
       "      <td>4.494570</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_a              item_a_name  item_b            item_b_name  \\\n",
       "0  200965            Stickad mössa  200970       Stickad tumvante   \n",
       "1  270307          Bikini-bh Bondi  270308      Bikinitrosa Bondi   \n",
       "2  210412                     Topp  240034          Byxa av bambu   \n",
       "3  261405           Undertröja älg  261426            Långkalsong   \n",
       "4  503380  Örngott 50x60 cm 1-Pack  507863  Underlakan 150x250 cm   \n",
       "\n",
       "   pair_orders  itemA_orders  itemB_orders         lift  log_lift     score  \\\n",
       "0           40            63            53  1347.864630  7.206277  0.064266   \n",
       "1           74           118            88   801.806818  6.686868  0.042369   \n",
       "2           44            91           280   194.292465  5.269365  0.023848   \n",
       "3          117           180           465   157.276237  5.058004  0.016490   \n",
       "4           59           283           262    89.529671  4.494570  0.015036   \n",
       "\n",
       "   rank  \n",
       "0     1  \n",
       "1     2  \n",
       "2     3  \n",
       "3     4  \n",
       "4     5  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, itertools, math\n",
    "from collections import Counter\n",
    "\n",
    "S_MIN = 40                 # support floor (distinct orders with both items)\n",
    "LOG_LIFT_MIN = 0.5         # keep only pairs better than chance (try 0.2–0.7 to tighten)\n",
    "MAX_PAIRS_PER_ITEM = 6     # cap: max pairs any single item can appear in (as A or B) as popular items still overtake recs\n",
    "\n",
    "df = order_items.copy() \n",
    "\n",
    "recs = order_items[[\"order_id\",\"groupId\",\"name\",\"country\"]].astype({\"order_id\": str, \"groupId\": str})\n",
    "\n",
    "# Canonical name: Sweden first, else global\n",
    "sw = (recs[recs[\"country\"]==\"Sweden\"].dropna(subset=[\"name\"])\n",
    "        .groupby(\"groupId\")[\"name\"].agg(lambda s: s.value_counts().index[0]).to_dict())\n",
    "glob = (recs.dropna(subset=[\"name\"]).groupby(\"groupId\")[\"name\"]\n",
    "        .agg(lambda s: s.value_counts().index[0]).to_dict())\n",
    "name_map = {gid: sw.get(gid, glob.get(gid)) for gid in set(df[\"groupId\"])}\n",
    "\n",
    "\n",
    "# Unique items per order\n",
    "recs = (df.drop_duplicates([\"order_id\",\"groupId\"])\n",
    "                 .groupby(\"order_id\")[\"groupId\"].apply(list))\n",
    "N = len(recs)\n",
    "\n",
    "# Frequencies\n",
    "item_df = Counter(itertools.chain.from_iterable(map(set, recs)))\n",
    "\n",
    "# Pair counts\n",
    "pair_counts = Counter()\n",
    "for items in recs:\n",
    "    for a, b in itertools.combinations(sorted(set(items)), 2):\n",
    "        pair_counts[(a, b)] += 1\n",
    "\n",
    "# Scoring + filters\n",
    "rows = []\n",
    "for (a, b), tf in pair_counts.items():\n",
    "    if tf < S_MIN:\n",
    "        continue\n",
    "    dfa, dfb = item_df[a], item_df[b]\n",
    "    expected = (dfa * dfb) / N\n",
    "    if expected <= 0:\n",
    "        continue\n",
    "    lift = tf / expected\n",
    "    log_lift = math.log(lift)\n",
    "    if log_lift <= LOG_LIFT_MIN:\n",
    "        continue\n",
    "\n",
    "    score = math.log(1 + tf) / math.sqrt(dfa * dfb)\n",
    "    rows.append((a, name_map.get(a), b, name_map.get(b),\n",
    "                 tf, dfa, dfb, lift, log_lift, score))\n",
    "\n",
    "res = pd.DataFrame(rows, columns=[\n",
    "    \"item_a\",\"item_a_name\",\"item_b\",\"item_b_name\",\n",
    "    \"pair_orders\",\"itemA_orders\",\"itemB_orders\",\"lift\",\"log_lift\",\"score\"\n",
    "])\n",
    "\n",
    "# Cap appearances per item (A or B)\n",
    "res_sorted = res.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "kept_rows, appear_counts = [], Counter()\n",
    "for _, r in res_sorted.iterrows():\n",
    "    a, b = r[\"item_a\"], r[\"item_b\"]\n",
    "    if appear_counts[a] < MAX_PAIRS_PER_ITEM and appear_counts[b] < MAX_PAIRS_PER_ITEM:\n",
    "        kept_rows.append(r)\n",
    "        appear_counts[a] += 1\n",
    "        appear_counts[b] += 1\n",
    "\n",
    "final = pd.DataFrame(kept_rows).reset_index(drop=True)\n",
    "\n",
    "# add rank (1 = best after all filters & cap)\n",
    "final[\"rank\"] = (final[\"score\"]\n",
    "                 .rank(method=\"dense\", ascending=False)\n",
    "                 .astype(int))\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a05f670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/processed/pair_complemenets.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"../data/processed\"\n",
    "final_to_save = final[[\"rank\",\"item_a\",\"item_a_name\",\"item_b\",\"item_b_name\"]].copy()\n",
    "final_to_save.columns = [\"Rank by Affinity Strength\", \"Product A ID\", \"Product A\", \"Product B ID\", \"Product B\"]\n",
    "\n",
    "output_path = os.path.join(output_dir, \"pair_complemenets.parquet\")\n",
    "final_to_save.to_parquet(output_path, index=False)\n",
    "print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "210c1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Top Brands by Country\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def build_top_brands_by_country(tx: pd.DataFrame, keep_top_n: int = 10) -> pd.DataFrame:\n",
    "    d = tx.copy()\n",
    "    d[\"quantity\"] = pd.to_numeric(d[\"quantity\"], errors=\"coerce\").fillna(1).astype(\"int64\")\n",
    "    d[\"country\"] = d[\"country\"].astype(\"string\")\n",
    "    d[\"brand\"]   = d[\"brand\"].astype(\"string\").str.strip()\n",
    "    d = d[d[\"brand\"].notna() & ~d[\"brand\"].str.lower().isin({\"unknown\",\"na\",\"\"})]\n",
    "\n",
    "    g = (d.groupby([\"country\",\"brand\"], dropna=False)[\"quantity\"]\n",
    "           .sum().rename(\"count\").reset_index())\n",
    "    g = g.sort_values([\"country\",\"count\",\"brand\"], ascending=[True,False,True])\n",
    "    g[\"rank\"] = g.groupby(\"country\")[\"count\"].rank(\"first\", ascending=False).astype(int)\n",
    "    return (g[g[\"rank\"] <= keep_top_n]\n",
    "              .sort_values([\"country\",\"rank\"])\n",
    "              .reset_index(drop=True)[[\"country\",\"brand\",\"count\",\"rank\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11a343f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        brand  count  rank\n",
      "       Åshild  16694     1\n",
      "       Louise   6836     2\n",
      "    Glamorise   2956     3\n",
      "  Good Living   2656     4\n",
      "    Miss Mary   2399     5\n",
      "       Sloggi   1232     6\n",
      "Locköstrumpan   1156     7\n",
      "        Trofé    931     8\n",
      "     Swegmark    822     9\n",
      "    Funq Wear    789    10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tx_top_brands = build_top_brands_by_country(order_items, keep_top_n=10)\n",
    "tx_top_brands.to_parquet(OUTPUT_DIR / \"top_brands_by_country.parquet\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "#  peek for Denmark\n",
    "print(\n",
    "    tx_top_brands.query(\"country == 'Denmark'\")\n",
    "                    .sort_values(\"rank\")[[\"brand\",\"count\",\"rank\"]]\n",
    "                    .to_string(index=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0366011",
   "metadata": {},
   "source": [
    "Each customer is counted once, in a mutually exclusive bucket based on the time from their first purchase to their first return on a different date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67ced722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Return Buckets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def bucket_return_days(d: int) -> str | pd.NA:\n",
    "    if pd.isna(d) or d <= 0:          return pd.NA          # no return or same-day only\n",
    "    if 1 <= d <= 7:                   return \"week 1\"\n",
    "    if 8 <= d <= 14:                  return \"week 2\"\n",
    "    if 15 <= d <= 21:                 return \"week 3\"\n",
    "    if 22 <= d <= 30:                 return \"1 month\"\n",
    "    # months as 30-day blocks up to 12 months\n",
    "    for m in range(2, 13):            # 2..12 months\n",
    "        lo, hi = 30*(m-1)+1, 30*m     # e.g., 31-60, 61-90, ...\n",
    "        if lo <= d <= hi:             return f\"{m} months\"\n",
    "    if d > 365:                       return \"> 1 year\"\n",
    "    return pd.NA\n",
    "\n",
    "def count_return_buckets(order_items: pd.DataFrame) -> pd.DataFrame:\n",
    "    tx = order_items.copy()\n",
    "    tx[\"created\"] = pd.to_datetime(tx[\"created\"], errors=\"coerce\")\n",
    "    tx = tx.dropna(subset=[\"created\", \"customer_id\"])\n",
    "    tx[\"purchase_date\"] = tx[\"created\"].dt.date\n",
    "\n",
    "    # unique purchase dates per customer\n",
    "    uniq = tx[[\"customer_id\",\"purchase_date\"]].drop_duplicates()\n",
    "\n",
    "    # first purchase per customer\n",
    "    first_date = uniq.groupby(\"customer_id\")[\"purchase_date\"].min().rename(\"first_date\")\n",
    "\n",
    "    # earliest purchase strictly AFTER first_date → first return date\n",
    "    tmp = uniq.merge(first_date, on=\"customer_id\")\n",
    "    tmp = tmp[tmp[\"purchase_date\"] > tmp[\"first_date\"]]\n",
    "    first_return = tmp.groupby(\"customer_id\")[\"purchase_date\"].min().rename(\"first_return_date\")\n",
    "\n",
    "    # join and compute delta days\n",
    "    timeline = first_date.to_frame().merge(first_return, left_index=True, right_index=True, how=\"left\")\n",
    "    timeline[\"days_to_return\"] = (pd.to_datetime(timeline[\"first_return_date\"]) - \n",
    "                                  pd.to_datetime(timeline[\"first_date\"])).dt.days\n",
    "\n",
    "    # bucketize (mutually exclusive)\n",
    "    timeline[\"bucket\"] = timeline[\"days_to_return\"].apply(bucket_return_days)\n",
    "\n",
    "    # keep only customers who returned (bucket not NA)\n",
    "    ret = timeline.dropna(subset=[\"bucket\"])\n",
    "\n",
    "    # counts by bucket\n",
    "    counts = (ret.groupby(\"bucket\").size().reset_index(name=\"customers\")\n",
    "                .sort_values(\"customers\", ascending=False)\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "    # enforce a readable bucket order\n",
    "    order = ([\"week 1\",\"week 2\",\"week 3\",\"1 month\"] +\n",
    "             [f\"{m} months\" for m in range(2,13)] + [\"> 1 year\"])\n",
    "    counts[\"order\"] = counts[\"bucket\"].map({b:i for i,b in enumerate(order)})\n",
    "    counts = counts.sort_values(\"order\").drop(columns=\"order\").reset_index(drop=True)\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c71fffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bucket  customers\n",
      "0      week 1       1325\n",
      "1      week 2       1768\n",
      "2      week 3       1271\n",
      "3     1 month       1306\n",
      "4    2 months       3180\n",
      "5    3 months       2502\n",
      "6    4 months       2252\n",
      "7    5 months       1883\n",
      "8    6 months       2123\n",
      "9    7 months       1775\n",
      "10   8 months       1410\n",
      "11   9 months        996\n",
      "12  10 months        772\n",
      "13  11 months        713\n",
      "14  12 months        583\n",
      "15   > 1 year        958\n"
     ]
    }
   ],
   "source": [
    "tx_buckets = count_return_buckets(order_items)\n",
    "print(tx_buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66661cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_buckets.to_parquet(\"../data/processed/return_buckets_overall.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a56d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc4565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e01c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (itcm-recsys)",
   "language": "python",
   "name": "itcm-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
