{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e0ea0c",
   "metadata": {},
   "source": [
    "## Assemble a DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1421a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13091878",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_parquet(\n",
    "    \"/workspace/data/processed/articles_for_recs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afd651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 18 rows with priceSEK < 1\n"
     ]
    }
   ],
   "source": [
    "groups['priceSEK'] = pd.to_numeric(groups['priceSEK'], errors='coerce')\n",
    "before_count = len(groups)\n",
    "groups = groups[groups['priceSEK'] >= 1]\n",
    "after_count = len(groups)\n",
    "print(f\"Dropped {before_count - after_count} rows with priceSEK < 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82550ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create price buckets based on the distribution of price_sek, using 6 buckets\n",
    "price_bins = [0, 100, 300, 600, 1000, 2000, float('inf')]\n",
    "price_labels = [\n",
    "    'Budget',\n",
    "    'Value',\n",
    "    'Popular',\n",
    "    'Premium',\n",
    "    'Luxury',\n",
    "    'Exclusive'\n",
    "]\n",
    "groups['priceband'] = pd.cut(groups['priceSEK'], bins=price_bins, labels=price_labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55aac7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'audienceId' in groups.columns:\n",
    "    groups = groups.drop(columns=['audienceId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5076eebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>audience</th>\n",
       "      <th>category</th>\n",
       "      <th>priceSEK</th>\n",
       "      <th>description</th>\n",
       "      <th>color</th>\n",
       "      <th>priceband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>055522</td>\n",
       "      <td>Beskrivning Tröja</td>\n",
       "      <td>Gjestal Garn</td>\n",
       "      <td>dam</td>\n",
       "      <td>Tröjor</td>\n",
       "      <td>29</td>\n",
       "      <td>Sticka en färgglad och trendig tröja i garnet ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>055573</td>\n",
       "      <td>Luva Hygge</td>\n",
       "      <td>Novita</td>\n",
       "      <td>dam</td>\n",
       "      <td>Mössor &amp; hattar,Mönster</td>\n",
       "      <td>29</td>\n",
       "      <td>Sticka en trendig huva i garnet Halaus från No...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>055575</td>\n",
       "      <td>Beskrivning Vantar</td>\n",
       "      <td>Novita</td>\n",
       "      <td>dam</td>\n",
       "      <td>Vantar</td>\n",
       "      <td>29</td>\n",
       "      <td>Sticka ett par vantar med blomstermotiv i garn...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>055576</td>\n",
       "      <td>Beskrivning Benvärmare</td>\n",
       "      <td>Novita</td>\n",
       "      <td>dam</td>\n",
       "      <td>Sockor &amp; strumpor</td>\n",
       "      <td>29</td>\n",
       "      <td>Sticka ett par trendiga benvärmare i garnet Ha...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>095302</td>\n",
       "      <td>Garn Drops Nepal</td>\n",
       "      <td>Drops Design</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>unknown</td>\n",
       "      <td>33</td>\n",
       "      <td>Garn Drops Nepal är ett underbart tjockt luxuö...</td>\n",
       "      <td>[Beige, Blush, Blå, Blå/grön, Cerise, Grå, Grå...</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>590838</td>\n",
       "      <td>Madrasskydd Plastad frotté</td>\n",
       "      <td>Linea</td>\n",
       "      <td>hemmet</td>\n",
       "      <td>Bäddtillbehör,Bädd,Inkontinens,Bädd (linea)</td>\n",
       "      <td>359</td>\n",
       "      <td>Hygienisk och vattenavvisande yta. OEKO-TEX.Pl...</td>\n",
       "      <td>[Vit]</td>\n",
       "      <td>Popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>590841</td>\n",
       "      <td>5-meterklipp Plastad frotté</td>\n",
       "      <td>Linea</td>\n",
       "      <td>hemmet</td>\n",
       "      <td>Bäddtillbehör,Bädd,Inkontinens,Bädd (linea)</td>\n",
       "      <td>398</td>\n",
       "      <td>Hygienisk och vattenavvisande yta. OEKO-TEX. P...</td>\n",
       "      <td>[Vit]</td>\n",
       "      <td>Popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>598005</td>\n",
       "      <td>Gardinkappa Sanna enfärgad med spets</td>\n",
       "      <td>Fondaco</td>\n",
       "      <td>hemmet</td>\n",
       "      <td>Kanalkappa</td>\n",
       "      <td>249</td>\n",
       "      <td>Underbar gardinkappa med vacker spetsdetalj.Ko...</td>\n",
       "      <td>[Grön, Linne, Röd]</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>790196</td>\n",
       "      <td>Fingerborg 17 mm</td>\n",
       "      <td>Ateljé Margaretha</td>\n",
       "      <td>generic</td>\n",
       "      <td>Sytillbehör,Vardagshjälpmedel</td>\n",
       "      <td>19</td>\n",
       "      <td>Fingerborg, storlek 17 mm.</td>\n",
       "      <td>[]</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>970100</td>\n",
       "      <td>Frakt- &amp; exp.avgift</td>\n",
       "      <td>unknown</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>unknown</td>\n",
       "      <td>69</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1702 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     groupId                                  name              brand  \\\n",
       "0     055522                     Beskrivning Tröja       Gjestal Garn   \n",
       "1     055573                            Luva Hygge             Novita   \n",
       "2     055575                    Beskrivning Vantar             Novita   \n",
       "3     055576                Beskrivning Benvärmare             Novita   \n",
       "4     095302                      Garn Drops Nepal       Drops Design   \n",
       "...      ...                                   ...                ...   \n",
       "1714  590838            Madrasskydd Plastad frotté              Linea   \n",
       "1715  590841           5-meterklipp Plastad frotté              Linea   \n",
       "1716  598005  Gardinkappa Sanna enfärgad med spets            Fondaco   \n",
       "1717  790196                      Fingerborg 17 mm  Ateljé Margaretha   \n",
       "1718  970100                   Frakt- & exp.avgift            unknown   \n",
       "\n",
       "     audience                                     category  priceSEK  \\\n",
       "0         dam                                       Tröjor        29   \n",
       "1         dam                      Mössor & hattar,Mönster        29   \n",
       "2         dam                                       Vantar        29   \n",
       "3         dam                            Sockor & strumpor        29   \n",
       "4        <NA>                                      unknown        33   \n",
       "...       ...                                          ...       ...   \n",
       "1714   hemmet  Bäddtillbehör,Bädd,Inkontinens,Bädd (linea)       359   \n",
       "1715   hemmet  Bäddtillbehör,Bädd,Inkontinens,Bädd (linea)       398   \n",
       "1716   hemmet                                   Kanalkappa       249   \n",
       "1717  generic                Sytillbehör,Vardagshjälpmedel        19   \n",
       "1718     <NA>                                      unknown        69   \n",
       "\n",
       "                                            description  \\\n",
       "0     Sticka en färgglad och trendig tröja i garnet ...   \n",
       "1     Sticka en trendig huva i garnet Halaus från No...   \n",
       "2     Sticka ett par vantar med blomstermotiv i garn...   \n",
       "3     Sticka ett par trendiga benvärmare i garnet Ha...   \n",
       "4     Garn Drops Nepal är ett underbart tjockt luxuö...   \n",
       "...                                                 ...   \n",
       "1714  Hygienisk och vattenavvisande yta. OEKO-TEX.Pl...   \n",
       "1715  Hygienisk och vattenavvisande yta. OEKO-TEX. P...   \n",
       "1716  Underbar gardinkappa med vacker spetsdetalj.Ko...   \n",
       "1717                         Fingerborg, storlek 17 mm.   \n",
       "1718                                               <NA>   \n",
       "\n",
       "                                                  color priceband  \n",
       "0                                                    []    Budget  \n",
       "1                                                    []    Budget  \n",
       "2                                                    []    Budget  \n",
       "3                                                    []    Budget  \n",
       "4     [Beige, Blush, Blå, Blå/grön, Cerise, Grå, Grå...    Budget  \n",
       "...                                                 ...       ...  \n",
       "1714                                              [Vit]   Popular  \n",
       "1715                                              [Vit]   Popular  \n",
       "1716                                 [Grön, Linne, Röd]     Value  \n",
       "1717                                                 []    Budget  \n",
       "1718                                                 []    Budget  \n",
       "\n",
       "[1702 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441943d8",
   "metadata": {},
   "source": [
    "## 1. Build a clean text field for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1546840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, unicodedata, re, numpy as np\n",
    "\n",
    "MISSING = {\"\", \"unknown\", \"nan\", \"none\", None}\n",
    "\n",
    "def canon(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    s = re.sub(r\"\\u00A0\", \" \", s)\n",
    "    s = re.sub(r\"[\\u2010-\\u2015\\u2212\\-]+\", \"-\", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def norm_categories(x):\n",
    "    cats = [canon(c) for c in str(x).split(\",\") if str(c).strip() not in MISSING]\n",
    "    seen, out = set(), []\n",
    "    for c in cats:\n",
    "        cl = c.lower()\n",
    "        if c and cl not in seen:\n",
    "            seen.add(cl)\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def short_desc(desc, max_words=30):\n",
    "    if not desc: return \"\"\n",
    "    first = re.split(r\"(?<=[.!?])\\s+\", desc)[0]\n",
    "    return \" \".join(first.split()[:max_words])\n",
    "\n",
    "def format_colors(col) -> str:\n",
    "    \"\"\"\n",
    "    Render colors as 'Svart, Grå' (no brackets). Accepts list/tuple/Series/ndarray or strings like:\n",
    "    \"['Svart' 'Grå']\", \"Grå,Svart\", \"Svart/Grå\".\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    if isinstance(col, (list, tuple, pd.Series, np.ndarray)):\n",
    "        seq = list(col)\n",
    "        for v in seq:\n",
    "            s = str(v).strip()\n",
    "            if not s or s.lower() in MISSING: \n",
    "                continue\n",
    "            # split embedded multi-values too (e.g., 'Grå,Svart')\n",
    "            parts = re.split(r\"\\s*[,/|;]\\s*\", s) if any(sep in s for sep in \",/|;\") else [s]\n",
    "            vals.extend(parts)\n",
    "    else:\n",
    "        s = str(col).strip()\n",
    "        if s and s.lower() not in MISSING:\n",
    "            quoted = re.findall(r\"'([^']+)'|\\\"([^\\\"]+)\\\"\", s)\n",
    "            if quoted:\n",
    "                vals = [a or b for a, b in quoted]\n",
    "            else:\n",
    "                vals = re.split(r\"\\s*[,/|;]\\s*\", s) if any(sep in s for sep in \",/|;\") else [s]\n",
    "\n",
    "    # order-preserving dedupe\n",
    "    out, seen = [], set()\n",
    "    for v in vals:\n",
    "        t = v.strip()\n",
    "        if t and t.lower() not in seen:\n",
    "            seen.add(t.lower())\n",
    "            out.append(t)\n",
    "    return \", \".join(out)\n",
    "\n",
    "# ---- build ----\n",
    "groups = groups.copy()\n",
    "\n",
    "# Ensure color column exists\n",
    "if \"color\" not in groups.columns:\n",
    "    groups[\"color\"] = \"\"\n",
    "\n",
    "# Single normalized categories column\n",
    "groups[\"categories\"] = groups[\"category\"].apply(norm_categories)\n",
    "\n",
    "# Nice string rendering of colors for text/metadata\n",
    "groups[\"colors_str\"] = groups[\"color\"].apply(format_colors)\n",
    "\n",
    "def build_text_embed_clean(r):\n",
    "    name  = canon(r.get(\"name\", \"\"))\n",
    "    desc  = short_desc(canon(r.get(\"description\", \"\")), 30)\n",
    "    brand = canon(r.get(\"brand\", \"\"))\n",
    "    cats  = r.get(\"categories\", []) or []\n",
    "    cols  = r.get(\"colors_str\", \"\")\n",
    "\n",
    "    # append audience as is (no missing checks, no mapping)\n",
    "    aud   = canon(r.get(\"audience\", \"\"))  # \"<NA>\", \"nan\", \"\" etc. will pass through\n",
    "\n",
    "    parts, attrs = [], []\n",
    "\n",
    "    # put audience first with a stable label\n",
    "    parts.append(f\"AUDIENCE: {aud}.\")\n",
    "\n",
    "    if name: parts.append(f\"{name}.\")\n",
    "    if desc: parts.append(desc)\n",
    "    if brand: attrs.append(brand)\n",
    "    if cats:  attrs.append(\", \".join(cats))\n",
    "    if cols:  attrs.append(cols)\n",
    "    if attrs: parts.append(\" \".join(attrs) + \".\")\n",
    "    return re.sub(r\"\\s+\", \" \", \" \".join(parts)).strip()\n",
    "\n",
    "groups[\"text\"] = groups.apply(build_text_embed_clean, axis=1)\n",
    "\n",
    "group_df = groups[[\n",
    "    \"groupId\",\n",
    "    \"text\",\n",
    "    \"audience\",     # raw audience only\n",
    "    \"color\",\n",
    "    \"colors_str\",\n",
    "    \"categories\",\n",
    "    \"brand\",\n",
    "    \"priceband\"\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "corpus = group_df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2f812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py exe: /usr/local/bin/python\n",
      "torch: 2.8.0+cpu at /usr/local/lib/python3.10/site-packages/torch/__init__.py\n",
      "transformers: 4.57.1\n",
      "sentence-transformers: 5.1.2\n"
     ]
    }
   ],
   "source": [
    "import sys, torch, transformers, sentence_transformers\n",
    "print(\"py exe:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__, \"at\", torch.__file__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"sentence-transformers:\", sentence_transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2759204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!python -m pip install --upgrade --index-url https://download.pytorch.org/whl/cpu torch==2.8.0\n",
    "\n",
    "#pip install --no-deps sentence-transformers transformers tokenizers huggingface_hub safetensors\n",
    "#pip install --no-cache-dir \"sentencepiece==0.1.99\"\n",
    "#pip install faiss-cpu scikit-learn\n",
    "\n",
    "#pip install \"huggingface_hub[hf_xet]\"  # or: pip install hf_xet\n",
    "\n",
    "#pip install regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf17a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 4096, 'do_lower_case': False, 'architecture': 'NewModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#load encoder\n",
    "MODEL_ID = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "\n",
    "import os, torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "enc = SentenceTransformer(MODEL_ID, device=\"cpu\", trust_remote_code=True)\n",
    "enc.max_seq_length = min(4096, enc.tokenizer.model_max_length)\n",
    "print(enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cc25e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867ee04b193346ba86623267f6dcd45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1702, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embed texts\n",
    "\n",
    "texts = group_df[\"text\"].fillna(\"\").tolist()\n",
    "\n",
    "E = enc.encode(\n",
    "    texts,\n",
    "    batch_size=512,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ").astype(\"float32\")\n",
    "\n",
    "N, d = E.shape\n",
    "N, d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4238414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1702, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FAISS index (cosine via inner product) + gid map\n",
    "\n",
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatIP(d)   # cosine since E is normalized\n",
    "index.add(E)\n",
    "\n",
    "gid2i = {str(g): i for i, g in enumerate(group_df[\"groupId\"].astype(str))}\n",
    "N, index.is_trained\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51e0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 1702, 'kept': 1699, 'skipped_lt_min': 3, 'K': 10, 'min_keep': 1, 'cos_min': 0.6, 'k_cand': 100}\n",
      "{'Product ID': '055522', 'Top 1': '261998', 'Score 1': 0.7245949506759644, 'Top 2': '260287', 'Score 2': 0.7113903164863586, 'Top 3': '260163', 'Score 3': 0.7076380252838135, 'Top 4': '267113', 'Score 4': 0.7033674716949463, 'Top 5': '261478', 'Score 5': 0.6997042894363403, 'Top 6': '272097', 'Score 6': 0.6988092660903931, 'Top 7': '260646', 'Score 7': 0.6972818374633789, 'Top 8': '210782', 'Score 8': 0.6907309889793396, 'Top 9': '210676', 'Score 9': 0.68827223777771, 'Top 10': '261476', 'Score 10': 0.6865171790122986}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_neighbors_with_audience(\n",
    "    index,\n",
    "    E: np.ndarray,\n",
    "    groups: pd.DataFrame,\n",
    "    audience_col: str = \"audience\",\n",
    "    K: int = 10,\n",
    "    cos_min: float = 0.6,\n",
    "    min_keep: int = 1,\n",
    "    k_cand: int | None = None,\n",
    "    aud_ok_map: dict | None = None,\n",
    "):\n",
    "    N = E.shape[0]\n",
    "    if k_cand is None:\n",
    "        k_cand = min(100, max(1, N - 1))\n",
    "\n",
    "    if aud_ok_map is None:\n",
    "        aud_ok_map = {\n",
    "            \"herr\": {\"herr\", \"generic\"},\n",
    "            \"dam\": {\"dam\", \"generic\"},\n",
    "            \"barn & ungdom\": {\"barn & ungdom\", \"generic\"},\n",
    "            \"hemmet\": {\"hemmet\", \"generic\"},\n",
    "            \"generic\": {\"generic\", \"herr\", \"dam\", \"barn & ungdom\", \"hemmet\"},\n",
    "        }\n",
    "\n",
    "    aud = groups[audience_col].astype(str).to_numpy()\n",
    "    S_all, I_all = index.search(E, k_cand + 1)\n",
    "\n",
    "    neighbors, sims_list, valid = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        js, ss = I_all[i], S_all[i]\n",
    "        qa = aud[i]\n",
    "        allowed = aud_ok_map.get(qa, {qa, \"generic\"})\n",
    "\n",
    "        m = (js != i) & (ss >= cos_min)\n",
    "        m &= np.isin(aud[js], list(allowed))\n",
    "\n",
    "        js, ss = js[m], ss[m]\n",
    "        if js.size:\n",
    "            order = np.argsort(-ss)\n",
    "            js, ss = js[order], ss[order]\n",
    "\n",
    "        take = min(K, js.size)\n",
    "        ok = take >= min_keep\n",
    "\n",
    "        if ok:\n",
    "            neighbors.append(js[:take].tolist())\n",
    "            sims_list.append(ss[:take].astype(float).tolist())\n",
    "        else:\n",
    "            neighbors.append([])\n",
    "            sims_list.append([])\n",
    "        valid.append(ok)\n",
    "\n",
    "    valid = np.array(valid, dtype=bool)\n",
    "    kept = int(valid.sum())\n",
    "    skipped = int(N - kept)\n",
    "    stats = {\n",
    "        \"total\": int(N), \"kept\": kept, \"skipped_lt_min\": skipped,\n",
    "        \"K\": K, \"min_keep\": min_keep, \"cos_min\": cos_min, \"k_cand\": k_cand\n",
    "    }\n",
    "    return neighbors, sims_list, valid, stats\n",
    "\n",
    "\n",
    "def build_topk_rows(\n",
    "    neighbors, sims_list, groups: pd.DataFrame,\n",
    "    K: int = 10, id_key: str = \"Product ID\", id_col: str | None = \"groupId\",\n",
    "    skip_if_empty: bool = True  # NEW\n",
    "):\n",
    "    ids = groups[id_col].astype(str).to_numpy() if id_col else groups.index.astype(str).to_numpy()\n",
    "    rows = []\n",
    "    for i, (js, ss) in enumerate(zip(neighbors, sims_list)):\n",
    "        if skip_if_empty and len(js) == 0:\n",
    "            continue\n",
    "        row = {id_key: ids[i]}\n",
    "        for k in range(1, K + 1):\n",
    "            if k <= len(js):\n",
    "                row[f\"Top {k}\"]   = ids[js[k - 1]]\n",
    "                row[f\"Score {k}\"] = float(ss[k - 1])\n",
    "            else:\n",
    "                row[f\"Top {k}\"]   = None\n",
    "                row[f\"Score {k}\"] = None\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "neighbors, sims, valid, stats = compute_neighbors_with_audience(index, E, groups, K=10)\n",
    "rows = build_topk_rows(neighbors, sims, groups, K=10, id_col=\"groupId\")\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0328948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wide_topk_parquet(rows, path=\"/workspace/data/processed/semantic_similarity_recs.parquet\", K=10):\n",
    "    cols = [\"Product ID\"] + [c for k in range(1, K+1) for c in (f\"Top {k}\", f\"Score {k}\")]\n",
    "    wide = pd.DataFrame(rows)\n",
    "    # ensure missing cols exist (in case some Ks weren’t filled)\n",
    "    for c in cols:\n",
    "        if c not in wide.columns:\n",
    "            wide[c] = None\n",
    "    wide = wide[cols]\n",
    "    wide.to_parquet(path, index=False)\n",
    "    return wide\n",
    "\n",
    "# usage\n",
    "neighbors, sims, valid, stats = compute_neighbors_with_audience(index, E, groups, K=10)\n",
    "rows = build_topk_rows(neighbors, sims, groups, K=10)\n",
    "wide = save_wide_topk_parquet(rows, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38657e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (itcm-recsys)",
   "language": "python",
   "name": "itcm-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
