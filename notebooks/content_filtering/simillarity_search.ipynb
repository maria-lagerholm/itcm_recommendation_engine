{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283a50f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hybrid with CF: final score = 0.7*embed_cos + 0.3*CF_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0ea0c",
   "metadata": {},
   "source": [
    "## Assemble a DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13091878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "art = pd.read_csv(\n",
    "    \"../../data/processed/articles_clean.csv\",\n",
    "    usecols=[\"sku\",\"groupId\", \"name\", \"brand\", \"description\", \"audience\", \"category\", \"priceSEK\", \"color\", \"fabrics\"],\n",
    "    dtype=str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afd651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove articles with priceSEK below 1 from the DataFrame and convert to numeric\n",
    "art['priceSEK'] = pd.to_numeric(art['priceSEK'], errors='coerce')\n",
    "art = art[art['priceSEK'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82550ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create price buckets based on the distribution of price_sek, using 6 buckets\n",
    "price_bins = [0, 100, 300, 600, 1000, 2000, float('inf')]\n",
    "price_labels = [\n",
    "    'Budget',        # 0-100\n",
    "    'Value',         # 100-300\n",
    "    'Popular',       # 300-600\n",
    "    'Premium',       # 600-1000\n",
    "    'Luxury',        # 1000-2000\n",
    "    'Exclusive'      # 2000+\n",
    "]\n",
    "art['priceband'] = pd.cut(art['priceSEK'], bins=price_bins, labels=price_labels, include_lowest=True)\n",
    "art['priceband'] = art['priceband'].astype(object)\n",
    "art.loc[art['priceSEK'].isna(), 'priceband'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e621ba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>groupId</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>audience</th>\n",
       "      <th>category</th>\n",
       "      <th>priceSEK</th>\n",
       "      <th>fabrics</th>\n",
       "      <th>priceband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>055522</td>\n",
       "      <td>055522</td>\n",
       "      <td>Tröja</td>\n",
       "      <td>Sticka en färgglad och trendig tröja i garnet ...</td>\n",
       "      <td>Gjestal Garn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dam</td>\n",
       "      <td>Tröjor</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>055573</td>\n",
       "      <td>055573</td>\n",
       "      <td>Luva</td>\n",
       "      <td>Sticka en trendig huva i garnet Halaus från No...</td>\n",
       "      <td>Novita</td>\n",
       "      <td>vit</td>\n",
       "      <td>dam</td>\n",
       "      <td>Mössor &amp; hattar,Mönster</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>055575</td>\n",
       "      <td>055575</td>\n",
       "      <td>Vantar</td>\n",
       "      <td>Sticka ett par vantar med blomstermotiv i garn...</td>\n",
       "      <td>Novita</td>\n",
       "      <td>vit</td>\n",
       "      <td>dam</td>\n",
       "      <td>Vantar</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>055576</td>\n",
       "      <td>055576</td>\n",
       "      <td>Benvärmare</td>\n",
       "      <td>Sticka ett par trendiga benvärmare i garnet Ha...</td>\n",
       "      <td>Novita</td>\n",
       "      <td>vit</td>\n",
       "      <td>dam</td>\n",
       "      <td>Sockor &amp; strumpor</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>095318</td>\n",
       "      <td>095302</td>\n",
       "      <td>Garn Drops Nepal</td>\n",
       "      <td>Garn Drops Nepal är ett underbart tjockt luxuö...</td>\n",
       "      <td>Drops Design</td>\n",
       "      <td>svart</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>33.0</td>\n",
       "      <td>['alpaca', 'ull']</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AH2031-4547</td>\n",
       "      <td>AH2031</td>\n",
       "      <td>Stödstrumpa Herr</td>\n",
       "      <td>FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...</td>\n",
       "      <td>Funq Wear</td>\n",
       "      <td>svart-grå</td>\n",
       "      <td>generic</td>\n",
       "      <td>Stödstrumpor,Stödartiklar</td>\n",
       "      <td>149.0</td>\n",
       "      <td>['bomull', 'elastan']</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AH2031-4244</td>\n",
       "      <td>AH2031</td>\n",
       "      <td>Stödstrumpa Herr</td>\n",
       "      <td>FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...</td>\n",
       "      <td>Funq Wear</td>\n",
       "      <td>svart-grå</td>\n",
       "      <td>generic</td>\n",
       "      <td>Stödstrumpor,Stödartiklar</td>\n",
       "      <td>149.0</td>\n",
       "      <td>['bomull', 'elastan']</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AH3021-4244</td>\n",
       "      <td>AH3021</td>\n",
       "      <td>Stödstrumpa Herr</td>\n",
       "      <td>FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...</td>\n",
       "      <td>Funq Wear</td>\n",
       "      <td>blå</td>\n",
       "      <td>generic</td>\n",
       "      <td>Stödstrumpor,Stödartiklar</td>\n",
       "      <td>149.0</td>\n",
       "      <td>['bomull', 'elastan']</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AH3021-4547</td>\n",
       "      <td>AH3021</td>\n",
       "      <td>Stödstrumpa Herr</td>\n",
       "      <td>FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...</td>\n",
       "      <td>Funq Wear</td>\n",
       "      <td>blå</td>\n",
       "      <td>generic</td>\n",
       "      <td>Stödstrumpor,Stödartiklar</td>\n",
       "      <td>149.0</td>\n",
       "      <td>['bomull', 'elastan']</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST01</td>\n",
       "      <td>TEST01</td>\n",
       "      <td>guldarmband</td>\n",
       "      <td>Fint guldarmband</td>\n",
       "      <td>Disney</td>\n",
       "      <td>guld</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Smycken</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Popular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32413 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sku groupId              name  \\\n",
       "11326       055522  055522             Tröja   \n",
       "11325       055573  055573              Luva   \n",
       "11324       055575  055575            Vantar   \n",
       "11323       055576  055576        Benvärmare   \n",
       "11310       095318  095302  Garn Drops Nepal   \n",
       "...            ...     ...               ...   \n",
       "9      AH2031-4547  AH2031  Stödstrumpa Herr   \n",
       "14     AH2031-4244  AH2031  Stödstrumpa Herr   \n",
       "15     AH3021-4244  AH3021  Stödstrumpa Herr   \n",
       "16     AH3021-4547  AH3021  Stödstrumpa Herr   \n",
       "7           TEST01  TEST01       guldarmband   \n",
       "\n",
       "                                             description         brand  \\\n",
       "11326  Sticka en färgglad och trendig tröja i garnet ...  Gjestal Garn   \n",
       "11325  Sticka en trendig huva i garnet Halaus från No...        Novita   \n",
       "11324  Sticka ett par vantar med blomstermotiv i garn...        Novita   \n",
       "11323  Sticka ett par trendiga benvärmare i garnet Ha...        Novita   \n",
       "11310  Garn Drops Nepal är ett underbart tjockt luxuö...  Drops Design   \n",
       "...                                                  ...           ...   \n",
       "9      FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...     Funq Wear   \n",
       "14     FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...     Funq Wear   \n",
       "15     FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...     Funq Wear   \n",
       "16     FUNQ WEAR Komfortsockor MILD 11-14 mmHg Organi...     Funq Wear   \n",
       "7                                       Fint guldarmband        Disney   \n",
       "\n",
       "           color audience                   category  priceSEK  \\\n",
       "11326        NaN      dam                     Tröjor      29.0   \n",
       "11325        vit      dam    Mössor & hattar,Mönster      29.0   \n",
       "11324        vit      dam                     Vantar      29.0   \n",
       "11323        vit      dam          Sockor & strumpor      29.0   \n",
       "11310      svart  unknown                    unknown      33.0   \n",
       "...          ...      ...                        ...       ...   \n",
       "9      svart-grå  generic  Stödstrumpor,Stödartiklar     149.0   \n",
       "14     svart-grå  generic  Stödstrumpor,Stödartiklar     149.0   \n",
       "15           blå  generic  Stödstrumpor,Stödartiklar     149.0   \n",
       "16           blå  generic  Stödstrumpor,Stödartiklar     149.0   \n",
       "7           guld  unknown                    Smycken     400.0   \n",
       "\n",
       "                     fabrics priceband  \n",
       "11326                    NaN    Budget  \n",
       "11325                    NaN    Budget  \n",
       "11324                    NaN    Budget  \n",
       "11323                    NaN    Budget  \n",
       "11310      ['alpaca', 'ull']    Budget  \n",
       "...                      ...       ...  \n",
       "9      ['bomull', 'elastan']     Value  \n",
       "14     ['bomull', 'elastan']     Value  \n",
       "15     ['bomull', 'elastan']     Value  \n",
       "16     ['bomull', 'elastan']     Value  \n",
       "7                        NaN   Popular  \n",
       "\n",
       "[32413 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None, 'display.width', 0):\n",
    "    display(art.sort_values(\"groupId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76657829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate so that for each groupId, keep the first row for all columns except 'color', \n",
    "# which should be a list of all colors from merged rows (excluding missing/unknown/nan/none).\n",
    "def merge_colors(series):\n",
    "    # Remove missing/unknown/nan/none and deduplicate\n",
    "    colors = [str(c).strip() for c in series if pd.notna(c) and str(c).strip().lower() not in {\"\", \"unknown\", \"nan\", \"none\"}]\n",
    "    return list(sorted(set(colors))) if colors else []\n",
    "\n",
    "art = art.sort_values(\"sku\")  # Ensure deterministic \"first\" row\n",
    "art = art.groupby(\"groupId\", as_index=False).agg(\n",
    "    {col: (merge_colors if col == \"color\" else \"first\") for col in art.columns if col != \"sku\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441943d8",
   "metadata": {},
   "source": [
    "## 1. Build a clean text field for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1546840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, unicodedata, re, ast\n",
    "\n",
    "# -----------------------------\n",
    "# Constants & tiny helpers\n",
    "# -----------------------------\n",
    "MISSING = {\"\", \"unknown\", \"nan\", \"none\", None}\n",
    "\n",
    "BAD_CATS = {\n",
    "    # marketing / temporal / state tags that shouldn't drive semantic similarity\n",
    "    \"REA\", \"Nyheter\", \"Kampanj\", \"Outlet\", \"Erbjudande\",\n",
    "    \"Sale\", \"Black Friday\", \"Jul\", \"Sommar\"\n",
    "}\n",
    "\n",
    "def canon(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Unicode, standardize dashes/spaces, trim.\n",
    "    Keep original casing (model is cased).\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    s = re.sub(r\"\\u00A0\", \" \", s)                       # nbsp\n",
    "    s = re.sub(r\"[\\u2010-\\u2015\\u2212\\-]+\", \"-\", s)     # dashes\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def as_list(x):\n",
    "    \"\"\"\n",
    "    Convert value to list[str] without transforming tokens.\n",
    "    Keeps colors/materials exactly as provided if already lists.\n",
    "    \"\"\"\n",
    "    if isinstance(x, (list, tuple, np.ndarray, pd.Series)):\n",
    "        return [str(v) for v in x if str(v).strip() not in MISSING]\n",
    "    s = str(x).strip()\n",
    "    if s in MISSING:\n",
    "        return []\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            vals = ast.literal_eval(s)\n",
    "            return [str(v) for v in vals if str(v).strip() not in MISSING]\n",
    "        except Exception:\n",
    "            return [s]\n",
    "    return [s]\n",
    "\n",
    "def norm_categories(x):\n",
    "    \"\"\"\n",
    "    Parse comma-separated categories -> canonicalized list (dedup, order-preserving).\n",
    "    \"\"\"\n",
    "    cats = [canon(c) for c in str(x).split(\",\") if str(c).strip() not in MISSING]\n",
    "    seen_lower, out = set(), []\n",
    "    for c in cats:\n",
    "        cl = c.lower()\n",
    "        if c and cl not in seen_lower:\n",
    "            seen_lower.add(cl)\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def primary_categories(cats, max_keep=2):\n",
    "    \"\"\"\n",
    "    Keep up to max_keep *semantic* categories (drop marketing/state tags like REA).\n",
    "    \"\"\"\n",
    "    cats = cats or []\n",
    "    good = [c for c in cats if c not in BAD_CATS]\n",
    "    return good[:max_keep]\n",
    "\n",
    "def short_desc(desc, max_words=30):\n",
    "    \"\"\"\n",
    "    First sentence of description, truncated by word count.\n",
    "    \"\"\"\n",
    "    if not desc:\n",
    "        return \"\"\n",
    "    # split at sentence boundary; then trim words\n",
    "    first = re.split(r\"(?<=[.!?])\\s+\", desc)[0]\n",
    "    toks = first.split()\n",
    "    return \" \".join(toks[:max_words])\n",
    "\n",
    "# -----------------------------\n",
    "# Build fields on a copy of your source df `art`\n",
    "# -----------------------------\n",
    "art = art.copy()\n",
    "\n",
    "# Colors & materials: keep EXACTLY as they are (no lowercasing/splitting/mapping)\n",
    "art[\"colors_norm\"]    = art[\"color\"].apply(as_list)\n",
    "art[\"materials_norm\"] = art[\"fabrics\"].apply(as_list)\n",
    "\n",
    "# Categories: keep full list for metadata, plus a semantic subset for embeddings\n",
    "art[\"categories_norm_full\"] = art[\"category\"].apply(norm_categories)\n",
    "art[\"categories_semantic\"]  = art[\"categories_norm_full\"].apply(lambda cs: primary_categories(cs, max_keep=2))\n",
    "\n",
    "# Optional: a REA flag (useful for filtering/UX; has zero effect on embeddings)\n",
    "art[\"sale_tag\"] = art[\"categories_norm_full\"].apply(lambda cs: \"REA\" in set(cs))\n",
    "\n",
    "# -----------------------------\n",
    "# Natural text for embeddings (no boilerplate labels)\n",
    "# - Include: name, short desc, brand, semantic categories, materials\n",
    "# - Exclude: colors, price, price band, audience, marketing tags (like REA)\n",
    "# -----------------------------\n",
    "def build_text_embed_clean(r):\n",
    "    name  = canon(r.get(\"name\", \"\"))\n",
    "    desc0 = canon(r.get(\"description\", \"\"))\n",
    "    desc  = short_desc(desc0, max_words=30)\n",
    "\n",
    "    brand_raw = r.get(\"brand\", \"\")\n",
    "    brand = canon(brand_raw) if str(brand_raw).lower() not in MISSING else \"\"\n",
    "\n",
    "    cats = r.get(\"categories_semantic\", []) or []\n",
    "    mats = r.get(\"materials_norm\", []) or []\n",
    "\n",
    "    parts = []\n",
    "    if name:\n",
    "        parts.append(f\"{name}.\")\n",
    "    if desc:\n",
    "        parts.append(desc)\n",
    "\n",
    "    # Add salient attributes as plain tokens (no labels like 'Varumärke:' / 'Kategori:')\n",
    "    attrs = []\n",
    "    if brand:\n",
    "        attrs.append(brand)\n",
    "    if cats:\n",
    "        attrs.append(\", \".join(cats))\n",
    "    if mats:\n",
    "        attrs.append(\", \".join(mats))\n",
    "\n",
    "    if attrs:\n",
    "        parts.append(\" \".join(attrs) + \".\")\n",
    "\n",
    "    txt = \" \".join(parts)\n",
    "    return re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "\n",
    "art[\"text\"] = art.apply(build_text_embed_clean, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Final table for retrieval\n",
    "# -----------------------------\n",
    "group_df = art[[\n",
    "    \"groupId\",\n",
    "    \"text\",\n",
    "    \"colors_norm\",          # kept as-is for filtering or hybrid rerank\n",
    "    \"materials_norm\",       # kept as-is; also lightly included in text\n",
    "    \"categories_norm_full\", # full list incl. REA etc. (metadata/UI)\n",
    "    \"categories_semantic\",  # semantic subset used in text\n",
    "    \"brand\",\n",
    "    \"priceband\"\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# This is the corpus you embed with your Swedish SBERT (no prefixes)\n",
    "corpus = group_df[\"text\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d396f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>text</th>\n",
       "      <th>colors_norm</th>\n",
       "      <th>materials_norm</th>\n",
       "      <th>categories_norm_full</th>\n",
       "      <th>categories_semantic</th>\n",
       "      <th>brand</th>\n",
       "      <th>priceband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>055522</td>\n",
       "      <td>Tröja. Sticka en färgglad och trendig tröja i garnet Vera från House of Yarn! Gjestal Garn Tröjor None.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Tröjor]</td>\n",
       "      <td>[Tröjor]</td>\n",
       "      <td>Gjestal Garn</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>055573</td>\n",
       "      <td>Luva. Sticka en trendig huva i garnet Halaus från Novita! Novita Mössor &amp; hattar, Mönster None.</td>\n",
       "      <td>[vit]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Mössor &amp; hattar, Mönster]</td>\n",
       "      <td>[Mössor &amp; hattar, Mönster]</td>\n",
       "      <td>Novita</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>055575</td>\n",
       "      <td>Vantar. Sticka ett par vantar med blomstermotiv i garnet Halaus från Novita! Novita Vantar None.</td>\n",
       "      <td>[vit]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Vantar]</td>\n",
       "      <td>[Vantar]</td>\n",
       "      <td>Novita</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>055576</td>\n",
       "      <td>Benvärmare. Sticka ett par trendiga benvärmare i garnet Halaus från Novita! Novita Sockor &amp; strumpor None.</td>\n",
       "      <td>[vit]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Sockor &amp; strumpor]</td>\n",
       "      <td>[Sockor &amp; strumpor]</td>\n",
       "      <td>Novita</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>095302</td>\n",
       "      <td>Garn Drops Nepal. Garn Drops Nepal är ett underbart tjockt luxuöst garn spunnet av 35% superfin alpaca och 65 % peruvian highland ull. Drops Design alpaca, ull.</td>\n",
       "      <td>[beige, blå, blå-grön, brun, grå, gråmelerad, grön, gul, lila, marin, mörkgrå, orange, rosa, röd, svart, turkos, vit]</td>\n",
       "      <td>[alpaca, ull]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Drops Design</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  groupId  \\\n",
       "0  055522   \n",
       "1  055573   \n",
       "2  055575   \n",
       "3  055576   \n",
       "4  095302   \n",
       "\n",
       "                                                                                                                                                               text  \\\n",
       "0                                                           Tröja. Sticka en färgglad och trendig tröja i garnet Vera från House of Yarn! Gjestal Garn Tröjor None.   \n",
       "1                                                                   Luva. Sticka en trendig huva i garnet Halaus från Novita! Novita Mössor & hattar, Mönster None.   \n",
       "2                                                                  Vantar. Sticka ett par vantar med blomstermotiv i garnet Halaus från Novita! Novita Vantar None.   \n",
       "3                                                        Benvärmare. Sticka ett par trendiga benvärmare i garnet Halaus från Novita! Novita Sockor & strumpor None.   \n",
       "4  Garn Drops Nepal. Garn Drops Nepal är ett underbart tjockt luxuöst garn spunnet av 35% superfin alpaca och 65 % peruvian highland ull. Drops Design alpaca, ull.   \n",
       "\n",
       "                                                                                                             colors_norm  \\\n",
       "0                                                                                                                     []   \n",
       "1                                                                                                                  [vit]   \n",
       "2                                                                                                                  [vit]   \n",
       "3                                                                                                                  [vit]   \n",
       "4  [beige, blå, blå-grön, brun, grå, gråmelerad, grön, gul, lila, marin, mörkgrå, orange, rosa, röd, svart, turkos, vit]   \n",
       "\n",
       "  materials_norm        categories_norm_full         categories_semantic  \\\n",
       "0         [None]                    [Tröjor]                    [Tröjor]   \n",
       "1         [None]  [Mössor & hattar, Mönster]  [Mössor & hattar, Mönster]   \n",
       "2         [None]                    [Vantar]                    [Vantar]   \n",
       "3         [None]         [Sockor & strumpor]         [Sockor & strumpor]   \n",
       "4  [alpaca, ull]                          []                          []   \n",
       "\n",
       "          brand priceband  \n",
       "0  Gjestal Garn    Budget  \n",
       "1        Novita    Budget  \n",
       "2        Novita    Budget  \n",
       "3        Novita    Budget  \n",
       "4  Drops Design    Budget  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a2f812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py exe: /opt/conda/bin/python\n",
      "torch: 2.8.0+cpu at /opt/conda/lib/python3.10/site-packages/torch/__init__.py\n",
      "transformers: 4.56.1\n",
      "sentence-transformers: 5.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys, torch, transformers, sentence_transformers\n",
    "print(\"py exe:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__, \"at\", torch.__file__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"sentence-transformers:\", sentence_transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759204a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m enc\u001b[38;5;241m.\u001b[39mmax_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m     18\u001b[0m corpus \u001b[38;5;241m=\u001b[39m group_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 19\u001b[0m E \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1051\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1048\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1051\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1132\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m   1127\u001b[0m         module_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1128\u001b[0m             key: value\n\u001b[1;32m   1129\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1130\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mforward_kwargs)\n\u001b[1;32m   1131\u001b[0m         }\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:234\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    229\u001b[0m     key: value\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    232\u001b[0m }\n\u001b[0;32m--> 234\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    236\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:852\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    850\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:606\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    602\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    604\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:543\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    540\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    541\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pytorch_utils.py:257\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:551\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:465\u001b[0m, in \u001b[0;36mXLMRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 465\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#python -m pip install --upgrade --index-url https://download.pytorch.org/whl/cpu torch==2.8.0\n",
    "\n",
    "#pip install --no-deps sentence-transformers transformers tokenizers huggingface_hub safetensors\n",
    "\n",
    "#pip install faiss-cpu scikit-learn\n",
    "\n",
    "#pip install \"huggingface_hub[hf_xet]\"  # or: pip install hf_xet\n",
    "\n",
    "\n",
    "#Embed\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, numpy as np, pandas as pd\n",
    "\n",
    "#Recommended RAG pipeline: Hybrid retrieval (use BGE-M3’s dense+sparse) → re-ranker (e.g., bge-reranker / v2). Works well with Vespa and Milvus. https://huggingface.co/BAAI/bge-m3\n",
    "enc = SentenceTransformer(\"BAAI/bge-m3\", device=\"cpu\") # three retrieval modes (dense + sparse + multi-vector/ColBERT, 100+ languages, and long context (≤8192 tokens).\n",
    "enc.max_seq_length = 256\n",
    "corpus = group_df[\"text\"].tolist()\n",
    "E = enc.encode(corpus, batch_size=64, normalize_embeddings=True).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, d = E.shape\n",
    "\n",
    "# ---------- FAISS (cosine via IP on normalized vectors) ----------\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Online helpers ----- run FAISS index.search on the fly, return top-k now (fast, per request).\n",
    "def _filter_topk(I_row, D_row, k, mask=None, drop_idx=None):\n",
    "    out_idx, out_sim = [], []\n",
    "    for j, s in zip(I_row, D_row):\n",
    "        if drop_idx is not None and j == drop_idx:\n",
    "            continue\n",
    "        if mask is None or mask[j]:\n",
    "            out_idx.append(j); out_sim.append(float(s))\n",
    "            if len(out_idx) == k:\n",
    "                break\n",
    "    return out_idx, out_sim\n",
    "\n",
    "def search_by_gid(gid, k=200, require_color=None):\n",
    "    i = group_df.index[group_df.groupId.eq(gid)][0]\n",
    "    D, I = index.search(E[i:i+1], k + 50)  # cushion then filter\n",
    "    mask = None\n",
    "    if require_color:\n",
    "        mask = group_df.colors_norm.apply(lambda cs: require_color in cs).to_numpy()\n",
    "    I0, D0 = _filter_topk(I[0], D[0], k, mask=mask, drop_idx=i)\n",
    "    res = group_df.iloc[I0].copy()\n",
    "    res[\"similarity\"] = D0\n",
    "    return res\n",
    "\n",
    "def search_by_text(q, k=200, require_color=None):\n",
    "    # Symmetric text query (no query:/passage: prompts)\n",
    "    qv = enc.encode([q], normalize_embeddings=True).astype(\"float32\")\n",
    "    D, I = index.search(qv, k + 50)\n",
    "    mask = None\n",
    "    if require_color:\n",
    "        mask = group_df.colors_norm.apply(lambda cs: require_color in cs).to_numpy()\n",
    "    I0, D0 = _filter_topk(I[0], D[0], k, mask=mask)\n",
    "    res = group_df.iloc[I0].copy()\n",
    "    res[\"similarity\"] = D0\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc892c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Persist artifacts -----\n",
    "np.save(\"embeddings_bge_E.npy\", E)\n",
    "group_df.to_parquet(\"groups.parquet\")\n",
    "faiss.write_index(index, \"faiss_ip.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e65ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m BATCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m                \u001b[38;5;66;03m# CE batch size (raise if VRAM/RAM allows)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m TRUNC \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m                \u001b[38;5;66;03m# effective CE max tokens per pair (keeps it fast)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m TOPK \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(K\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, R\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[43mN\u001b[49m)\n\u001b[1;32m     15\u001b[0m D_all, I_all \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msearch(E, TOPK)\n\u001b[1;32m     17\u001b[0m texts \u001b[38;5;241m=\u001b[39m group_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "TOPK = min(K+1, N)\n",
    "D_all, I_all = index.search(E, TOPK)\n",
    "\n",
    "rows = []\n",
    "texts = group_df[\"text\"].tolist()\n",
    "gids  = group_df[\"groupId\"].to_numpy()\n",
    "\n",
    "for i in range(N):\n",
    "    cand_idx = [j for j in I_all[i] if j != i][:K]\n",
    "    pairs = [[texts[i], texts[j]] for j in cand_idx]            # (src, rec) pairs\n",
    "    ce_scores = rer.compute_score(pairs, batch_size=32)         # cross-encoder scores\n",
    "    order = np.argsort(-np.asarray(ce_scores))                  # sort desc by CE score\n",
    "\n",
    "    for rank, t in enumerate(order, 1):\n",
    "        j = cand_idx[t]\n",
    "        rows.append((gids[i], gids[j], float(D_all[i][np.where(I_all[i]==j)][0]),\n",
    "                     float(ce_scores[t]), rank))\n",
    "\n",
    "recs = pd.DataFrame(rows, columns=[\"src_groupId\",\"rec_groupId\",\"similarity\",\"rerank_score\",\"rec_rank\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b27670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_groupId with less than one rec: []\n"
     ]
    }
   ],
   "source": [
    "# Find src_groupId that have less than three rec (i.e., zero recs)\n",
    "src_counts = recs[\"src_groupId\"].value_counts()\n",
    "no_rec_srcs = src_counts[src_counts < 3]\n",
    "print(\"src_groupId with less than one rec:\", no_rec_srcs.index.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_groupId</th>\n",
       "      <th>rec_groupId</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rec_rank</th>\n",
       "      <th>src_text</th>\n",
       "      <th>src_brand</th>\n",
       "      <th>src_categories_norm_full</th>\n",
       "      <th>src_colors_norm</th>\n",
       "      <th>rec_text</th>\n",
       "      <th>rec_brand</th>\n",
       "      <th>rec_categories_norm_full</th>\n",
       "      <th>rec_colors_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>290281</td>\n",
       "      <td>294785</td>\n",
       "      <td>0.649926</td>\n",
       "      <td>1</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Reflex Snap On Reflector. Snap-on reflex som är enkel att fästa runt armar och ben. SpringYard Vardagshjälpmedel None.</td>\n",
       "      <td>SpringYard</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>290281</td>\n",
       "      <td>290282</td>\n",
       "      <td>0.606378</td>\n",
       "      <td>2</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Reflexbälte stretch. Reflexbälte så du syns bra ute i mörkret! Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>290281</td>\n",
       "      <td>290299</td>\n",
       "      <td>0.598651</td>\n",
       "      <td>3</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Väska reflex. Tygkasse i reflextyg.Mått: 42x38x8 cm Väskor, Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Väskor, Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>290281</td>\n",
       "      <td>290182</td>\n",
       "      <td>0.556411</td>\n",
       "      <td>4</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hopfällbar Krycka. Hopfällbar krycka som är mycket populär resekrycka, men är lika omtyckt för användning till vardags. Good Living Gånghjälpmedel None.</td>\n",
       "      <td>Good Living</td>\n",
       "      <td>[Gånghjälpmedel]</td>\n",
       "      <td>[svart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154</th>\n",
       "      <td>290281</td>\n",
       "      <td>200231</td>\n",
       "      <td>0.552933</td>\n",
       "      <td>5</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Reflexmössa Herr. Varm och skön mössa. Åshild Accessoarer, Herr akryl, polyester.</td>\n",
       "      <td>Åshild</td>\n",
       "      <td>[Accessoarer, Herr, Kepsar &amp; mössor]</td>\n",
       "      <td>[svart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>290281</td>\n",
       "      <td>281030</td>\n",
       "      <td>0.538784</td>\n",
       "      <td>6</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Stövel. Pälsfodrad lättviksstövel som fungerar bra i kallt väder. Skor nylon.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Skor]</td>\n",
       "      <td>[sand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>290281</td>\n",
       "      <td>290178</td>\n",
       "      <td>0.534825</td>\n",
       "      <td>7</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Rollator Let' Shop. Let&amp;#039;s Shop hjälper dig att transportera dina föremål vart du än går - snabbt, enkelt och säkert.Denna lätta aluminium rullator är monterad med en stor shoppingväska som hjälper dig transportera Trust Care Gånghjälpmedel, Rollatorer None.</td>\n",
       "      <td>Trust Care</td>\n",
       "      <td>[Gånghjälpmedel, Rollatorer]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157</th>\n",
       "      <td>290281</td>\n",
       "      <td>440447</td>\n",
       "      <td>0.526648</td>\n",
       "      <td>8</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Uppladdningsbar clip on Lampa. Denna mångsidiga och praktiska mini lampa erbjuder ett flexibelt, justerbart halsdesign och dimbar belysning för att passa dina behov. PURElite Synhjälpmedel, Vardagshjälpmedel None.</td>\n",
       "      <td>PURElite</td>\n",
       "      <td>[Synhjälpmedel, Vardagshjälpmedel, Belysning]</td>\n",
       "      <td>[vit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9158</th>\n",
       "      <td>290281</td>\n",
       "      <td>525050</td>\n",
       "      <td>0.524604</td>\n",
       "      <td>9</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Natt &amp; Garderobslampa. Praktiska LED-puckar som är perfekta till garderober, förråd och andra mörka utrymmen där man behöver en liten extra ljuspunkt. Star Trading Belysning, Barnrummet None.</td>\n",
       "      <td>Star Trading</td>\n",
       "      <td>[Belysning, Barnrummet, Natt &amp; garderobslampor]</td>\n",
       "      <td>[vit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9159</th>\n",
       "      <td>290281</td>\n",
       "      <td>525051</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>10</td>\n",
       "      <td>Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Vardagshjälpmedel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Natt&amp;Garderobslampa. Praktiska LED-puckar som är perfekta till garderober, förråd och andra mörka utrymmen där man behöver en liten extra ljuspunkt. Star Trading Belysning, Barnrummet None.</td>\n",
       "      <td>Star Trading</td>\n",
       "      <td>[Belysning, Barnrummet, Natt &amp; garderobslampor]</td>\n",
       "      <td>[svart]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     src_groupId rec_groupId  similarity  rec_rank  \\\n",
       "9150      290281      294785    0.649926         1   \n",
       "9151      290281      290282    0.606378         2   \n",
       "9152      290281      290299    0.598651         3   \n",
       "9153      290281      290182    0.556411         4   \n",
       "9154      290281      200231    0.552933         5   \n",
       "9155      290281      281030    0.538784         6   \n",
       "9156      290281      290178    0.534825         7   \n",
       "9157      290281      440447    0.526648         8   \n",
       "9158      290281      525050    0.524604         9   \n",
       "9159      290281      525051    0.520661        10   \n",
       "\n",
       "                                                                                                                                                                             src_text  \\\n",
       "9150  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9151  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9152  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9153  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9154  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9155  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9156  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9157  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9158  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "9159  Reflex Pom Pom. Snygg och trendig reflex boll Pom-Pom med metallhake som gör att man kan lätt kan flytta reflexen från till exempel jackan till väskan. Vardagshjälpmedel None.   \n",
       "\n",
       "     src_brand src_categories_norm_full src_colors_norm  \\\n",
       "9150   unknown      [Vardagshjälpmedel]              []   \n",
       "9151   unknown      [Vardagshjälpmedel]              []   \n",
       "9152   unknown      [Vardagshjälpmedel]              []   \n",
       "9153   unknown      [Vardagshjälpmedel]              []   \n",
       "9154   unknown      [Vardagshjälpmedel]              []   \n",
       "9155   unknown      [Vardagshjälpmedel]              []   \n",
       "9156   unknown      [Vardagshjälpmedel]              []   \n",
       "9157   unknown      [Vardagshjälpmedel]              []   \n",
       "9158   unknown      [Vardagshjälpmedel]              []   \n",
       "9159   unknown      [Vardagshjälpmedel]              []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                    rec_text  \\\n",
       "9150                                                                                                                                                  Reflex Snap On Reflector. Snap-on reflex som är enkel att fästa runt armar och ben. SpringYard Vardagshjälpmedel None.   \n",
       "9151                                                                                                                                                                                  Reflexbälte stretch. Reflexbälte så du syns bra ute i mörkret! Vardagshjälpmedel None.   \n",
       "9152                                                                                                                                                                                     Väska reflex. Tygkasse i reflextyg.Mått: 42x38x8 cm Väskor, Vardagshjälpmedel None.   \n",
       "9153                                                                                                                Hopfällbar Krycka. Hopfällbar krycka som är mycket populär resekrycka, men är lika omtyckt för användning till vardags. Good Living Gånghjälpmedel None.   \n",
       "9154                                                                                                                                                                                       Reflexmössa Herr. Varm och skön mössa. Åshild Accessoarer, Herr akryl, polyester.   \n",
       "9155                                                                                                                                                                                           Stövel. Pälsfodrad lättviksstövel som fungerar bra i kallt väder. Skor nylon.   \n",
       "9156  Rollator Let' Shop. Let&#039;s Shop hjälper dig att transportera dina föremål vart du än går - snabbt, enkelt och säkert.Denna lätta aluminium rullator är monterad med en stor shoppingväska som hjälper dig transportera Trust Care Gånghjälpmedel, Rollatorer None.   \n",
       "9157                                                   Uppladdningsbar clip on Lampa. Denna mångsidiga och praktiska mini lampa erbjuder ett flexibelt, justerbart halsdesign och dimbar belysning för att passa dina behov. PURElite Synhjälpmedel, Vardagshjälpmedel None.   \n",
       "9158                                                                         Natt & Garderobslampa. Praktiska LED-puckar som är perfekta till garderober, förråd och andra mörka utrymmen där man behöver en liten extra ljuspunkt. Star Trading Belysning, Barnrummet None.   \n",
       "9159                                                                           Natt&Garderobslampa. Praktiska LED-puckar som är perfekta till garderober, förråd och andra mörka utrymmen där man behöver en liten extra ljuspunkt. Star Trading Belysning, Barnrummet None.   \n",
       "\n",
       "         rec_brand                         rec_categories_norm_full  \\\n",
       "9150    SpringYard                              [Vardagshjälpmedel]   \n",
       "9151       unknown                              [Vardagshjälpmedel]   \n",
       "9152       unknown                      [Väskor, Vardagshjälpmedel]   \n",
       "9153   Good Living                                 [Gånghjälpmedel]   \n",
       "9154        Åshild             [Accessoarer, Herr, Kepsar & mössor]   \n",
       "9155       unknown                                           [Skor]   \n",
       "9156    Trust Care                     [Gånghjälpmedel, Rollatorer]   \n",
       "9157      PURElite    [Synhjälpmedel, Vardagshjälpmedel, Belysning]   \n",
       "9158  Star Trading  [Belysning, Barnrummet, Natt & garderobslampor]   \n",
       "9159  Star Trading  [Belysning, Barnrummet, Natt & garderobslampor]   \n",
       "\n",
       "     rec_colors_norm  \n",
       "9150              []  \n",
       "9151              []  \n",
       "9152              []  \n",
       "9153         [svart]  \n",
       "9154         [svart]  \n",
       "9155          [sand]  \n",
       "9156              []  \n",
       "9157           [vit]  \n",
       "9158           [vit]  \n",
       "9159         [svart]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs[recs[\"src_groupId\"] == \"290281\"] # reflex\n",
    "#recs[recs[\"src_groupId\"] == \"200970\"] # random\n",
    "#recs[recs[\"src_groupId\"] == \"292706\"] #dildo\n",
    "#recs[recs[\"src_groupId\"] == \"291534\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
