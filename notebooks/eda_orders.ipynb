{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18fb56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tx = pd.read_parquet(\"../data/processed/transactions_clean.parquet\")\n",
    "customers = pd.read_parquet(\"../data/processed/customers_clean.parquet\")\n",
    "articles  = pd.read_parquet(\"../data/processed/articles_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b670705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- customers ---\n",
      "Age column: 'Age' dtype=float64\n",
      " non-null=36100, unique=87\n",
      " min=17.0, max=103.0\n",
      " sample uniques: [17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0]\n",
      "Gender column: 'Gender' dtype=object\n",
      " unique (non-null): ['female', 'male']\n",
      "\n",
      " value counts:\n",
      " Gender\n",
      "female    34370\n",
      "male       1730\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# === Debug: unique Age / Gender in customers only ===\n",
    "import pandas as pd\n",
    "\n",
    "def _find_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "age_col = _find_col(customers, [\"Age\",\"age\",\"customer_age\"])\n",
    "gen_col = _find_col(customers, [\"Gender\",\"gender\",\"customer_gender\"])\n",
    "\n",
    "print(\"--- customers ---\")\n",
    "if age_col:\n",
    "    ages = pd.to_numeric(customers[age_col], errors=\"coerce\")\n",
    "    print(f\"Age column: '{age_col}' dtype={customers[age_col].dtype}\")\n",
    "    print(f\" non-null={ages.notna().sum()}, unique={ages.dropna().nunique()}\")\n",
    "    if ages.notna().any():\n",
    "        print(f\" min={float(ages.min())}, max={float(ages.max())}\")\n",
    "        print(\" sample uniques:\", sorted(ages.dropna().unique().tolist())[:20])\n",
    "else:\n",
    "    print(\"Age column: NOT FOUND\")\n",
    "\n",
    "if gen_col:\n",
    "    g = customers[gen_col].astype(\"string[python]\").str.strip().str.lower()\n",
    "    print(f\"Gender column: '{gen_col}' dtype={customers[gen_col].dtype}\")\n",
    "    print(\" unique (non-null):\", sorted(g.dropna().unique().tolist()))\n",
    "    print(\"\\n value counts:\\n\", g.value_counts(dropna=True))\n",
    "else:\n",
    "    print(\"Gender column: NOT FOUND\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11111154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shopUserId                  object\n",
       "invoiceFirstName    string[python]\n",
       "invoiceLastName     string[python]\n",
       "invoiceSSN                  object\n",
       "invoiceZip          string[python]\n",
       "invoiceCity                 object\n",
       "invoiceCountryId            object\n",
       "invoiceEmail                object\n",
       "_row                         int64\n",
       "Gender                      object\n",
       "Age                        float64\n",
       "Country                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e76633",
   "metadata": {},
   "source": [
    "## Build json for mental mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3686d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: helpers + split (robust merge of Age/Gender from customers) ===\n",
    "import re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "NORDICS = [\"Sweden\", \"Denmark\", \"Finland\", \"Norway\"]\n",
    "\n",
    "def status_from_orders(n):\n",
    "    return \"new\" if n <= 1 else (\"returning\" if n <= 3 else \"loyal\")\n",
    "\n",
    "def mode_or_first(s: pd.Series):\n",
    "    m = s.mode()\n",
    "    if not m.empty: return m.iat[0]\n",
    "    s = s.dropna()\n",
    "    return s.iat[0] if not s.empty else None\n",
    "\n",
    "def _pick(df, names, default=None):\n",
    "    for n in names:\n",
    "        if n in df.columns: return df[n]\n",
    "    return pd.Series([default]*len(df), index=df.index)\n",
    "\n",
    "def _norm_id(s: pd.Series) -> pd.Series:\n",
    "    # to string, strip, drop trailing \".0\" if present (common after Parquet/float cast)\n",
    "    s = s.astype(\"string[python]\").str.strip()\n",
    "    return s.str.replace(r\"\\.0+$\", \"\", regex=True)\n",
    "\n",
    "def _norm_gender(s: pd.Series):\n",
    "    if s is None: return s\n",
    "    s = s.astype(\"string[python]\").str.strip().str.lower()\n",
    "    return s.replace({\"f\":\"female\", \"m\":\"male\", \"kvinnan\":\"female\", \"man\":\"male\"})\n",
    "\n",
    "def split_nordics(tx: pd.DataFrame, customers: pd.DataFrame) -> dict:\n",
    "    # ---------- tx core ----------\n",
    "    country = _pick(tx, [\"currency_country\",\"Country\"], \"Unknown\").astype(\"string[python]\").str.strip()\n",
    "    country = country.replace({\"\": pd.NA}).fillna(\"Unknown\")\n",
    "    city    = _pick(tx, [\"invoiceCity\",\"city\"], \"Unknown\").astype(object).fillna(\"Unknown\")\n",
    "    shop    = _norm_id(tx[\"shopUserId\"])\n",
    "    order_id= tx[\"orderId\"].astype(\"string[python]\").str.strip()\n",
    "\n",
    "    created = tx[\"created\"] if np.issubdtype(tx[\"created\"].dtype, np.datetime64) \\\n",
    "             else pd.to_datetime(tx[\"created\"], errors=\"coerce\")\n",
    "    if isinstance(created, pd.Series) and np.issubdtype(created.dtype, np.datetime64):\n",
    "        try:\n",
    "            if getattr(created.dt, \"tz\", None) is not None:\n",
    "                created = created.dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    rev   = pd.to_numeric(tx.get(\"line_total_sek\"), errors=\"coerce\").fillna(0)\n",
    "    typ   = tx[\"type\"]  if \"type\"  in tx.columns else pd.Series([None]*len(tx), index=tx.index)\n",
    "    price = tx[\"price\"] if \"price\" in tx.columns else pd.Series([None]*len(tx), index=tx.index)\n",
    "\n",
    "    base_df = pd.DataFrame({\n",
    "        \"country\": country, \"city\": city, \"shopUserId\": shop, \"orderId\": order_id,\n",
    "        \"rev\": rev, \"created\": created, \"type\": typ, \"price\": price\n",
    "    })\n",
    "\n",
    "    # ---------- customers lookup (normalize id; collapse variants) ----------\n",
    "    c = customers.copy()\n",
    "    c[\"shopUserId_norm\"] = _norm_id(c[\"shopUserId\"])\n",
    "    c[\"Age\"]    = pd.to_numeric(_pick(c, [\"Age\",\"age\",\"customer_age\"]), errors=\"coerce\").astype(\"Float64\")\n",
    "    c[\"Gender\"] = _pick(c, [\"Gender\",\"gender\",\"customer_gender\"])\n",
    "\n",
    "    c_agg = (c.groupby(\"shopUserId_norm\", dropna=False)\n",
    "               .agg(Age=(\"Age\", mode_or_first),\n",
    "                    Gender=(\"Gender\", mode_or_first))\n",
    "               .reset_index())\n",
    "\n",
    "    # ---------- merge + normalize ----------\n",
    "    df = base_df.merge(c_agg, left_on=\"shopUserId\", right_on=\"shopUserId_norm\", how=\"left\")\n",
    "    df.drop(columns=[\"shopUserId_norm\"], inplace=True)\n",
    "\n",
    "    df[\"age\"]    = pd.to_numeric(df[\"Age\"], errors=\"coerce\").astype(\"Float64\")\n",
    "    df[\"gender\"] = _norm_gender(df[\"Gender\"])\n",
    "    df.drop(columns=[\"Age\",\"Gender\"], inplace=True)\n",
    "\n",
    "    # ---------- optional: backfill country from customers if missing ----------\n",
    "    if \"Country\" in customers.columns and (df[\"country\"] == \"Unknown\").any():\n",
    "        country_map = (customers.assign(shopUserId_norm=_norm_id(customers[\"shopUserId\"]))\n",
    "                                .dropna(subset=[\"shopUserId_norm\"])\n",
    "                                .drop_duplicates(\"shopUserId_norm\")\n",
    "                                .set_index(\"shopUserId_norm\")[\"Country\"]\n",
    "                                .astype(\"string[python]\").str.strip())\n",
    "        mask = df[\"country\"].eq(\"Unknown\")\n",
    "        df.loc[mask, \"country\"] = df.loc[mask, \"shopUserId\"].map(country_map).fillna(\"Unknown\")\n",
    "\n",
    "    # ---------- split ----------\n",
    "    return {cname: df[df[\"country\"] == cname].copy() for cname in NORDICS}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef339f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/data/processed/Sweden.json\n",
      "Saved: /workspace/data/processed/Denmark.json\n",
      "Saved: /workspace/data/processed/Finland.json\n",
      "Saved: /workspace/data/processed/Norway.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: pipeline for ONE country df; call this 4x (Sweden, Denmark, Finland, Norway) ===\n",
    "\n",
    "def export_country_json(df_country: pd.DataFrame, tx: pd.DataFrame, country_name: str, out_dir=\"/workspace/data/processed\"):\n",
    "    df = df_country.copy()\n",
    "    df[\"city\"] = df[\"city\"].fillna(\"Unknown\")\n",
    "\n",
    "    # --- totals (country) ---\n",
    "    total_revenue   = int(np.rint(df[\"rev\"].sum()))\n",
    "    customers_cnt   = int(df[\"shopUserId\"].nunique())\n",
    "    total_orders    = int(df[\"orderId\"].nunique())\n",
    "    aov_country     = None if total_orders == 0 else int(round(float(total_revenue) / total_orders))\n",
    "\n",
    "    # --- city aggregates ---\n",
    "    agg_city = (\n",
    "        df.groupby(\"city\", dropna=False, sort=False)\n",
    "          .agg(total_revenue_sek=(\"rev\",\"sum\"), customers_count=(\"shopUserId\",\"nunique\"))\n",
    "    )\n",
    "    agg_city[\"total_revenue_sek\"] = np.rint(agg_city[\"total_revenue_sek\"]).astype(\"int64\")\n",
    "    agg_city[\"customers_count\"]   = agg_city[\"customers_count\"].astype(\"int64\")\n",
    "\n",
    "    city_orders = (\n",
    "        df.groupby(\"city\", dropna=False)[\"orderId\"]\n",
    "          .nunique()\n",
    "          .rename(\"total_orders\")\n",
    "          .astype(\"int64\")\n",
    "    )\n",
    "\n",
    "    # --- customer summaries (includes age & gender) ---\n",
    "    df_cust = df[df[\"shopUserId\"].notna()].copy()\n",
    "    agg_customer = (\n",
    "        df_cust.groupby([\"city\",\"shopUserId\"], dropna=False, sort=False)\n",
    "              .agg(total_spent_sek=(\"rev\",\"sum\"),\n",
    "                   total_orders=(\"orderId\",\"nunique\"),\n",
    "                   first_order=(\"created\",\"min\"),\n",
    "                   last_order=(\"created\",\"max\"),\n",
    "                   age=(\"age\", mode_or_first),\n",
    "                   gender=(\"gender\", mode_or_first))\n",
    "    )\n",
    "    agg_customer[\"total_spent_sek\"] = np.rint(agg_customer[\"total_spent_sek\"]).astype(\"int64\")\n",
    "    agg_customer = agg_customer.sort_index(level=[\"city\",\"shopUserId\"])\n",
    "\n",
    "    # --- per-order ---\n",
    "    agg_order = (\n",
    "        df_cust.groupby([\"city\",\"shopUserId\",\"orderId\"], dropna=False, sort=False)\n",
    "              .agg(order_total_sek=(\"rev\",\"sum\"),\n",
    "                   n_items=(\"orderId\",\"size\"),\n",
    "                   created=(\"created\",\"min\"),\n",
    "                   order_type=(\"type\", mode_or_first),\n",
    "                   price=(\"price\", mode_or_first))\n",
    "    )\n",
    "    agg_order[\"order_total_sek\"] = np.rint(agg_order[\"order_total_sek\"]).astype(\"int64\")\n",
    "    agg_order = agg_order.sort_index(level=[\"city\",\"shopUserId\",\"orderId\"])\n",
    "\n",
    "    # --- items (from tx by original index alignment) ---\n",
    "    item_cols = [\"sku\",\"groupId\",\"created\",\"quantity\",\"price_sek\",\"name\",\"line_total_sek\",\"type\",\"brand\",\"category\",\"price\"]\n",
    "    present   = [c for c in item_cols if c in tx.columns]\n",
    "\n",
    "    items_df = pd.DataFrame({\"city\": df_country[\"city\"], \"shopUserId\": df_country[\"shopUserId\"], \"orderId\": df_country[\"orderId\"]})\n",
    "    for c in present:\n",
    "        if c == \"created\":\n",
    "            col_created = df_country[\"created\"]\n",
    "            try:\n",
    "                if getattr(col_created.dt, \"tz\", None) is not None:\n",
    "                    col_created = col_created.dt.tz_localize(None)\n",
    "            except Exception:\n",
    "                pass\n",
    "            items_df[c] = col_created\n",
    "        else:\n",
    "            items_df[c] = tx.loc[df_country.index, c] if c in tx.columns else None\n",
    "\n",
    "    items_df = items_df[df_country[\"shopUserId\"].notna()].copy()\n",
    "    items_df[\"city\"] = items_df[\"city\"].fillna(\"Unknown\")\n",
    "    items_grouped = items_df.groupby([\"city\",\"shopUserId\",\"orderId\"], dropna=False, sort=False)\n",
    "\n",
    "    # ---------- build JSON ----------\n",
    "    top_key = country_name.lower()\n",
    "    result = {\n",
    "        top_key: {\n",
    "            \"total_revenue_sek\": int(total_revenue),\n",
    "            \"customers_count\": int(customers_cnt),\n",
    "            \"total_orders\": int(total_orders),\n",
    "            \"avg_order_value_sek\": aov_country,\n",
    "            \"cities\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for cty, row in agg_city.iterrows():\n",
    "        ckey = \"Unknown\" if pd.isna(cty) else str(cty)\n",
    "        orders_c = int(city_orders.get(cty, 0))\n",
    "        rev_c    = int(row[\"total_revenue_sek\"])\n",
    "        aov_c    = None if orders_c == 0 else int(round(float(rev_c) / orders_c))\n",
    "\n",
    "        result[top_key][\"cities\"][ckey] = {\n",
    "            \"total_revenue_sek\": rev_c,\n",
    "            \"customers_count\": int(row[\"customers_count\"]),\n",
    "            \"total_orders\": orders_c,\n",
    "            \"avg_order_value_sek\": aov_c,\n",
    "            \"customers\": {}\n",
    "        }\n",
    "\n",
    "    def _item_dict(row: pd.Series):\n",
    "        cr = row.get(\"created\")\n",
    "        if isinstance(cr, pd.Timestamp): cr = cr.isoformat(sep=\" \")\n",
    "        def nz(v): return None if pd.isna(v) else v\n",
    "        def to_int(v): return None if pd.isna(v) else int(v)\n",
    "        def to_float(v): return None if pd.isna(v) else float(v)\n",
    "        return {\n",
    "            \"sku\": nz(row.get(\"sku\")),\n",
    "            \"groupId\": nz(row.get(\"groupId\")),\n",
    "            \"created\": nz(cr),\n",
    "            \"quantity\": to_int(row.get(\"quantity\")),\n",
    "            \"price_sek\": to_int(row.get(\"price_sek\")),\n",
    "            \"name\": nz(row.get(\"name\")),\n",
    "            \"line_total_sek\": to_int(row.get(\"line_total_sek\")),\n",
    "            \"type\": nz(row.get(\"type\")),\n",
    "            \"brand\": nz(row.get(\"brand\")),\n",
    "            \"category\": nz(row.get(\"category\")),\n",
    "            \"price\": to_float(row.get(\"price\")),\n",
    "        }\n",
    "\n",
    "    # customers + orders + items\n",
    "    for (cty, uid), row in agg_customer.iterrows():\n",
    "        status = status_from_orders(int(row[\"total_orders\"]))\n",
    "        first_iso = row[\"first_order\"].isoformat(sep=\" \") if pd.notna(row[\"first_order\"]) else None\n",
    "        last_iso  = row[\"last_order\"].isoformat(sep=\" \")  if pd.notna(row[\"last_order\"])  else None\n",
    "\n",
    "        age_val = None\n",
    "        if \"age\" in row and pd.notna(row[\"age\"]):\n",
    "            try: age_val = int(row[\"age\"])\n",
    "            except Exception: age_val = None\n",
    "\n",
    "        gender_val = None if \"gender\" not in row or pd.isna(row[\"gender\"]) else str(row[\"gender\"])\n",
    "\n",
    "        cust_node = {\n",
    "            \"summary\": {\n",
    "                \"total_orders\": int(row[\"total_orders\"]),\n",
    "                \"total_spent_sek\": int(row[\"total_spent_sek\"]),\n",
    "                \"first_order\": first_iso,\n",
    "                \"last_order\": last_iso,\n",
    "                \"status\": status,\n",
    "                \"age\": age_val,\n",
    "                \"gender\": gender_val,\n",
    "            },\n",
    "            \"orders\": {}\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            cust_orders = agg_order.loc[(cty, uid)]\n",
    "            if isinstance(cust_orders, pd.Series):\n",
    "                cust_orders = cust_orders.to_frame().T\n",
    "            for oid, orow in cust_orders.iterrows():\n",
    "                try:\n",
    "                    items_for_order = items_grouped.get_group((cty, uid, oid))\n",
    "                    items = [_item_dict(r) for _, r in items_for_order.iterrows()]\n",
    "                except KeyError:\n",
    "                    items = []\n",
    "                cust_node[\"orders\"][str(oid)] = {\n",
    "                    \"created\": orow[\"created\"].isoformat(sep=\" \") if pd.notna(orow[\"created\"]) else None,\n",
    "                    \"order_total_sek\": int(orow[\"order_total_sek\"]),\n",
    "                    \"n_items\": int(orow[\"n_items\"]),\n",
    "                    \"order_type\": None if pd.isna(orow[\"order_type\"]) else orow[\"order_type\"],\n",
    "                    \"price\": None if pd.isna(orow.get(\"price\")) else float(orow.get(\"price\")),\n",
    "                    \"items\": items,\n",
    "                }\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        ckey = \"Unknown\" if pd.isna(cty) else str(cty)\n",
    "        result[top_key][\"cities\"][ckey][\"customers\"][str(uid)] = cust_node\n",
    "\n",
    "    out_path = Path(out_dir) / f\"{country_name}.json\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# ==== Example usage ====\n",
    "countries = split_nordics(tx, customers)\n",
    "export_country_json(countries[\"Sweden\"],  tx, \"Sweden\")\n",
    "export_country_json(countries[\"Denmark\"], tx, \"Denmark\")\n",
    "export_country_json(countries[\"Finland\"], tx, \"Finland\")\n",
    "export_country_json(countries[\"Norway\"],  tx, \"Norway\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51f7ae",
   "metadata": {},
   "source": [
    "## Flatten json for quick math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ef68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] parsed Sweden\n",
      "[ok] parsed Denmark\n",
      "[ok] parsed Finland\n",
      "[ok] parsed Norway\n",
      "[done] wrote Parquet files to /workspace/data/parquet_out\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ---- configure these paths ----\n",
    "INPUT_DIR  = Path(\"../data/processed\")     # Sweden.json, Denmark.json, Finland.json, Norway.json\n",
    "OUTPUT_DIR = Path(\"../data/parquet_out\")   # will contain the 5 Parquet files\n",
    "\n",
    "COUNTRY_FILES = {\n",
    "    \"Sweden\":  INPUT_DIR / \"Sweden.json\",\n",
    "    \"Denmark\": INPUT_DIR / \"Denmark.json\",\n",
    "    \"Finland\": INPUT_DIR / \"Finland.json\",\n",
    "    \"Norway\":  INPUT_DIR / \"Norway.json\",\n",
    "}\n",
    "\n",
    "# ---- stable column schemas (order) ----\n",
    "CS_COUNTRY = [\"country\",\"total_revenue_sek\",\"customers_count\",\"total_orders\",\"avg_order_value_sek\"]\n",
    "CS_CITY    = [\"country\",\"city\",\"total_revenue_sek\",\"customers_count\",\"total_orders\",\"avg_order_value_sek\"]\n",
    "\n",
    "# Added age & gender here\n",
    "CS_CUST    = [\"country\",\"city\",\"customer_id\",\"total_orders\",\"total_spent_sek\",\n",
    "              \"first_order\",\"last_order\",\"status\",\"age\",\"gender\"]\n",
    "\n",
    "CS_ORDERS  = [\"country\",\"city\",\"customer_id\",\"order_id\",\"created\",\"order_total_sek\",\"n_items\",\"order_type\",\"price\"]\n",
    "CS_ITEMS   = [\"country\",\"city\",\"customer_id\",\"order_id\",\"sku\",\"groupId\",\"created\",\"quantity\",\"price_sek\",\"name\",\"line_total_sek\",\"type\",\"brand\",\"category\",\"price\"]\n",
    "\n",
    "def _unwrap(obj, hint):\n",
    "    # Accept {\"denmark\": {...}} or {...}\n",
    "    if isinstance(obj, dict) and len(obj) == 1 and isinstance(next(iter(obj.values())), dict):\n",
    "        k = next(iter(obj.keys()))\n",
    "        return k.capitalize(), next(iter(obj.values()))\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Top-level JSON must be an object/dict\")\n",
    "    return hint, obj\n",
    "\n",
    "def _ensure(df: pd.DataFrame, cols):\n",
    "    \"\"\"Ensure columns exist, preserve dtypes, and reorder.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame({c: pd.Series([], dtype=\"object\") for c in cols})[cols]\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df[cols]\n",
    "\n",
    "def flatten_country(obj, country_hint):\n",
    "    country, root = _unwrap(obj, country_hint)\n",
    "    out = {\n",
    "        \"country_summary\": [{\n",
    "            \"country\": country,\n",
    "            \"total_revenue_sek\": root.get(\"total_revenue_sek\"),\n",
    "            \"customers_count\": root.get(\"customers_count\"),\n",
    "            \"total_orders\": root.get(\"total_orders\"),\n",
    "            \"avg_order_value_sek\": root.get(\"avg_order_value_sek\"),\n",
    "        }],\n",
    "        \"city_summary\": [],\n",
    "        \"customer_summary\": [],\n",
    "        \"orders\": [],\n",
    "        \"order_items\": [],\n",
    "    }\n",
    "    for city, cnode in (root.get(\"cities\") or {}).items():\n",
    "        out[\"city_summary\"].append({\n",
    "            \"country\": country, \"city\": city,\n",
    "            \"total_revenue_sek\": cnode.get(\"total_revenue_sek\"),\n",
    "            \"customers_count\": cnode.get(\"customers_count\"),\n",
    "            \"total_orders\": cnode.get(\"total_orders\"),\n",
    "            \"avg_order_value_sek\": cnode.get(\"avg_order_value_sek\"),\n",
    "        })\n",
    "        for cust_id, cst in (cnode.get(\"customers\") or {}).items():\n",
    "            summ = cst.get(\"summary\") or {}\n",
    "            out[\"customer_summary\"].append({\n",
    "                \"country\": country,\n",
    "                \"city\": city,\n",
    "                \"customer_id\": cust_id,\n",
    "                \"total_orders\": summ.get(\"total_orders\"),\n",
    "                \"total_spent_sek\": summ.get(\"total_spent_sek\"),\n",
    "                \"first_order\": summ.get(\"first_order\"),\n",
    "                \"last_order\": summ.get(\"last_order\"),\n",
    "                \"status\": summ.get(\"status\"),\n",
    "                # NEW: carry through age & gender\n",
    "                \"age\": summ.get(\"age\"),\n",
    "                \"gender\": summ.get(\"gender\"),\n",
    "            })\n",
    "            for order_id, ordn in (cst.get(\"orders\") or {}).items():\n",
    "                out[\"orders\"].append({\n",
    "                    \"country\": country, \"city\": city, \"customer_id\": cust_id, \"order_id\": order_id,\n",
    "                    \"created\": ordn.get(\"created\"),\n",
    "                    \"order_total_sek\": ordn.get(\"order_total_sek\"),\n",
    "                    \"n_items\": ordn.get(\"n_items\"),\n",
    "                    \"order_type\": ordn.get(\"order_type\"),\n",
    "                    \"price\": ordn.get(\"price\"),\n",
    "                })\n",
    "                for it in (ordn.get(\"items\") or []):\n",
    "                    out[\"order_items\"].append({\n",
    "                        \"country\": country, \"city\": city, \"customer_id\": cust_id, \"order_id\": order_id,\n",
    "                        \"sku\": it.get(\"sku\"), \"groupId\": it.get(\"groupId\"), \"created\": it.get(\"created\"),\n",
    "                        \"quantity\": it.get(\"quantity\"), \"price_sek\": it.get(\"price_sek\"), \"name\": it.get(\"name\"),\n",
    "                        \"line_total_sek\": it.get(\"line_total_sek\"), \"type\": it.get(\"type\"),\n",
    "                        \"brand\": it.get(\"brand\"), \"category\": it.get(\"category\"), \"price\": it.get(\"price\"),\n",
    "                    })\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    # accumulate rows across all countries\n",
    "    buckets = {k: [] for k in [\"country_summary\",\"city_summary\",\"customer_summary\",\"orders\",\"order_items\"]}\n",
    "    for name, path in COUNTRY_FILES.items():\n",
    "        if not path.exists():\n",
    "            print(f\"[warn] missing: {path}\")\n",
    "            continue\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            obj = json.load(f)\n",
    "        rows = flatten_country(obj, name)\n",
    "        for k, v in rows.items():\n",
    "            buckets[k].extend(v)\n",
    "        print(f\"[ok] parsed {name}\")\n",
    "\n",
    "    # to DataFrames (fixed schemas) and save\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    df_country = _ensure(pd.DataFrame(buckets[\"country_summary\"]), CS_COUNTRY)\n",
    "    df_city    = _ensure(pd.DataFrame(buckets[\"city_summary\"]),    CS_CITY)\n",
    "    df_cust    = _ensure(pd.DataFrame(buckets[\"customer_summary\"]),CS_CUST)\n",
    "    df_orders  = _ensure(pd.DataFrame(buckets[\"orders\"]),          CS_ORDERS)\n",
    "    df_items   = _ensure(pd.DataFrame(buckets[\"order_items\"]),     CS_ITEMS)\n",
    "\n",
    "    df_country.to_parquet(OUTPUT_DIR / \"country_summary.parquet\", index=False)\n",
    "    df_city.to_parquet(OUTPUT_DIR / \"city_summary.parquet\", index=False)\n",
    "    df_cust.to_parquet(OUTPUT_DIR / \"customer_summary.parquet\", index=False)\n",
    "    df_orders.to_parquet(OUTPUT_DIR / \"orders.parquet\", index=False)\n",
    "    df_items.to_parquet(OUTPUT_DIR / \"order_items.parquet\", index=False)\n",
    "    print(f\"[done] wrote Parquet files to {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a699804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
